{
    "journal": {
        "id": "eLife", 
        "title": "eLife", 
        "issn": "2050-084X"
    }, 
    "snippet": {
        "-meta": {
            "location": "https://raw.githubusercontent.com/elifesciences/elife-article-xml/5aac79759a440b88c82b263dbd866793307e5300/articles/elife-21397-v1.xml"
        }, 
        "status": "vor", 
        "id": "21397", 
        "version": 1, 
        "type": "research-article", 
        "doi": "10.7554/eLife.21397", 
        "authorLine": "Olivia Guest, Bradley C Love", 
        "title": "What the success of brain imaging implies about the neural code", 
        "published": "2017-01-19T00:00:00Z", 
        "versionDate": "2017-01-19T00:00:00Z", 
        "volume": 6, 
        "elocationId": "e21397", 
        "pdf": "https://publishing-cdn.elifesciences.org/21397/elife-21397-v1.pdf", 
        "subjects": [
            {
                "id": "neuroscience", 
                "name": "Neuroscience"
            }
        ], 
        "researchOrganisms": [
            "Human"
        ], 
        "abstract": {
            "doi": "10.7554/eLife.21397.001", 
            "content": [
                {
                    "type": "paragraph", 
                    "text": "The success of fMRI places constraints on the nature of the neural code. The fact that researchers can infer similarities between neural representations, despite fMRI\u2019s limitations, implies that certain neural coding schemes are more likely than others. For fMRI to succeed given its low temporal and spatial resolution, the neural code must be smooth at the voxel and functional level such that similar stimuli engender similar internal representations. Through proof and simulation, we determine which coding schemes are plausible given both fMRI\u2019s successes and its limitations in measuring neural activity. Deep neural network approaches, which have been forwarded as computational accounts of the ventral stream, are consistent with the success of fMRI, though functional smoothness breaks down in the later network layers. These results have implications for the nature of the neural code and ventral stream, as well as what can be successfully investigated with fMRI."
                }
            ]
        }, 
        "copyright": {
            "license": "CC-BY-4.0", 
            "holder": "Guest et al", 
            "statement": "This article is distributed under the terms of the <a href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution License</a>, which permits unrestricted use and redistribution provided that the original author and source are credited."
        }, 
        "authors": [
            {
                "type": "person", 
                "name": {
                    "preferred": "Olivia Guest", 
                    "index": "Guest, Olivia"
                }, 
                "orcid": "0000-0002-1891-0972", 
                "affiliations": [
                    {
                        "name": [
                            "Experimental Psychology", 
                            "University College London"
                        ], 
                        "address": {
                            "formatted": [
                                "London", 
                                "United Kingdom"
                            ], 
                            "components": {
                                "locality": [
                                    "London"
                                ], 
                                "country": "United Kingdom"
                            }
                        }
                    }
                ], 
                "emailAddresses": [
                    "o.guest@ucl.ac.uk"
                ], 
                "contribution": "OG, Conceptualization, Data curation, Software, Formal analysis, Visualization, Writing\u2014original draft, Writing\u2014review and editing", 
                "competingInterests": "The authors declare that no competing interests exist."
            }, 
            {
                "type": "person", 
                "name": {
                    "preferred": "Bradley C Love", 
                    "index": "Love, Bradley C"
                }, 
                "orcid": "0000-0002-7883-7076", 
                "affiliations": [
                    {
                        "name": [
                            "Experimental Psychology", 
                            "University College London"
                        ], 
                        "address": {
                            "formatted": [
                                "London", 
                                "United Kingdom"
                            ], 
                            "components": {
                                "locality": [
                                    "London"
                                ], 
                                "country": "United Kingdom"
                            }
                        }
                    }, 
                    {
                        "name": [
                            "The Alan Turing Institute"
                        ], 
                        "address": {
                            "formatted": [
                                "London", 
                                "United Kingdom"
                            ], 
                            "components": {
                                "locality": [
                                    "London"
                                ], 
                                "country": "United Kingdom"
                            }
                        }
                    }
                ], 
                "emailAddresses": [
                    "b.love@ucl.ac.uk"
                ], 
                "contribution": "BCL, Conceptualization, Resources, Supervision, Funding acquisition, Writing\u2014original draft, Project administration, Writing\u2014review and editing", 
                "competingInterests": "The authors declare that no competing interests exist."
            }
        ], 
        "reviewers": [
            {
                "type": "person", 
                "name": {
                    "preferred": "Russell Poldrack", 
                    "index": "Poldrack, Russell"
                }, 
                "affiliations": [
                    {
                        "name": [
                            "Stanford University"
                        ], 
                        "address": {
                            "formatted": [
                                "United States"
                            ], 
                            "components": {
                                "country": "United States"
                            }
                        }
                    }
                ], 
                "role": "Reviewing editor"
            }
        ], 
        "funding": {
            "awards": [
                {
                    "id": "par-1", 
                    "source": {
                        "funderId": "10.13039/501100000275", 
                        "name": [
                            "Leverhulme Trust"
                        ]
                    }, 
                    "awardId": "RPG-2014-075", 
                    "recipients": [
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Bradley C Love", 
                                "index": "Love, Bradley C"
                            }
                        }
                    ]
                }, 
                {
                    "id": "par-2", 
                    "source": {
                        "funderId": "10.13039/100010269", 
                        "name": [
                            "Wellcome"
                        ]
                    }, 
                    "awardId": "WT106931MA", 
                    "recipients": [
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Bradley C Love", 
                                "index": "Love, Bradley C"
                            }
                        }
                    ]
                }, 
                {
                    "id": "par-3", 
                    "source": {
                        "funderId": "10.13039/100000002", 
                        "name": [
                            "National Institutes of Health"
                        ]
                    }, 
                    "awardId": "1P01HD080679", 
                    "recipients": [
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Bradley C Love", 
                                "index": "Love, Bradley C"
                            }
                        }
                    ]
                }
            ], 
            "statement": "The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication."
        }, 
        "impactStatement": "For brain imaging to be useful despite its limitations in measuring neural activity, the neural code must be smooth both in a traditional sense and functionally."
    }, 
    "article": {
        "-meta": {
            "location": "https://raw.githubusercontent.com/elifesciences/elife-article-xml/5aac79759a440b88c82b263dbd866793307e5300/articles/elife-21397-v1.xml", 
            "patched": true
        }, 
        "status": "vor", 
        "id": "21397", 
        "version": 1, 
        "type": "research-article", 
        "doi": "10.7554/eLife.21397", 
        "authorLine": "Olivia Guest, Bradley C Love", 
        "title": "What the success of brain imaging implies about the neural code", 
        "published": "2017-01-19T00:00:00Z", 
        "versionDate": "2017-01-19T00:00:00Z", 
        "volume": 6, 
        "elocationId": "e21397", 
        "pdf": "https://publishing-cdn.elifesciences.org/21397/elife-21397-v1.pdf", 
        "subjects": [
            {
                "id": "neuroscience", 
                "name": "Neuroscience"
            }
        ], 
        "researchOrganisms": [
            "Human"
        ], 
        "abstract": {
            "doi": "10.7554/eLife.21397.001", 
            "content": [
                {
                    "type": "paragraph", 
                    "text": "The success of fMRI places constraints on the nature of the neural code. The fact that researchers can infer similarities between neural representations, despite fMRI\u2019s limitations, implies that certain neural coding schemes are more likely than others. For fMRI to succeed given its low temporal and spatial resolution, the neural code must be smooth at the voxel and functional level such that similar stimuli engender similar internal representations. Through proof and simulation, we determine which coding schemes are plausible given both fMRI\u2019s successes and its limitations in measuring neural activity. Deep neural network approaches, which have been forwarded as computational accounts of the ventral stream, are consistent with the success of fMRI, though functional smoothness breaks down in the later network layers. These results have implications for the nature of the neural code and ventral stream, as well as what can be successfully investigated with fMRI."
                }
            ]
        }, 
        "copyright": {
            "license": "CC-BY-4.0", 
            "holder": "Guest et al", 
            "statement": "This article is distributed under the terms of the <a href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution License</a>, which permits unrestricted use and redistribution provided that the original author and source are credited."
        }, 
        "authors": [
            {
                "type": "person", 
                "name": {
                    "preferred": "Olivia Guest", 
                    "index": "Guest, Olivia"
                }, 
                "orcid": "0000-0002-1891-0972", 
                "affiliations": [
                    {
                        "name": [
                            "Experimental Psychology", 
                            "University College London"
                        ], 
                        "address": {
                            "formatted": [
                                "London", 
                                "United Kingdom"
                            ], 
                            "components": {
                                "locality": [
                                    "London"
                                ], 
                                "country": "United Kingdom"
                            }
                        }
                    }
                ], 
                "emailAddresses": [
                    "o.guest@ucl.ac.uk"
                ], 
                "contribution": "OG, Conceptualization, Data curation, Software, Formal analysis, Visualization, Writing\u2014original draft, Writing\u2014review and editing", 
                "competingInterests": "The authors declare that no competing interests exist."
            }, 
            {
                "type": "person", 
                "name": {
                    "preferred": "Bradley C Love", 
                    "index": "Love, Bradley C"
                }, 
                "orcid": "0000-0002-7883-7076", 
                "affiliations": [
                    {
                        "name": [
                            "Experimental Psychology", 
                            "University College London"
                        ], 
                        "address": {
                            "formatted": [
                                "London", 
                                "United Kingdom"
                            ], 
                            "components": {
                                "locality": [
                                    "London"
                                ], 
                                "country": "United Kingdom"
                            }
                        }
                    }, 
                    {
                        "name": [
                            "The Alan Turing Institute"
                        ], 
                        "address": {
                            "formatted": [
                                "London", 
                                "United Kingdom"
                            ], 
                            "components": {
                                "locality": [
                                    "London"
                                ], 
                                "country": "United Kingdom"
                            }
                        }
                    }
                ], 
                "emailAddresses": [
                    "b.love@ucl.ac.uk"
                ], 
                "contribution": "BCL, Conceptualization, Resources, Supervision, Funding acquisition, Writing\u2014original draft, Project administration, Writing\u2014review and editing", 
                "competingInterests": "The authors declare that no competing interests exist."
            }
        ], 
        "reviewers": [
            {
                "type": "person", 
                "name": {
                    "preferred": "Russell Poldrack", 
                    "index": "Poldrack, Russell"
                }, 
                "affiliations": [
                    {
                        "name": [
                            "Stanford University"
                        ], 
                        "address": {
                            "formatted": [
                                "United States"
                            ], 
                            "components": {
                                "country": "United States"
                            }
                        }
                    }
                ], 
                "role": "Reviewing editor"
            }
        ], 
        "funding": {
            "awards": [
                {
                    "id": "par-1", 
                    "source": {
                        "funderId": "10.13039/501100000275", 
                        "name": [
                            "Leverhulme Trust"
                        ]
                    }, 
                    "awardId": "RPG-2014-075", 
                    "recipients": [
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Bradley C Love", 
                                "index": "Love, Bradley C"
                            }
                        }
                    ]
                }, 
                {
                    "id": "par-2", 
                    "source": {
                        "funderId": "10.13039/100010269", 
                        "name": [
                            "Wellcome"
                        ]
                    }, 
                    "awardId": "WT106931MA", 
                    "recipients": [
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Bradley C Love", 
                                "index": "Love, Bradley C"
                            }
                        }
                    ]
                }, 
                {
                    "id": "par-3", 
                    "source": {
                        "funderId": "10.13039/100000002", 
                        "name": [
                            "National Institutes of Health"
                        ]
                    }, 
                    "awardId": "1P01HD080679", 
                    "recipients": [
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Bradley C Love", 
                                "index": "Love, Bradley C"
                            }
                        }
                    ]
                }
            ], 
            "statement": "The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication."
        }, 
        "impactStatement": "For brain imaging to be useful despite its limitations in measuring neural activity, the neural code must be smooth both in a traditional sense and functionally.", 
        "keywords": [
            "BOLD response", 
            "convolutional neural network", 
            "deep artificial neural network", 
            "neural code", 
            "neural plausibility", 
            "ventral stream"
        ], 
        "-related-articles-internal": [], 
        "-related-articles-external": [], 
        "digest": {
            "doi": "10.7554/eLife.21397.002", 
            "content": [
                {
                    "type": "paragraph", 
                    "text": "We can appreciate that a cat is more similar to a dog than to a truck. The combined activity of millions of neurons in the brain somehow captures these everyday similarities, and this activity can be measured using imaging techniques such as functional magnetic resonance imaging (fMRI). However, fMRI scanners are not particularly precise \u2013 they average together the responses of many thousands of neurons over several seconds, which provides a blurry snapshot of brain activity. Nevertheless, the pattern of activity measured when viewing a photograph of a cat is more similar to that seen when viewing a picture of a dog than a picture of a truck. This tells us a lot about how the brain codes information, as only certain coding methods would allow fMRI to capture these similarities given the technique\u2019s limitations."
                }, 
                {
                    "type": "paragraph", 
                    "text": "There are many different models that attempt to describe how the brain codes similarity relations. Some models use the principle of neural networks, in which neurons can be considered as arranged into interconnected layers. In such models, neurons transmit information from one layer to the next."
                }, 
                {
                    "type": "paragraph", 
                    "text": "By investigating which models are consistent with fMRI\u2019s ability to capture similarity relations, Guest and Love have found that certain neural network models are plausible accounts of how the brain represents and processes information. These models include the deep learning networks that contain many layers of neurons and are popularly used in artificial intelligence. Other modeling approaches do not account for the ability of fMRI to capture similarity relations."
                }, 
                {
                    "type": "paragraph", 
                    "text": "As neural networks become deeper with more layers, they should be less readily understood using fMRI: as the number of layers increases, the representations of objects with similarities (for example, cats and dogs) become more unrelated. One question that requires further investigation is whether this finding explains why certain parts of the brain are more difficult to image."
                }
            ]
        }, 
        "body": [
            {
                "type": "section", 
                "id": "s1", 
                "title": "Introduction", 
                "content": [
                    {
                        "type": "paragraph", 
                        "text": "Neuroimaging and especially functional magnetic resonance imaging (fMRI) has come a long way since the first experiments in the early 1990s.\u00a0These impressive findings are curious in light of fMRI\u2019s limitations.\u00a0The blood-oxygen-level-dependent (BOLD) response measured by fMRI is a noisy and indirect measure of neural activity (<a href=\"#bib54\">Logothetis, 2002</a>, <a href=\"#bib55\">2008</a>;\u00a0<a href=\"#bib66\">O'Herron et al., 2016</a>) from which researchers try to infer neural function."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "The BOLD response trails neural activity by 2 s, peaks at 5 to 6 s, and returns to baseline around 10 s, whereas neural activity occurs on the order of milliseconds and can be brief (<a href=\"#bib39\">Huettel et al., 2009</a>).\u00a0In terms of spatial resolution, the BOLD response may spill\u00a0over millimeters away from neural activity due to contributions from venous signals (<a href=\"#bib88\">Turner, 2002</a>).\u00a0Likewise, differences in BOLD response can arise from incidental differences in the vascular properties of brain regions (<a href=\"#bib3\">Ances et al., 2009</a>).\u00a0Such sources of noise can potentially imply differences in neural activity in regions where there should not be."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "The data acquisition process itself places limits on fMRI measurement.\u00a0Motion artefacts (e.g., head movements by human subjects) and non-uniformity in the magnetic field reduce data quality. In analysis, three-dimensional images are constructed from slices acquired at slightly different times.\u00a0Once collected, fMRI data are typically smoothed during analyses (<a href=\"#bib9\">Carp, 2012</a>).\u00a0All these factors place limits on what fMRI can measure."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "Despite these weaknesses, fMRI has proved to be an incredibly useful tool.\u00a0For example, we now know that basic cognitive processes involved in language (<a href=\"#bib5\">Binder et al., 1997</a>) and working memory (<a href=\"#bib68\">Pessoa et al., 2002</a>) are distributed throughout the cortex.\u00a0Such findings challenged notions that cognitive faculties are in a one-to-one correspondence with brain regions."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "Advances in data analysis have increased what can be inferred by fMRI (<a href=\"#bib18\">De Martino et al., 2008</a>).\u00a0One of these advances is multivariate pattern analysis (MVPA), which decodes a pattern of neural activity in order to assess the information contained within (<a href=\"#bib14\">Cox and Savoy, 2003</a>).\u00a0Rather than computing univariate statistical contrasts, such as comparing overall BOLD activity for a region when a face or house stimulus is shown, MVPA takes voxel patterns into account."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "Using MVPA, so-called \u2018mind reading\u2019 can be carried out \u2014 specific brain states can be decoded given fMRI activity (<a href=\"#bib65\">Norman et al., 2006</a>), revealing cortical representation and organization in impressive detail.\u00a0For example, using these analysis techniques paired with fMRI we can know whether a participant is being deceitful in a game (<a href=\"#bib16\">Davatzikos et al., 2005</a>), and we can determine whether a participant is reading an ambiguous sentence as well as infer the semantic category of a word they are reading (<a href=\"#bib62\">Mitchell et al., 2004</a>)."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "Representational similarity analysis (RSA), another multivariate technique, is particularly suited to examining representational structure (<a href=\"#bib48\">Kriegeskorte et al., 2008</a>; <a href=\"#bib49\">Kriegeskorte, 2009</a>).\u00a0We will focus on RSA later in this contribution, so we will consider this technique in some detail.\u00a0RSA directly compares the similarity (e.g., by using correlation) of brain activity arising from the presentation of different stimuli.\u00a0For example, the neural activity arising from viewing a robin and sparrow may be more similar to each other than between a robin and a penguin."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "These pairwise neural similarities can be compared to those predicted by a particular theoretical model to determine correspondences. For example, <a href=\"#bib57\">Mack et al. (2013</a>) identified brain regions where the neural similarity structure corresponded to that of a cognitive model of human categorization, which was useful in inferring the function of various brain regions.\u00a0The neural similarities themselves can be visualized by applying multidimensional scaling to further understand the properties of the space (<a href=\"#bib17\">Davis et al., 2014</a>).\u00a0RSA has been useful in a number of other endeavors, such as understanding the role of various brain areas in reinstating past experiences (<a href=\"#bib87\">Tompary et al., 2016</a>; <a href=\"#bib58\">Mack and Preston, 2016</a>)."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "Given fMRI\u2019s limitations in measuring neural activity, one might ask how it is possible for methods like RSA to be successful.\u00a0The BOLD response is temporally and spatially imprecise, yet it appears that researchers can infer general properties of neural representations that link sensibly to stimulus and behavior.\u00a0The neural code must have certain properties for this state of affairs to hold.\u00a0What kinds of models or computations are consistent with the success of fMRI?\u00a0If the brain is a computing device, it would have to be of a particular type for fMRI to be useful given its limitations in measuring neural activity."
                    }
                ]
            }, 
            {
                "type": "section", 
                "id": "s2", 
                "title": "Smoothness and the neural code", 
                "content": [
                    {
                        "type": "paragraph", 
                        "text": "For fMRI to recover neural similarity spaces, the neural code must display certain properties. Firstly, the neural code cannot be so fine-grained that fMRI\u2019s temporal and spatial resolution limitations make it impossible to resolve representational differences.\u00a0Second, a notion of <i>functional smoothness</i>, which we will introduce and define, must also be partially satisfied."
                    }, 
                    {
                        "type": "section", 
                        "id": "s2-1", 
                        "title": "Voxel inhomogeneity across space and time", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "The BOLD response summates neural activity over space and time, which places hard limits on what fMRI can measure.\u00a0To make an analogy, <math id=\"inf1\"><mrow><mn>3</mn><mo>+</mo><mn>5</mn></mrow></math> and <math id=\"inf2\"><mrow><mn>6</mn><mo>+</mo><mn>2</mn></mrow></math> both equal <math id=\"inf3\"><mn>8</mn></math> through different routes. If different \u2018routes\u2019 of neural activity are consequential to the neural code and are summated in the BOLD response, then fMRI will be blind to representational differences."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "To capture representational differences, voxel response must be inhomogeneous both between voxels and within a voxel across time. Consider the fMRI analogues shown in <a href=\"#fig1\">Figure 1</a>; paralleling neurons with pixels and voxels with the squares on the superimposed grid.\u00a0The top-left image depicts neural activity that smoothly varies such that the transitions from red to yellow occur in progressive increments.\u00a0Summating within a square, i.e., a voxel, will not dramatically alter the high-level view of a smooth transition from red to yellow (bottom-left image). Voxel response is inhomogeneous, which would allow decoding by fMRI (cf.\u00a0<a href=\"#bib40\">Kamitani and Tong, 2005</a>;\u00a0<a href=\"#bib2\">Alink et al., 2013</a>).\u00a0Altering the grid (i.e., voxel) size will not have a dramatic impact on the results as long as the square does not become so large as to subsume most of the pixels (i.e., neurons).\u00a0This result is in line with basic concepts from information theory, such as the Nyquist-Shannon sampling theorem.\u00a0The key is that the red and yellow pixels/neurons are topologically organized: their relationship to each other is for all intents and purposes invariant to the granularity of the squares/voxels (for more details see: <a href=\"#bib10\">Chaimow et al., 2011</a>; <a href=\"#bib23\">Freeman et al., 2011</a>; <a href=\"#bib83\">Swisher et al., 2010</a>)."
                            }, 
                            {
                                "type": "image", 
                                "doi": "10.7554/eLife.21397.003", 
                                "id": "fig1", 
                                "label": "Figure 1.", 
                                "title": "The activity of neurons in the top-left panel gradually changes from left to right, whereas changes are more abrupt in the top-middle and top-right panels.", 
                                "caption": [
                                    {
                                        "type": "paragraph", 
                                        "text": "Each square in the grid represents a voxel which summates activity within its frame as shown in the bottom panels. For the smoother pattern of neural activity, the summation of each voxel (bottom left) captures the changing gradient from left to right depicted in the top-left, whereas for the less smooth representation in the middle panel all voxels sum to the same orange value (bottom middle). Thus, differences in activation of yellow vs. red neurons are detectable using fMRI for the smooth case, but not for the less smooth case because voxel response is homogenous. Improving spatial resolution (right panels) by reducing voxel size overcomes these sampling limits, resulting in voxel inhomogeneity (bottom-right panel)."
                                    }
                                ], 
                                "alt": "", 
                                "uri": "https://publishing-cdn.elifesciences.org/21397/elife-21397-fig1-v1.jpg", 
                                "filename": "elife-21397-fig1-v1.jpg"
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "In contrast, the center-top image in <a href=\"#fig1\">Figure 1</a> involves dramatic representational changes within voxel.\u00a0Each voxel (square in the grid), in this case, will produce a homogenous orange color when its contents are summated.\u00a0Thus, summating the contents of a voxel in this case obliterates the representational content: red and yellow; returning instead squares/voxels that are all the same uniform color: orange. This failure is due to sampling limits that could be addressed by smaller voxels (see rightmost\u00a0column). Unfortunately, arbitrarily small voxels with high sampling rates is not a luxury afforded to fMRI."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "The success of fMRI given its sampling limits is consistent with proposed neural coding schemes, such as population coding (<a href=\"#bib4\">Averbeck et al., 2006</a>; <a href=\"#bib67\">Panzeri et al., 2015</a>; <a href=\"#bib69\">Pouget et al., 2000</a>) in cases where neurons with similar tunings spatially cluster (e.g., <a href=\"#bib61\">Maunsell and Van Essen, 1983</a>).\u00a0In population coding, neurons jointly contribute to represent a stimulus in much the same way as pixels were contributing to represent different colors in the leftmost column of <a href=\"#fig1\">Figure 1</a>.\u00a0When this inhomogeneity breaks down, similarity structures should be difficult to recover using fMRI. Indeed, a recent study with macaque monkeys which considered both single-cell and fMRI measures supports this viewpoint \u2014 stimulus aspects which were poorly spatially clustered in terms of single cell selectivity were harder to decode from the BOLD response (<a href=\"#bib20\">Dubois et al., 2015</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "The same principles extend from the spatial to the temporal domain.\u00a0The BOLD response will be blind to the\u00a0differences between representations to the extent that the brain relies on the precise timing of neural activity to code information. For example, in burstiness coding, neural representations are distinguished from one another not by their average firing rate but by the variance of their activity (<a href=\"#bib22\">Fano, 1947</a>; <a href=\"#bib41\">Katz, 1996</a>).\u00a0Under this coding scheme, more intense stimulus values are represented by burstier units, not units that fire more overall. Neural similarity is not recoverable by fMRI under a burstiness coding scheme.\u00a0Because the BOLD signal roughly summates through time (<a href=\"#bib6\">Boynton et al., 1996</a>), firing events will sum together to the same number irrespective of their burstiness."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "Likewise, BOLD activity may be a composite of synchronized activity at multiple frequencies. Although gamma-band local field potential is most associated with BOLD response, oscillations at other frequency bands may also contribute to the BOLD response (<a href=\"#bib59\">Magri et al., 2012</a>;\u00a0<a href=\"#bib79\">Scheeringa et al., 2011</a>). If so, fMRI would fail to distinguish between representational states that are differentiated by the balance of contributions across bands, much like the arithmetic example at the start of this subsection in which different addends yield the same sum. As before, basic concepts in information theory, such as the Nyquist-Shannon sampling theorem, imply that temporally demanding coding schemes will be invisible to fMRI (cf. <a href=\"#bib64\">Nevado et al., 2004</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "The success of fMRI does not imply that the brain does not utilize precise timing information, but it does mean that such temporally demanding coding schemes cannot be the full story given fMRI\u2019s successes in revealing neural representations.\u00a0Instead, the neural code must include in its mixture at\u00a0least\u00a0some coding\u00a0schemes that are consistent with fMRI's\u00a0successes. For example, rate coding (<a href=\"#bib1\">Adrian and Zotterman, 1926</a>) in which the frequency at which neurons fire is a function of the intensity of a stimulus is consistent with the success of fMRI because changes in firing rate for a population of cells should be recoverable by fMRI as more blood flows to more active cells (<a href=\"#bib66\">O'Herron et al., 2016</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "These examples make clear that the neural code must be somewhat spatially and temporally smooth with respect to neural activity (which is several orders of magnitude smaller than voxels) for fMRI to be successful.\u00a0Whatever is happening in the roughly one million neurons within a voxel (<a href=\"#bib39\">Huettel et al., 2009</a>) through time is being partially reflected by the BOLD summation,\u00a0which would not be the case if each neuron was computing something dramatically different for in-depth discussion, see: (<a href=\"#bib47\">Kriegeskorte et al., 2010</a>)."
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s2-2", 
                        "title": "Functional smoothness", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "One general conclusion is that important aspects of the neural code are spatially and temporally smooth. In a sense, this notion of smoothness is trivial as it merely implies that changes in neural activity must be visible in the BOLD response (i.e., across-voxel inhomogeneity) for fMRI to be successful.\u00a0In this section, we focus on a more subtle sense of smoothness that must also be satisfied, namely functional smoothness."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "Neighboring voxels predominantly contain similar representations\u00a0(<a href=\"#bib65\">Norman et al., 2006</a>), i.e., they are topologically organized like in <a href=\"#fig1\">Figure 1</a>. However, <i>super-voxel smoothness</i> is neither necessary nor sufficient for fMRI to succeed in recovering similarity structure. Instead, a more general notion of functional smoothness must be satisfied in which similar stimuli map to similar internal representations. Although super-voxel and functional smoothness are both specified at the super-voxel level, these distinct concepts should not be confused.\u00a0A function <math id=\"inf4\"><mi>f</mi></math> that maps from some input <math id=\"inf5\"><mi>x</mi></math> to output <math id=\"inf6\"><mi>y</mi></math> is functionally smooth if and only if"
                            }, 
                            {
                                "type": "mathml", 
                                "id": "equ1", 
                                "label": "(1)", 
                                "mathml": "<math><mstyle displaystyle=\"true\" scriptlevel=\"0\"><mrow><mrow><mi mathvariant=\"normal\">s</mi><mi mathvariant=\"normal\">i</mi><mi mathvariant=\"normal\">m</mi></mrow><mrow><mo>(</mo><mrow><msub><mi>x</mi><mrow><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>2</mn></mrow></msub></mrow><mo>)</mo></mrow><mo>\u221d</mo><mrow><mi mathvariant=\"normal\">s</mi><mi mathvariant=\"normal\">i</mi><mi mathvariant=\"normal\">m</mi></mrow><mrow><mo>(</mo><mrow><msub><mi>y</mi><mrow><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>y</mi><mrow><mn>2</mn></mrow></msub></mrow><mo>)</mo></mrow><mo>,</mo></mrow></mstyle></math>"
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "where <math id=\"inf7\"><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo>(</mo><msub id=\"XM7\"><mi>x</mi><mn>1</mn></msub><mo>)</mo></mrow></mrow><mo>=</mo><msub><mi>y</mi><mn>1</mn></msub></mrow></math> and <math id=\"inf8\"><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo>(</mo><msub id=\"XM8\"><mi>x</mi><mn>2</mn></msub><mo>)</mo></mrow></mrow><mo>=</mo><msub><mi>y</mi><mn>2</mn></msub></mrow></math>. For example, <math id=\"inf9\"><mi>x</mi></math> and <math id=\"inf10\"><mi>y</mi></math> could be the beta estimates for voxels in two brain regions and <math id=\"inf11\"><mstyle displaystyle=\"true\" scriptlevel=\"0\"><mrow><mi mathvariant=\"normal\">s</mi><mi mathvariant=\"normal\">i</mi><mi mathvariant=\"normal\">m</mi></mrow></mstyle></math> could be Pearson correlation. To measure functional smoothness, the degree of proportionality between all possible similarity pairs <math id=\"inf12\"><mstyle displaystyle=\"true\" scriptlevel=\"0\"><mrow><mrow><mi mathvariant=\"normal\">s</mi><mi mathvariant=\"normal\">i</mi><mi mathvariant=\"normal\">m</mi></mrow><mrow><mo>(</mo><mrow><msub><mi>x</mi><mrow><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>x</mi><mrow><mn>2</mn></mrow></msub></mrow><mo>)</mo></mrow></mrow></mstyle></math> and <math id=\"inf13\"><mstyle displaystyle=\"true\" scriptlevel=\"0\"><mrow><mrow><mi mathvariant=\"normal\">s</mi><mi mathvariant=\"normal\">i</mi><mi mathvariant=\"normal\">m</mi></mrow><mrow><mo>(</mo><mrow><msub><mi>y</mi><mrow><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>y</mi><mrow><mn>2</mn></mrow></msub></mrow><mo>)</mo></mrow></mrow></mstyle></math> also could be assessed by Pearson correlation (i.e., does the similarity between a <math id=\"inf14\"><msub><mi>y</mi><mn>1</mn></msub></math> and <math id=\"inf15\"><msub><mi>y</mi><mn>2</mn></msub></math> pair increase as the similarity increases between the corresponding <math id=\"inf16\"><msub><mi>x</mi><mn>1</mn></msub></math> and <math id=\"inf17\"><msub><mi>x</mi><mn>2</mn></msub></math> pair). By definition, functional smoothness needs to be preserved in the neural code for fMRI to recover similarity correspondences (as in RSA), whether these correspondences are between stimuli (e.g., <math id=\"inf18\"><mi>x</mi></math>s) and neural activity (e.g., <math id=\"inf19\"><mi>y</mi></math>s), multiple brain regions (e.g., <math id=\"inf20\"><mi>x</mi></math>s and <math id=\"inf21\"><mi>y</mi></math>s), or model measure (e.g., <math id=\"inf22\"><mi>x</mi></math>s) and some brain region (e.g., <math id=\"inf23\"><mi>y</mi></math>s)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "From this definition, it should be clear that functional smoothness is distinct from super-voxel smoothness. For example, a brain area that showed smooth activity patterns across voxels for each individual face stimulus but whose activity did not reflect the similarity structure of the stimuli would be super-voxel smooth, but not functionally smooth with respect to the stimulus set. Conversely, a later section of this contribution discusses how neural networks with random weights are functionally but not super-voxel smooth."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "To help introduce the concept of functional smoothness, we consider two coding schemes used in engineering applications, factorial and hash coding, which are both inconsistent with the success of fMRI because they do not preserve functional smoothness.\u00a0In the next section, we consider coding schemes, such as deep learning networks, that are functionally smooth to varying extents and are consistent with the success of fMRI."
                            }, 
                            {
                                "type": "section", 
                                "id": "s2-2-1", 
                                "title": "Factorial design coding", 
                                "content": [
                                    {
                                        "type": "paragraph", 
                                        "text": "Factorial design is closely related to the notion of hierarchy.\u00a0For example, hierarchical approaches to human object recognition (<a href=\"#bib80\">Serre and Poggio, 2010</a>) propose that simple visual features (e.g., a horizontal or vertical line) are combined to form more complex features (e.g., a cross).\u00a0From a factorial perspective, the simple features can be thought of as main effects and the complex features, which reflect the combination of simple features, as interactions."
                                    }, 
                                    {
                                        "type": "paragraph", 
                                        "text": "In <a href=\"#tbl1\">Table 1</a>, a <math id=\"inf24\"><msup><mn>2</mn><mn>3</mn></msup></math> two-level full factorial design is shown with three factors A, B, C, three two-way interactions AB, AC, BC, and a three-way interaction ABC, as well as an intercept term.\u00a0All columns in the design matrix are pairwise orthogonal."
                                    }, 
                                    {
                                        "type": "table", 
                                        "doi": "10.7554/eLife.21397.004", 
                                        "id": "tbl1", 
                                        "label": "Table 1.", 
                                        "title": "Design matrix for a <math id=\"inf25\"><msup><mn>2</mn><mn>3</mn></msup></math> full factorial design", 
                                        "tables": [
                                            "<table><thead><tr><th>I</th><th>A</th><th>B</th><th>C</th><th>AB</th><th>AC</th><th>BC</th><th>ABC</th></tr></thead><tbody><tr><th><math id=\"inf26\"><mn>1</mn></math></th><td align=\"right\"><math id=\"inf27\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf28\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf29\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf30\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf31\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf32\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf33\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td></tr><tr><th><math id=\"inf34\"><mn>1</mn></math></th><td align=\"right\"><math id=\"inf35\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf36\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf37\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf38\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf39\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf40\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf41\"><mn>1</mn></math></td></tr><tr><th><math id=\"inf42\"><mn>1</mn></math></th><td align=\"right\"><math id=\"inf43\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf44\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf45\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf46\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf47\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf48\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf49\"><mn>1</mn></math></td></tr><tr><th><math id=\"inf50\"><mn>1</mn></math></th><td align=\"right\"><math id=\"inf51\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf52\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf53\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf54\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf55\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf56\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf57\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td></tr><tr><th><math id=\"inf58\"><mn>1</mn></math></th><td align=\"right\"><math id=\"inf59\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf60\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf61\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf62\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf63\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf64\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf65\"><mn>1</mn></math></td></tr><tr><th><math id=\"inf66\"><mn>1</mn></math></th><td align=\"right\"><math id=\"inf67\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf68\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf69\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf70\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf71\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf72\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf73\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td></tr><tr><th><math id=\"inf74\"><mn>1</mn></math></th><td align=\"right\"><math id=\"inf75\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf76\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf77\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf78\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf79\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td><td align=\"right\"><math id=\"inf80\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf81\"><mrow><mo>-</mo><mn>1</mn></mrow></math></td></tr><tr><th><math id=\"inf82\"><mn>1</mn></math></th><td align=\"right\"><math id=\"inf83\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf84\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf85\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf86\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf87\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf88\"><mn>1</mn></math></td><td align=\"right\"><math id=\"inf89\"><mn>1</mn></math></td></tr></tbody></table>"
                                        ]
                                    }, 
                                    {
                                        "type": "paragraph", 
                                        "text": "Applying the concept of factorial design to modeling the neural code involves treating each row in <a href=\"#tbl1\">Table 1</a> as a representation.\u00a0For example, each entry in a row could correspond to the activity level of a voxel.\u00a0Interestingly, if any region in the brain solely had such a distribution of voxels, neural similarity would be impossible to recover by fMRI.\u00a0The reason for this is that every representation (i.e., row in <a href=\"#tbl1\">Table 1</a>) is orthogonal to every other row, which means\u00a0the neural similarity is the same for any pair of items.\u00a0Thus, this coding scheme cannot uncover that low distortions are more similar to a category prototype than high distortions."
                                    }, 
                                    {
                                        "type": "paragraph", 
                                        "text": "Rather than demonstrate by simulation, we can supply a simple proof to make this case using basic linear algebra.\u00a0Dividing each item in the <math id=\"inf90\"><mrow><mi>n</mi><mo>\u00d7</mo><mi>n</mi></mrow></math> design matrix (i.e., <a href=\"#tbl1\">Table 1</a>) by <math id=\"inf91\"><msqrt><mi>n</mi></msqrt></math>, makes each column orthonormal, i.e., each column will represent a unit vector and be orthogonal to the other columns.\u00a0This condition means that the design matrix is orthogonal.\u00a0For an orthogonal matrix, <math id=\"inf92\"><mi>Q</mi></math>, like our design matrix, the following property holds: <math id=\"inf93\"><mrow><mrow><mi>Q</mi><mo>\u00d7</mo><msup><mi>Q</mi><mi>T</mi></msup></mrow><mo>=</mo><mrow><msup><mi>Q</mi><mi>T</mi></msup><mo>\u00d7</mo><mi>Q</mi></mrow><mo>=</mo><mi>I</mi></mrow></math>; where <math id=\"inf94\"><msup><mi>Q</mi><mi>T</mi></msup></math> is the transpose of <math id=\"inf95\"><mi>Q</mi></math> (a matrix obtained by swapping columns and rows), and <math id=\"inf96\"><mi>I</mi></math> is the identity matrix.\u00a0This property of orthogonal matrices implies that rows and columns in the factorial design matrix are interchangeable, and that both rows and columns are orthogonal."
                                    }, 
                                    {
                                        "type": "paragraph", 
                                        "text": "The internal representations created using a factorial design matrix do not cluster in ways that meaningfully reflect the categorical structure of the inputs.\u00a0Due to the fact that each representation is created such that it is orthogonal to every other, there can be no way for information, correlations within and between categories, to emerge.\u00a0Two inputs varying in just one dimension (i.e., pixel) would have zero similarity; this is inherently not functionally smooth. In terms of <a href=\"#equ1\">Equation 1</a> and <a href=\"#tbl1\">Table 1</a>, an <math id=\"inf97\"><mi>x</mi></math> would be a three dimensional vector consisting of the values of A, B, and C, whereas its <math id=\"inf98\"><mi>y</mi></math> would be the entire corresponding row from the table. Setting aside the degenerate case of self-similarity, there is no proportional relationship between similarity pairs because all <math id=\"inf99\"><mi>y</mi></math> pairs have zero similarity. If the neural code for a region was employing a technique similar to factorial design, neuroimaging studies would never uncover similarity structures by looking at the activity\u00a0patterns of voxels in that region."
                                    }
                                ]
                            }, 
                            {
                                "type": "section", 
                                "id": "s2-2-2", 
                                "title": "Hash function coding", 
                                "content": [
                                    {
                                        "type": "paragraph", 
                                        "text": "Hash functions assign arbitrary unique outputs to unique inputs, which is potentially useful for any memory system be it digital or biological. However, such a coding scheme is not functionally smooth by design.\u00a0Hashing inputs allow for a memory, a data store known as a hash table, that is content-addressable (<a href=\"#bib31\">Hanlon, 1966</a>; <a href=\"#bib44\">Knott, 1975</a>) \u2014 also a property of certain types of artificial neural network (<a href=\"#bib36\">Hopfield, 1982</a>; <a href=\"#bib45\">Kohonen et al., 1987</a>).\u00a0Using a cryptographic hash function means that the arbitrary location in memory of an input is a function of the input itself."
                                    }, 
                                    {
                                        "type": "paragraph", 
                                        "text": "We employed (using the procedure below) the secure cryptographic hash algorithm 1 (SHA-1), an often-used hash function, and applied it to each value in the input vector (<a href=\"#bib63\">National Institute of Standards and Technology, 2015</a>).\u00a0Two very similar inputs (e.g., members of the same category) are extremely unlikely to produce similar SHA-1 hashes. Thus, they will be stored distally to each other, and no meaningful within-category correlation will arise (i.e., functional smoothness is violated). Indeed, in cryptography applications any such similarities could be exploited to make predictions about the input."
                                    }, 
                                    {
                                        "type": "paragraph", 
                                        "text": "If the neural code in a brain area was underpinned by behavior akin to that of a hash function, imaging would be unable to detect correlations with the input.\u00a0This is due to the fact that hash functions are engineered in such a way as to destroy any correlations, while nonetheless allowing for the storage of the input in hash tables."
                                    }, 
                                    {
                                        "type": "paragraph", 
                                        "text": "Although hash tables do not seem well-matched to the demands of cognitive systems that generalize inputs, they would prove useful in higher-level mental functions such as source memory monitoring.\u00a0Indeed, to foreshadow a result below, the advanced layers of very deep artificial neural networks approximate a cryptographic hash function, which consequently makes it difficult to recover the\u00a0similarity structure in those layers."
                                    }
                                ]
                            }
                        ]
                    }
                ]
            }, 
            {
                "type": "section", 
                "id": "s3", 
                "title": "Model", 
                "content": [
                    {
                        "type": "paragraph", 
                        "text": "In this section, we consider whether neural networks with random weights are consistent with the success of fMRI given its limitations in measuring neural activity. Simulations in the next section revisit these issues through the lens of a deep learning model trained to classify photographs of real-world categories, such as moped, tiger, guitar, robin, etc."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "Each simulation is analogous to performing fMRI on the candidate neural code.\u00a0These simple simulations answer whether in principle neural similarity can be recovered from fMRI data taken from certain neural coding schemes.\u00a0Stimuli are presented to a model while its internal representations are measured by a simulated fMRI scanner."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "The methods were as follows. The stimuli consist of 100-dimensional vectors that were distortions of an underlying prototype.\u00a0As noise is added to the prototype and the distortion level increases, the neural similarity (measured using Pearson\u2019s correlation coefficient <math id=\"inf100\"><mi>\u03c1</mi></math>) between the prototype and its member should decrease.\u00a0The question is whether we can recover this change in neural similarity in our simulated fMRI scanner."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "First, each fully-connected network was initialized to random weights drawn from a Gaussian distribution\u00a0(<math id=\"inf101\"><mrow><mrow id=\"XM15\"><mi>\u03bc</mi><mo>=</mo><mn>0</mn></mrow><mo rspace=\"5.8pt\">,</mo><mrow id=\"XM16\"><mi>\u03c3</mi><mo>=</mo><mn>1</mn></mrow></mrow></math>).\u00a0Then, a prototype was created from 100 draws from a Gaussian distribution (<math id=\"inf102\"><mrow><mrow id=\"XM17\"><mi>\u03bc</mi><mo>=</mo><mn>0</mn></mrow><mo rspace=\"5.8pt\">,</mo><mrow id=\"XM18\"><mi>\u03c3</mi><mo>=</mo><mn>1</mn></mrow></mrow></math>).\u00a0Nineteen distortions of the prototype were created by adding levels of Gaussian noise with increasing standard deviation (<math id=\"inf103\"><mrow><mi>\u03c3</mi><mo>=</mo><mrow><msub><mi>\u03c3</mi><mrow><mi>p</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>v</mi></mrow></msub><mo>+</mo><mn>0.05</mn></mrow></mrow></math>) to the prototype.\u00a0Finally, each item was re-normalized and mean centered, so that <math id=\"inf104\"><mrow><mi>\u03bc</mi><mo>=</mo><mn>0</mn></mrow></math> and <math id=\"inf105\"><mrow><mi>\u03c3</mi><mo>=</mo><mn>1</mn></mrow></math> regardless of the level of distortion.\u00a0This procedure was repeated for 100 random networks.\u00a0In the simulations that follow, the models considered involved some portion of the randomly-initialized 8-layer network (<math id=\"inf106\"><mrow><mn>8</mn><mo>\u00d7</mo><msup><mn>100</mn><mn>2</mn></msup></mrow></math> weights)."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "The coding schemes that follow are important components in artificial neural network models.\u00a0The order of presentation is from the most basic components to more complex configurations of networks.\u00a0To foreshadow the results shown in <a href=\"#fig2\">Figure 2</a>, fMRI can recover the\u00a0similarity structure for all of these models to varying degrees with the simpler models faring better than the more complex models."
                    }, 
                    {
                        "type": "image", 
                        "doi": "10.7554/eLife.21397.005", 
                        "id": "fig2", 
                        "label": "Figure 2.", 
                        "title": "As models become more complex with added layers, similarity structure becomes harder to recover, which might parallel function along the ventral stream.\u00a0", 
                        "caption": [
                            {
                                "type": "paragraph", 
                                "text": "(<b>A</b>) For the artificial neural network coding schemes, similarity to the prototype falls off with increasing distortion (i.e., noise).\u00a0The models, numbered 1\u201311, are (<i>1</i>) vector space coding, (<i>2</i>) gain control coding, (<i>3</i>) matrix multiplication coding, (<i>4</i>), perceptron coding, (<i>5</i>) 2-layer network, (<i>6</i>) 3-layer network, (<i>7</i>) 4-layer network, (<i>8</i>) 5-layer network, (<i>9</i>) 6-layer network (<i>10</i>) 7-layer network, and (<i>11</i>), 8-layer network.\u00a0The darker a model is, the simpler the model is and the more the model preserves similarity structure under fMRI.\u00a0(<b>B</b>) A deep artificial neural network and the ventral stream can be seen as performing related computations.\u00a0As in our simulation results, neural similarity should be more difficult to recover in the more advanced layers."
                            }
                        ], 
                        "alt": "", 
                        "uri": "https://publishing-cdn.elifesciences.org/21397/elife-21397-fig2-v1.jpg", 
                        "filename": "elife-21397-fig2-v1.jpg"
                    }, 
                    {
                        "type": "section", 
                        "id": "s3-1", 
                        "title": "Vector space coding", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "The first in this line of models considered is vector space coding (i.e., <math id=\"inf107\"><msup><mi>\u211d</mi><mi>n</mi></msup></math>), in which stimuli are represented as a vector of real-valued features.\u00a0Representing concepts in multidimensional spaces has a long and successful history in psychology (<a href=\"#bib82\">Shepard, 1987</a>). For example, in a large space, lions and tigers should be closer to each other than lions and robins because they are more similar.\u00a0The kinds of operations that are naturally done in vector spaces (e.g., additions and multiplications) are particularly well suited to the BOLD response.\u00a0For example, the haemodynamic response to individual stimuli roughly summates across a range of conditions\u00a0(<a href=\"#bib15\">Dale and Buckner, 1997</a>) and this linearity seems to extend to representational patterns (<a href=\"#bib73\">Reddy et al., 2009</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "In this neural coding scheme, each item (e.g., a dog) is represented as the set of values in its input vector (i.e., a set of numbers with range <math id=\"inf108\"><mrow><mo>[</mo><mrow id=\"XM19\"><mo>-</mo><mn>1</mn></mrow><mo>,</mo><mn id=\"XM20\">1</mn><mo>]</mo></mrow></math>).\u00a0This means that for a given stimulus, the representation this model produces is identical to the input.\u00a0In this sense, vector space coding is functionally smooth in a trivial sense as the function is identity.\u00a0As shown in <a href=\"#fig2\">Figure 2</a>, neural similarity gradually falls off with added distortion (i.e., noise).\u00a0Therefore, this very simple coding scheme creates representational spaces that would be successfully detected by fMRI."
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s3-2", 
                        "title": "Gain control coding", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "Building on the basic vector space model, this scheme encodes each input vector by passing it through a monotonic non-linear function, the hyperbolic tangent function (<math id=\"inf109\"><mstyle displaystyle=\"true\" scriptlevel=\"0\"><mrow><mi mathvariant=\"normal\">t</mi><mi mathvariant=\"normal\">a</mi><mi mathvariant=\"normal\">n</mi><mi mathvariant=\"normal\">h</mi></mrow></mstyle></math>), which is functionally smooth.\u00a0This results in each vector element being transformed, or squashed, to values between <math id=\"inf110\"><mrow><mo>[</mo><mrow id=\"XM21\"><mo>-</mo><mn>1</mn></mrow><mo>,</mo><mn id=\"XM22\">1</mn><mo>]</mo></mrow></math>.\u00a0Such functions are required by artificial neural networks (and perhaps the brain) for gain control (<a href=\"#bib70\">Priebe and Ferster, 2002</a>).\u00a0The practical effect of this model is to push the values in the model\u2019s internal representation toward either <math id=\"inf111\"><mrow><mo>-</mo><mn>1</mn></mrow></math> or <math id=\"inf112\"><mn>1</mn></math>.\u00a0As can be seen in <a href=\"#fig2\">Figure 2</a>, neural similarity is well-captured by the gain control neural coding model."
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s3-3", 
                        "title": "Matrix multiplication coding", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "This model performs more sophisticated computations on the input stimuli.\u00a0In line with early connectionism and Rescorla-Wagner modeling of conditioning, this model receives an input vector and performs matrix multiplication on it, i.e., computes the weighted sums of the inputs to pass on to the output layer (<a href=\"#bib43\">Knapp and Anderson, 1984</a>; <a href=\"#bib74\">Rescorla and Wagner, 1972</a>).\u00a0These simple one-layer neural networks can be surprisingly powerful and account for a range of complex behavioral findings (<a href=\"#bib72\">Ramscar et al., 2013</a>).\u00a0As we will see in later subsections, when a non-linearity is added (e.g., <math id=\"inf113\"><mstyle displaystyle=\"true\" scriptlevel=\"0\"><mrow><mi mathvariant=\"normal\">t</mi><mi mathvariant=\"normal\">a</mi><mi mathvariant=\"normal\">n</mi><mi mathvariant=\"normal\">h</mi></mrow></mstyle></math>), one-layer networks can be stacked on one another to build deep networks."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "This neural coding scheme takes an input stimulus (e.g., an image of a dog) and multiplies it by a weight matrix to create an internal representation, as shown in <a href=\"#fig3\">Figure 3</a>. Interestingly, as shown in <a href=\"#fig3\">Figure 3</a>, the internal representation of this coding scheme is completely nonsensical to the human eye and is not super-voxel smooth, yet it successfully preserves similarity structure (see <a href=\"#fig2\">Figure 2</a>). Matrix multiplication maps similar inputs to similar internal representations. In other words, the result is not super-voxel smooth, but it\u00a0is functionally smooth which we conjecture is critical for fMRI to succeed."
                            }, 
                            {
                                "type": "image", 
                                "doi": "10.7554/eLife.21397.006", 
                                "id": "fig3", 
                                "label": "Figure 3.", 
                                "title": "The effect of matrix multiplication followed by the <math id=\"inf114\"><mstyle displaystyle=\"true\" scriptlevel=\"0\"><mrow><mi mathvariant=\"normal\">t</mi><mi mathvariant=\"normal\">a</mi><mi mathvariant=\"normal\">n</mi><mi mathvariant=\"normal\">h</mi></mrow></mstyle></math> function on the input stimulus.\u00a0", 
                                "caption": [
                                    {
                                        "type": "paragraph", 
                                        "text": "The output of this one-layer network is shown, as well as the outcome of applying a non-linearity to the output of the matrix multiplication. In this example, functional smoothness is preserved whereas super-voxel smoothness is not. The result of applying this non-linearity can serve as the input to the next layer of a multi-layer network."
                                    }
                                ], 
                                "alt": "", 
                                "uri": "https://publishing-cdn.elifesciences.org/21397/elife-21397-fig3-v1.jpg", 
                                "filename": "elife-21397-fig3-v1.jpg"
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s3-4", 
                        "title": "Perceptron coding", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "The preceding coding scheme was a single-layer neural network.\u00a0To create multi-layer networks, that are potentially more powerful than an equivalent single-layer network, a non-linearity (such as <math id=\"inf115\"><mstyle displaystyle=\"true\" scriptlevel=\"0\"><mrow><mi mathvariant=\"normal\">t</mi><mi mathvariant=\"normal\">a</mi><mi mathvariant=\"normal\">n</mi><mi mathvariant=\"normal\">h</mi></mrow></mstyle></math>) must be added to each network layer\u00a0post-synaptically.\u00a0Here, we consider a single-layer network with the <math id=\"inf116\"><mstyle displaystyle=\"true\" scriptlevel=\"0\"><mrow><mi mathvariant=\"normal\">t</mi><mi mathvariant=\"normal\">a</mi><mi mathvariant=\"normal\">n</mi><mi mathvariant=\"normal\">h</mi></mrow></mstyle></math> non-linearity included (see <a href=\"#fig3\">Figure 3</a>).\u00a0As with matrix multiplication previously, this neural coding scheme is successful (see <a href=\"#fig2\">Figure 2</a>) with \u2018similar inputs lead[ing] to similar outputs\u2019 (<a href=\"#bib77\">Rummelhart et al., 1995</a>, p. 31)."
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s3-5", 
                        "title": "Multi-layered neural network coding", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "The basic network considered in the previous section can be combined with other networks, creating a potentially more powerful multi-layered network.\u00a0These multi-layered models can be used to capture a stream of processing as is thought to occur for visual input to the ventral stream, shown in <a href=\"#fig2\">Figure 2B</a> (<a href=\"#bib19\">DiCarlo and Cox, 2007</a>; <a href=\"#bib75\">Riesenhuber and Poggio, 1999</a>, <a href=\"#bib76\">2000</a>; <a href=\"#bib71\">Quiroga et al., 2005</a>; <a href=\"#bib91\">Yamins and DiCarlo, 2016</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "In this section, we evaluate whether the similarity preserving properties of single-layer networks extend to deeper, yet still untrained, networks.\u00a0The simulations consider networks with 2 to 8 layers.\u00a0The models operate in a fashion identical to the perceptron neural coding model considered in the previous section.\u00a0The perceptrons are stacked such that the output of a layer serves as the input to the next layer.\u00a0We only perform simulated fMRI on the final layer of each model.\u00a0These simulations consider whether the representations that emerge in multi-layered networks are plausible given the success of fMRI in uncovering similarity spaces see also:\u00a0(<a href=\"#bib13\">Cox et al., 2015</a>; <a href=\"#bib12\">Cowell et al., 2009</a>; <a href=\"#bib21\">Edelman et al., 1998</a>; <a href=\"#bib27\">Goldrick, 2008</a>; <a href=\"#bib51\">Laakso and Cottrell, 2000</a>).\u00a0Such representations, as found in deep artificial neural network architectures, are uncovered by adding layers to discover increasingly more abstract commonalities between inputs (<a href=\"#bib28\">Graves et al., 2013</a>; <a href=\"#bib33\">Hinton et al., 2006</a>; <a href=\"#bib34\">Hinton, 2007</a>; <a href=\"#bib32\">Hinton et al., 2015</a>; <a href=\"#bib52\">LeCun et al., 2015</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "As shown in <a href=\"#fig2\">Figure 2</a>, the deeper the network the less clear the similarity structure becomes.\u00a0However, even the deepest network preserves some level of similarity structure.\u00a0In effect, as layers are added, functional smoothness declines such that small perturbations to the initial input result in final-layer representations that tend to lie in arbitrary corners of the representational space, as the output takes on values that are <math id=\"inf117\"><mrow><mo>+</mo><mn>1</mn></mrow></math> or <math id=\"inf118\"><mrow><mo>-</mo><mn>1</mn></mrow></math> due to <math id=\"inf119\"><mstyle displaystyle=\"true\" scriptlevel=\"0\"><mrow><mi mathvariant=\"normal\">t</mi><mi mathvariant=\"normal\">a</mi><mi mathvariant=\"normal\">n</mi><mi mathvariant=\"normal\">h</mi></mrow></mstyle></math>.\u00a0As layers are added, the network becomes potentially more powerful, but less functionally smooth, which makes it less suitable for analysis by fMRI because the similarity space breaks down.\u00a0In other words, two similar stimuli can engender near orthogonal (i.e., dissimilar) representations at the most advanced layers of these networks. We measured functional smoothness for a large set of random input vectors using <a href=\"#equ1\">Equation 1</a> with Pearson correlation serving as both the similarity measure and measure of proportionality. Consistent with <a href=\"#fig2\">Figure 2</a>\u2019s results, at layer 1 (equivalent to the perceptron coding model) functional smoothness was <math id=\"inf120\"><mstyle displaystyle=\"true\" scriptlevel=\"0\"><mrow><mn>0.86</mn></mrow></mstyle></math>, but declined to <math id=\"inf121\"><mstyle displaystyle=\"true\" scriptlevel=\"0\"><mrow><mn>0.22</mn></mrow></mstyle></math> by the eighth network layer. These values were calculated using all item pairs consisting of a prototype and one of its distortions.\u00a0In the Discussion section, we consider the theoretical significance of these results in tandem with the deep learning network results (next section)."
                            }
                        ]
                    }
                ]
            }, 
            {
                "type": "section", 
                "id": "s4", 
                "title": "Deep learning networks", 
                "content": [
                    {
                        "type": "paragraph", 
                        "text": "Deep learning networks (DLNs) have led to a revolution in machine learning and artificial intelligence (<a href=\"#bib50\">Krizhevsky et al., 2012</a>; <a href=\"#bib53\">LeCun et al., 1998</a>; <a href=\"#bib81\">Serre et al., 2007</a>; <a href=\"#bib86\">Szegedy et al., 2015a</a>).\u00a0DLNs outperform existing approaches on object recognition tasks by training complex multi-layer networks with millions of parameters (i.e., weights) on large databases of natural images.\u00a0Recently, neuroscientists have become interested in how the computations and representations in these models relate to the ventral stream in monkeys and humans (<a href=\"#bib8\">Cadieu et al., 2014</a>; <a href=\"#bib20\">Dubois et al., 2015</a>; <a href=\"#bib30\">Guclu and van Gerven, 2015</a>; <a href=\"#bib35\">Hong et al., 2016</a>; <a href=\"#bib42\">Khaligh-Razavi and Kriegeskorte, 2014</a>; <a href=\"#bib92\">Yamins et al., 2014</a>; <a href=\"#bib91\">Yamins and DiCarlo, 2016</a>). For these reasons, we choose to examine these models, which also allow for RSA at multiple representational levels."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "In this contribution, one key question is whether functional smoothness breaks down at more advanced layers in DLNs as it did in the untrained random neural networks considered in the previous section. We address this question by presenting natural image stimuli (i.e., novel photographs) to a trained DLN, specifically Inception-v3 GoogLeNet (<a href=\"#bib86\">Szegedy et al., 2015b</a>), and applying RSA to evaluate whether the similarity structure of items would be recoverable using fMRI."
                    }, 
                    {
                        "type": "section", 
                        "id": "s4-1", 
                        "title": "Architecture", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "The DLN we consider, Inception-v3 GoogLeNet, is a convolutional neural network (CNN), which is a type of DLN especially adept at classification and recognition of visual inputs. CNNs excel in computer vision, learning from huge amounts of data.\u00a0For example, human-like accuracy on test sets has been achieved by:\u00a0LeNet, a pioneering CNN that identifies handwritten digits (<a href=\"#bib53\">LeCun et al., 1998</a>);\u00a0HMAX, trained to detect objects, e.g., faces, in cluttered environments (<a href=\"#bib81\">Serre et al., 2007</a>);\u00a0and AlexNet, which classifies photographs into <math id=\"inf122\"><mn>1000</mn></math> categories (<a href=\"#bib50\">Krizhevsky et al., 2012</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "The high-level architecture of CNNs consists of many layers (<a href=\"#bib85\">Szegedy et al., 2015a</a>).\u00a0These are stacked on top of each other, in much the same way as the stacked multilevel perceptrons described previously.\u00a0A key difference is that CNNs have more variety especially in breadth (number of units) between layers."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "In many CNNs, some of the network\u2019s layers are convolutional, which contain components that do not receive input from the whole of the previous layer, but a small subset of it (<a href=\"#bib86\">Szegedy et al., 2015b</a>).\u00a0Many convolutional components are required to process the whole of the previous layer by creating an overlapping tiling of small patches.\u00a0Often\u00a0convolutional layers are interleaved with max-pooling layers\u00a0(<a href=\"#bib53\">Lecun et al., 1998</a>), which also contain tile-like components that act as local filters over the previous layer.\u00a0This type of processing and architecture is both empirically driven by what works best, as well as inspired by the visual ventral stream, specifically receptive fields (<a href=\"#bib25\">Fukushima, 1980</a>; <a href=\"#bib37\">Hubel and Wiesel, 1959</a>, <a href=\"#bib38\">1968</a>; <a href=\"#bib81\">Serre et al., 2007</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "Convolutional and max-pooling layers provide a structure that is inherently hierarchical.\u00a0Lower layers perform computations on small localized patches of the input, while deeper layers perform computations on increasingly larger, more global, areas of the stimuli.\u00a0After such localized processing, it is typical to include layers that are fully-connected, i.e., are more classically connectionist.\u00a0And finally, a layer with the required output structure, e.g., units that represent classes or a yes/no response as appropriate."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "Inception-v3 GoogLeNet uses a specific arrangement of these aforementioned layers, connected both in series and in parallel (<a href=\"#bib86\">Szegedy et al., 2015b</a>, <a href=\"#bib85\">2015a</a>, <a href=\"#bib84\">2016</a>).\u00a0In total it has <math id=\"inf123\"><mn>26</mn></math> layers and <math id=\"inf124\"><mn>25</mn></math> million parameters inclusive of connection weights (<a href=\"#bib86\">Szegedy et al., 2015b</a>).\u00a0The final layer is a softmax layer that is trained to activate a single unit per class.\u00a0These units correspond to labels that have been applied to sets of photographs by humans, e.g., \u2018space shuttle\u2019, \u2018ice cream\u2019, \u2018sock\u2019, within the ImageNet database (<a href=\"#bib78\">Russakovsky et al., 2015</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "Inception-v3 GoogLeNet has been trained on millions of human-labeled photographs from <math id=\"inf125\"><mn>1000</mn></math> of ImageNet\u2019s synsets (sets of photographs).\u00a0The <math id=\"inf126\"><mn>1000</mn></math>-unit wide output produced by the network when presented with a photograph represents the probabilities of the input belonging to each of those classes.\u00a0For example, if the network is given a photograph of a moped it may also activate the output unit that corresponds to bicycle with activation <math id=\"inf127\"><mn>0.03</mn></math>.\u00a0This is interpreted as the network expressing the belief that there is a <math id=\"inf128\"><mrow><mn>3</mn><mo lspace=\"0pt\" rspace=\"3.5pt\">%</mo></mrow></math> probability that the appropriate label for the input is \u2018bicycle\u2019.\u00a0In addition, this interpretation is useful because it allows for multiple classes to co-exist within a single input.\u00a0For example, a photo with a guillotine and a wig in it will cause it to activate both corresponding output units.\u00a0Thus the network is held to have learned a distribution of appropriate labels that reflect the most salient items in a scene.\u00a0Inception-v3 GoogLeNet, achieves human levels of accuracy on test sets, producing the correct label in its five most probable guesses approximately <math id=\"inf129\"><mrow><mn>95</mn><mo lspace=\"0pt\" rspace=\"3.5pt\">%</mo></mrow></math> of the time (<a href=\"#bib86\">Szegedy et al., 2015b</a>)."
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s4-2", 
                        "title": "Deep learning network simulation", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "We consider whether functional smoothness declines as inputs are processed by the more advanced layers of Inception-v3 GoogLeNet. If so, fMRI should be less successful in brain regions that instantiate computations analogous to the more advanced layers of such networks. Unlike the previous simulations, we present novel photographs of natural categories to these networks. The key question is whether items from related categories (e.g., banjos and guitars) will be similar at various network layers. The <math id=\"inf130\"><mn>40</mn></math> photographs (i.e., stimuli) are divided equally amongst <math id=\"inf131\"><mn>8</mn></math> subordinate categories: banjos, guitars, mopeds, sportscars, lions, tigers, robins, and partridges, which in turn aggregate into <math id=\"inf132\"><mn>4</mn></math> basic-level categories: musical instruments, vehicles, mammals, and birds; which in turn aggregate into <math id=\"inf133\"><mn>2</mn></math> superordinates: animate and inanimate."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "We consider how similar the internal network representations are for pairs of stimuli by comparing the resulting network activity, which is analogous to comparing neural activity over voxels in RSA. Correlations for all possible pairings of the <math id=\"inf134\"><mn>40</mn></math> stimuli were calculated for both a mid and a later network layer (see <a href=\"#fig4\">Figure 4</a>)."
                            }, 
                            {
                                "type": "image", 
                                "doi": "10.7554/eLife.21397.007", 
                                "id": "fig4", 
                                "label": "Figure 4.", 
                                "title": "Similarity structure becomes more difficult to recover in the more advanced layers of the DLN.", 
                                "caption": [
                                    {
                                        "type": "paragraph", 
                                        "text": "(<b>A</b>) The similarity structure in a middle layer of a DLN, Inception-v3 GoogLeNet. The mammals (lions and tigers) and birds (robins and partridges) correlate forming a high-level domain, rendering the upper-left quadrant a darker shade of red. Whereas the vehicles (sportscars and mopeds) and musical instruments (guitars and banjos) form two high-level categories.\u00a0(<b>B</b>) In contrast, at a later layer in this network, the similarity space shows high within-category correlations and weakened correlations between categories. While some structure between categories is preserved, mopeds are no more similar to sportscars than they are to robins."
                                    }
                                ], 
                                "alt": "", 
                                "uri": "https://publishing-cdn.elifesciences.org/21397/elife-21397-fig4-v1.jpg", 
                                "filename": "elife-21397-fig4-v1.jpg"
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "The middle layer (<a href=\"#fig4\">Figure 4A</a>) reveals cross-category similarity at both the basic and superordinate level. For example, lions are more like robins than guitars.\u00a0However, at the later layer (<a href=\"#fig4\">Figure 4B</a>) the similarity structure has broken down such that subordinate category similarity dominates (i.e., a lion is like another lion, but not so much like a tiger).\u00a0Interestingly, the decline in functional smoothness is not a consequence of sparseness at the later layer as the Gini coefficient, a measure of sparseness (<a href=\"#bib26\">Gini, 1909</a>), is <math id=\"inf135\"><mn>0.947</mn></math> for the earlier middle layer (<a href=\"#fig4\">Figure 4A</a>) and <math id=\"inf136\"><mn>0.579</mn></math> for the later advanced layer (<a href=\"#fig4\">Figure 4B</a>), indicating that network representations are distributed in general and even more so at the later layer. Thus, the decline in functional smoothness at later layers does not appear to be a straightforward consequence of training these networks to classify stimuli, although it would be interesting to compare to unsupervised approaches that can perform\u00a0at equivalent accuracy levels (no such network currently exists)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "These DLN results are directly analogous to those with random untrained networks (see <a href=\"#fig2\">Figure 2</a>).\u00a0In those simulations, similar input patterns mapped to orthogonal (i.e., dissimilar) internal representations in later layers.\u00a0Likewise, the trained DLN at later layers can only capture similarity structure within subordinate categories (e.g., a tiger is like another tiger) which the network was trained to classify.\u00a0The effect of training the network was to create equivalence classes based on the training label (e.g., tiger) such that members of that category are mapped to similar network states.\u00a0Violating functional smoothness, all other similarity structure is discarded such that a tiger is no more similar to a lion than to a banjo from the network\u2019s perspective.\u00a0Should brain regions operate in a similar fashion, fMRI would not be successful in recovering similarity structure therein.\u00a0In the Discussion, we consider the implications of these findings on our understanding of the ventral stream and the prospects for fMRI."
                            }
                        ]
                    }
                ]
            }, 
            {
                "type": "section", 
                "id": "s5", 
                "title": "Discussion", 
                "content": [
                    {
                        "type": "paragraph", 
                        "text": "Neuroscientists would rightly prefer a method that had both excellent spatial and temporal resolution for measuring brain activity. However, as we demonstrate in this article, the fact that fMRI has proven useful in examining neural representations, despite limitations in both its temporal and spatial resolution, says something about the nature of the neural code. One general conclusion is that the neural code must be smooth, both at voxel (such that voxel responses are inhomogeneous across time and space) and functional levels."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "The latter notion of smoothness is often overlooked or confused with super-voxel smoothness, but is necessary for fMRI to recover similarity spaces in the brain. Coding schemes, such as factorial and hash coding, are useful in numerous real-world applications and have an inverse function (i.e., one can go backwards from the internal representation to recover the unique stimulus input).\u00a0However, these schemes are incompatible with the success of fMRI because they are not functionally smooth. For example, if the brain solely used such coding schemes, the neural representation of a robin would be no more similar to that of a sparrow than to that of a car.\u00a0The fact that such neural similarities are recoverable by fMRI suggests that the neural code differs from these schemes in many cases."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "In contrast, we found that the types of representations used and generated by artificial neural networks, including deep learning networks, are broadly compatible with the success of fMRI in assessing neural representations. These coding schemes are functionally smooth in that similar inputs tend toward similar outputs, which allows item similarity to be reflected in neural similarity (as measured by fMRI). However, we found that functional smoothness breaks down as additional network layers are added. Specifically, we have shown that multi-layer networks eventually converge to something akin to a hash function, as arbitrary locations in memory correspond to categories of inputs."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "These results take on additional significance given the recent interest in deep artificial neural networks as computational accounts of the ventral stream.\u00a0One emerging view is that the more advanced the layers of these models correspond to more advanced regions along the ventral stream (<a href=\"#bib8\">Cadieu et al., 2014-12</a>; <a href=\"#bib20\">Dubois et al., 2015</a>; <a href=\"#bib30\">Guclu and van Gerven, 2015</a>; <a href=\"#bib35\">Hong et al., 2016</a>; <a href=\"#bib42\">Khaligh-Razavi and Kriegeskorte, 2014</a>; <a href=\"#bib92\">Yamins et al., 2014</a>; <a href=\"#bib91\">Yamins and DiCarlo, 2016</a>)."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "If this viewpoint is correct, our results indicate that neural representations should progressively become less functionally smooth and more abstract as one moves along the ventral stream (recall <a href=\"#fig2\">Figure 2</a>).\u00a0Indeed, neural representations appear to become more abstract, encoding whole concepts or categories, as a function of how far along the ventral stream they are located (<a href=\"#bib7\">Bracci and Op de Beeck, 2016</a>; <a href=\"#bib19\">DiCarlo and Cox, 2007</a>; <a href=\"#bib75\">Riesenhuber and Poggio, 1999</a>, <a href=\"#bib76\">2000</a>; <a href=\"#bib91\">Yamins and DiCarlo, 2016</a>).\u00a0For example, early on in visual processing, the brain may extract so-called basic features, such as in broadly-tuned orientation columns (<a href=\"#bib37\">Hubel and Wiesel, 1959</a>, <a href=\"#bib38\">1968</a>).\u00a0In contrast, later on in processing, cells may selectively respond to particular individual stimulus classes i.e., Jennifer Aniston, grandmother, concept, or gnostic cells (<a href=\"#bib29\">Gross, 2002</a>; <a href=\"#bib46\">Konorski, 1967</a>; <a href=\"#bib71\">Quiroga et al., 2005</a>), irrespective of orientation, etc."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "Likewise, we found that Inception-v3 GoogLeNet\u2019s representations became symbol-like at advanced network layers such that items sharing a category label (e.g., tigers) engendered related network states, while items in other categories engendered orthogonal states (recall <a href=\"#fig4\">Figure 4</a>).\u00a0Our simulations of random networks also found reduced functional smoothness at advanced network layers, suggesting a basic geometric property of multi-layer networks.\u00a0The effect of training seems limited to creating network states in which stimuli that share the same label (e.g., multiple viewpoints of Jennifer Aniston) become similar and items from all other categories (even if conceptually related) become orthogonal.\u00a0If so, areas further along the ventral stream should prove less amenable to imaging (recall <a href=\"#fig2\">Figure 2</a>).\u00a0Indeed, a recent object recognition study found that the ceiling on observable correlation values becomes lower as one moves along the ventral stream (<a href=\"#bib7\">Bracci and Op de Beeck, 2016</a>)."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "Here, we focused on using fMRI to recover non-degenerate similarity spaces (i.e., where there are similarities beyond self-similarities). However, functional smoothness is also important for other analysis approaches. For example, MVPA decoders trained to classify items (e.g., is a house or a face being shown?) based on fMRI activity will only generalize to novel stimuli when functional smoothness holds. Likewise, univariate clusters (e.g., a house or face area) will most likely be found and generalize to novel stimuli when functional smoothness holds because functional smoothness implies similar activation profiles for similar stimuli. Functional smoothness should be an important factor in determining how well classifiers perform and how statistically robust univariate clusters of voxels are."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "In cognitive science, research is often divided into levels of analysis.\u00a0In Marr\u2019s levels, the top level is the problem description, the middle level captures how the problem is solved, and bottom level concerns how the solution is implemented in the brain (<a href=\"#bib60\">Marr, 1982</a>).\u00a0Given that the \u2018how\u2019 and \u2018where\u2019 of cognition appear to be merging, some have questioned the utility of this tripartite division (<a href=\"#bib56\">Love, 2015</a>)."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "Our results suggest another inadequacy of these three levels of description, namely that the implementation level itself should be further subdivided.\u00a0What is measured by fMRI is at a vastly more abstract scale than what can be measured in the brain.\u00a0For example, major efforts, like the European Human Brain Project and the Machine Intelligence from Cortical Networks project (<a href=\"#bib89\">Underwood, 2016</a>), are chiefly concerned with fine-grained aspects of the brain that are outside the reach of fMRI (<a href=\"#bib11\">Chi, 2016</a>; <a href=\"#bib24\">Fr\u00e9gnac and Laurent, 2014</a>).\u00a0Likewise, models of spiking neurons e.g., (<a href=\"#bib90\">Wong and Wang, 2006</a>) are at a level of analysis lower than where fMRI applies."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "Nevertheless, fMRI has proven useful in understanding neural representations that are consequential to behavior.\u00a0Perhaps this success suggests that the appropriate level for relating brain to behavior is close to what fMRI measures.\u00a0This does not mean lower-level efforts do not have utility when the details are of interest.\u00a0However, fMRI\u2019s success might mean that when one is interested in the nature of computations carried out by the brain, the level of analysis where fMRI applies may be preferred.\u00a0To draw an analogy, one could construct a theory of macroeconomics based on quantum physics, but it would be incredibly cumbersome and no more predictive nor explanatory than a theory that contained abstract concepts such as money and supply.\u00a0Reductionism, while seductive, is not always the best path forward."
                    }
                ]
            }
        ], 
        "references": [
            {
                "type": "journal", 
                "id": "bib1", 
                "date": "1926", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "ED Adrian", 
                            "index": "Adrian, ED"
                        }
                    }
                ], 
                "articleTitle": "The impulses produced by sensory nerve endings: Part I", 
                "journal": "The Journal of Physiology", 
                "volume": "61", 
                "pages": {
                    "first": "49", 
                    "last": "72", 
                    "range": "49\u201372"
                }, 
                "doi": "10.1113/jphysiol.1926.sp002273", 
                "pmid": 16993776
            }, 
            {
                "type": "unknown", 
                "id": "bib2", 
                "date": "2013", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Alink", 
                            "index": "Alink, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Krugliak", 
                            "index": "Krugliak, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Walther", 
                            "index": "Walther, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "N Kriegeskorte", 
                            "index": "Kriegeskorte, N"
                        }
                    }
                ], 
                "title": "fMRI orientation decoding in V1 does not require global maps or globally coherent orientation stimuli", 
                "details": "Frontiers in Psychology, 4, 10.3389/fpsyg.2013.00493, 23964251"
            }, 
            {
                "type": "journal", 
                "id": "bib3", 
                "date": "2009", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "BM Ances", 
                            "index": "Ances, BM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "CL Liang", 
                            "index": "Liang, CL"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "O Leontiev", 
                            "index": "Leontiev, O"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JE Perthen", 
                            "index": "Perthen, JE"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AS Fleisher", 
                            "index": "Fleisher, AS"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AE Lansing", 
                            "index": "Lansing, AE"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RB Buxton", 
                            "index": "Buxton, RB"
                        }
                    }
                ], 
                "articleTitle": "Effects of aging on cerebral blood flow, oxygen metabolism, and blood oxygenation level dependent responses to visual stimulation", 
                "journal": "Human Brain Mapping", 
                "volume": "30", 
                "pages": {
                    "first": "1120", 
                    "last": "1132", 
                    "range": "1120\u20131132"
                }, 
                "doi": "10.1002/hbm.20574", 
                "pmid": 18465743
            }, 
            {
                "type": "journal", 
                "id": "bib4", 
                "date": "2006", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "BB Averbeck", 
                            "index": "Averbeck, BB"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "PE Latham", 
                            "index": "Latham, PE"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Pouget", 
                            "index": "Pouget, A"
                        }
                    }
                ], 
                "articleTitle": "Neural correlations, population coding and computation", 
                "journal": "Nature Reviews Neuroscience", 
                "volume": "7", 
                "pages": {
                    "first": "358", 
                    "last": "366", 
                    "range": "358\u2013366"
                }, 
                "doi": "10.1038/nrn1888", 
                "pmid": 16760916
            }, 
            {
                "type": "journal", 
                "id": "bib5", 
                "date": "1997", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JR Binder", 
                            "index": "Binder, JR"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JA Frost", 
                            "index": "Frost, JA"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "TA Hammeke", 
                            "index": "Hammeke, TA"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RW Cox", 
                            "index": "Cox, RW"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "SM Rao", 
                            "index": "Rao, SM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "T Prieto", 
                            "index": "Prieto, T"
                        }
                    }
                ], 
                "articleTitle": "Human brain language areas identified by functional magnetic resonance imaging", 
                "journal": "Journal of Neuroscience", 
                "volume": "17", 
                "pages": {
                    "first": "353", 
                    "last": "362", 
                    "range": "353\u2013362"
                }, 
                "pmid": 8987760
            }, 
            {
                "type": "journal", 
                "id": "bib6", 
                "date": "1996", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "GM Boynton", 
                            "index": "Boynton, GM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "SA Engel", 
                            "index": "Engel, SA"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "GH Glover", 
                            "index": "Glover, GH"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DJ Heeger", 
                            "index": "Heeger, DJ"
                        }
                    }
                ], 
                "articleTitle": "Linear systems analysis of functional magnetic resonance imaging in human V1", 
                "journal": "Journal of Neuroscience", 
                "volume": "16", 
                "pages": {
                    "first": "4207", 
                    "last": "4221", 
                    "range": "4207\u20134221"
                }, 
                "pmid": 8753882
            }, 
            {
                "type": "journal", 
                "id": "bib7", 
                "date": "2016", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Bracci", 
                            "index": "Bracci, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "H Op de Beeck", 
                            "index": "Op de Beeck, H"
                        }
                    }
                ], 
                "articleTitle": "Dissociations and associations between shape and category representations in the two visual pathways", 
                "journal": "Journal of Neuroscience", 
                "volume": "36", 
                "pages": {
                    "first": "432", 
                    "last": "444", 
                    "range": "432\u2013444"
                }, 
                "doi": "10.1523/JNEUROSCI.2314-15.2016", 
                "pmid": 26758835
            }, 
            {
                "type": "journal", 
                "id": "bib8", 
                "date": "2014", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "CF Cadieu", 
                            "index": "Cadieu, CF"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "H Hong", 
                            "index": "Hong, H"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DL Yamins", 
                            "index": "Yamins, DL"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "N Pinto", 
                            "index": "Pinto, N"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "D Ardila", 
                            "index": "Ardila, D"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "EA Solomon", 
                            "index": "Solomon, EA"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "NJ Majaj", 
                            "index": "Majaj, NJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JJ DiCarlo", 
                            "index": "DiCarlo, JJ"
                        }
                    }
                ], 
                "articleTitle": "Deep neural networks rival the representation of primate IT cortex for core visual object recognition", 
                "journal": "PLoS Computational Biology", 
                "volume": "10", 
                "pages": "e1003963", 
                "doi": "10.1371/journal.pcbi.1003963", 
                "pmid": 25521294
            }, 
            {
                "type": "journal", 
                "id": "bib9", 
                "date": "2012", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "J Carp", 
                            "index": "Carp, J"
                        }
                    }
                ], 
                "articleTitle": "The secret lives of experiments: methods reporting in the fMRI literature", 
                "journal": "NeuroImage", 
                "volume": "63", 
                "pages": {
                    "first": "289", 
                    "last": "300", 
                    "range": "289\u2013300"
                }, 
                "doi": "10.1016/j.neuroimage.2012.07.004", 
                "pmid": 22796459
            }, 
            {
                "type": "journal", 
                "id": "bib10", 
                "date": "2011", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "D Chaimow", 
                            "index": "Chaimow, D"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "E Yacoub", 
                            "index": "Yacoub, E"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "K Ugurbil", 
                            "index": "Ugurbil, K"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Shmuel", 
                            "index": "Shmuel, A"
                        }
                    }
                ], 
                "articleTitle": "Modeling and analysis of mechanisms underlying fMRI-based decoding of information conveyed in cortical columns", 
                "journal": "NeuroImage", 
                "volume": "56", 
                "pages": {
                    "first": "627", 
                    "last": "642", 
                    "range": "627\u2013642"
                }, 
                "doi": "10.1016/j.neuroimage.2010.09.037", 
                "pmid": 20868757
            }, 
            {
                "type": "journal", 
                "id": "bib11", 
                "date": "2016", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "KR Chi", 
                            "index": "Chi, KR"
                        }
                    }
                ], 
                "articleTitle": "Neural modelling: Abstractions of the mind", 
                "journal": "Nature", 
                "volume": "531", 
                "pages": {
                    "first": "S16", 
                    "last": "S17", 
                    "range": "S16\u2013S17"
                }, 
                "doi": "10.1038/531S16a", 
                "pmid": 26934521
            }, 
            {
                "type": "conference-proceeding", 
                "id": "bib12", 
                "date": "2009", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RA Cowell", 
                            "index": "Cowell, RA"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DE Huber", 
                            "index": "Huber, DE"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "GW Cottrell", 
                            "index": "Cottrell, GW"
                        }
                    }
                ], 
                "articleTitle": "Virtual brain reading: A connectionist approach to understanding fMRI", 
                "conference": {
                    "name": [
                        "In 31st Annual Meeting of the Cognitive Science Society"
                    ]
                }
            }, 
            {
                "type": "journal", 
                "id": "bib13", 
                "date": "2015", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "CR Cox", 
                            "index": "Cox, CR"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "MS Seidenberg", 
                            "index": "Seidenberg, MS"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "TT Rogers", 
                            "index": "Rogers, TT"
                        }
                    }
                ], 
                "articleTitle": "Connecting functional brain imaging and parallel distributed processing", 
                "journal": "Language, Cognition and Neuroscience", 
                "volume": "30", 
                "pages": {
                    "first": "380", 
                    "last": "394", 
                    "range": "380\u2013394"
                }, 
                "doi": "10.1080/23273798.2014.994010"
            }, 
            {
                "type": "journal", 
                "id": "bib14", 
                "date": "2003", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DD Cox", 
                            "index": "Cox, DD"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RL Savoy", 
                            "index": "Savoy, RL"
                        }
                    }
                ], 
                "articleTitle": "Functional magnetic resonance imaging (fMRI) \"brain reading\": detecting and classifying distributed patterns of fMRI activity in human visual cortex", 
                "journal": "NeuroImage", 
                "volume": "19", 
                "pages": {
                    "first": "261", 
                    "last": "270", 
                    "range": "261\u2013270"
                }, 
                "doi": "10.1016/S1053-8119(03)00049-1", 
                "pmid": 12814577
            }, 
            {
                "type": "journal", 
                "id": "bib15", 
                "date": "1997", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AM Dale", 
                            "index": "Dale, AM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RL Buckner", 
                            "index": "Buckner, RL"
                        }
                    }
                ], 
                "articleTitle": "Selective averaging of rapidly presented individual trials using fMRI", 
                "journal": "Human Brain Mapping", 
                "volume": "5", 
                "pages": {
                    "first": "329", 
                    "last": "340", 
                    "range": "329\u2013340"
                }, 
                "doi": "10.1002/(SICI)1097-0193(1997)5:5<329::AID-HBM1>3.0.CO;2-5", 
                "pmid": 20408237
            }, 
            {
                "type": "journal", 
                "id": "bib16", 
                "date": "2005", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "C Davatzikos", 
                            "index": "Davatzikos, C"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "K Ruparel", 
                            "index": "Ruparel, K"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Y Fan", 
                            "index": "Fan, Y"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DG Shen", 
                            "index": "Shen, DG"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Acharyya", 
                            "index": "Acharyya, M"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JW Loughead", 
                            "index": "Loughead, JW"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RC Gur", 
                            "index": "Gur, RC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DD Langleben", 
                            "index": "Langleben, DD"
                        }
                    }
                ], 
                "articleTitle": "Classifying spatial patterns of brain activity with machine learning methods: application to lie detection", 
                "journal": "NeuroImage", 
                "volume": "28", 
                "pages": {
                    "first": "663", 
                    "last": "668", 
                    "range": "663\u2013668"
                }, 
                "doi": "10.1016/j.neuroimage.2005.08.009", 
                "pmid": 16169252
            }, 
            {
                "type": "journal", 
                "id": "bib17", 
                "date": "2014", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "T Davis", 
                            "index": "Davis, T"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "G Xue", 
                            "index": "Xue, G"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "BC Love", 
                            "index": "Love, BC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AR Preston", 
                            "index": "Preston, AR"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RA Poldrack", 
                            "index": "Poldrack, RA"
                        }
                    }
                ], 
                "articleTitle": "Global neural pattern similarity as a common basis for categorization and recognition memory", 
                "journal": "Journal of Neuroscience", 
                "volume": "34", 
                "pages": {
                    "first": "7472", 
                    "last": "7484", 
                    "range": "7472\u20137484"
                }, 
                "doi": "10.1523/JNEUROSCI.3376-13.2014", 
                "pmid": 24872552
            }, 
            {
                "type": "journal", 
                "id": "bib18", 
                "date": "2008", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "F De Martino", 
                            "index": "De Martino, F"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "G Valente", 
                            "index": "Valente, G"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "N Staeren", 
                            "index": "Staeren, N"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "J Ashburner", 
                            "index": "Ashburner, J"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Goebel", 
                            "index": "Goebel, R"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "E Formisano", 
                            "index": "Formisano, E"
                        }
                    }
                ], 
                "articleTitle": "Combining multivariate voxel selection and support vector machines for mapping and classification of fMRI spatial patterns", 
                "journal": "NeuroImage", 
                "volume": "43", 
                "pages": {
                    "first": "44", 
                    "last": "58", 
                    "range": "44\u201358"
                }, 
                "doi": "10.1016/j.neuroimage.2008.06.037", 
                "pmid": 18672070
            }, 
            {
                "type": "journal", 
                "id": "bib19", 
                "date": "2007", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JJ DiCarlo", 
                            "index": "DiCarlo, JJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DD Cox", 
                            "index": "Cox, DD"
                        }
                    }
                ], 
                "articleTitle": "Untangling invariant object recognition", 
                "journal": "Trends in Cognitive Sciences", 
                "volume": "11", 
                "pages": {
                    "first": "333", 
                    "last": "341", 
                    "range": "333\u2013341"
                }, 
                "doi": "10.1016/j.tics.2007.06.010", 
                "pmid": 17631409
            }, 
            {
                "type": "journal", 
                "id": "bib20", 
                "date": "2015", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "J Dubois", 
                            "index": "Dubois, J"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AO de Berker", 
                            "index": "de Berker, AO"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DY Tsao", 
                            "index": "Tsao, DY"
                        }
                    }
                ], 
                "articleTitle": "Single-unit recordings in the macaque face patch system reveal limitations of fMRI MVPA", 
                "journal": "Journal of Neuroscience", 
                "volume": "35", 
                "pages": {
                    "first": "2791", 
                    "last": "2802", 
                    "range": "2791\u20132802"
                }, 
                "doi": "10.1523/JNEUROSCI.4037-14.2015", 
                "pmid": 25673866
            }, 
            {
                "type": "journal", 
                "id": "bib21", 
                "date": "1998", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Edelman", 
                            "index": "Edelman, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "K Grill-Spector", 
                            "index": "Grill-Spector, K"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "T Kushnir", 
                            "index": "Kushnir, T"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Malach", 
                            "index": "Malach, R"
                        }
                    }
                ], 
                "articleTitle": "Toward direct visualization of the internal shape representation space by fMRI", 
                "journal": "Psychobiology", 
                "volume": "26", 
                "pages": {
                    "first": "309", 
                    "last": "321", 
                    "range": "309\u2013321"
                }
            }, 
            {
                "type": "journal", 
                "id": "bib22", 
                "date": "1947", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "U Fano", 
                            "index": "Fano, U"
                        }
                    }
                ], 
                "articleTitle": "Ionization yield of radiations. II. The fluctuations of the number of ions", 
                "journal": "Physical Review", 
                "volume": "72", 
                "pages": {
                    "first": "26", 
                    "last": "29", 
                    "range": "26\u201329"
                }, 
                "doi": "10.1103/PhysRev.72.26"
            }, 
            {
                "type": "journal", 
                "id": "bib23", 
                "date": "2011", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "J Freeman", 
                            "index": "Freeman, J"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "GJ Brouwer", 
                            "index": "Brouwer, GJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DJ Heeger", 
                            "index": "Heeger, DJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "EP Merriam", 
                            "index": "Merriam, EP"
                        }
                    }
                ], 
                "articleTitle": "Orientation decoding depends on maps, not columns", 
                "journal": "Journal of Neuroscience", 
                "volume": "31", 
                "pages": {
                    "first": "4792", 
                    "last": "4804", 
                    "range": "4792\u20134804"
                }, 
                "doi": "10.1523/JNEUROSCI.5160-10.2011", 
                "pmid": 21451017
            }, 
            {
                "type": "journal", 
                "id": "bib24", 
                "date": "2014", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Y Fr\u00e9gnac", 
                            "index": "Fr\u00e9gnac, Y"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "G Laurent", 
                            "index": "Laurent, G"
                        }
                    }
                ], 
                "articleTitle": "Neuroscience: Where is the brain in the human brain project?", 
                "journal": "Nature", 
                "volume": "513", 
                "pages": {
                    "first": "27", 
                    "last": "29", 
                    "range": "27\u201329"
                }, 
                "doi": "10.1038/513027a", 
                "pmid": 25186884
            }, 
            {
                "type": "journal", 
                "id": "bib25", 
                "date": "1980", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "K Fukushima", 
                            "index": "Fukushima, K"
                        }
                    }
                ], 
                "articleTitle": "Neocognitron: a self organizing neural network model for a mechanism of pattern recognition unaffected by shift in position", 
                "journal": "Biological Cybernetics", 
                "volume": "36", 
                "pages": {
                    "first": "193", 
                    "last": "202", 
                    "range": "193\u2013202"
                }, 
                "doi": "10.1007/BF00344251", 
                "pmid": 7370364
            }, 
            {
                "type": "journal", 
                "id": "bib26", 
                "date": "1909", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "C Gini", 
                            "index": "Gini, C"
                        }
                    }
                ], 
                "articleTitle": "Il diverso accrescimento delle classi sociali e la concentrazione della ricchezza", 
                "journal": "Giornale Degli Economisti", 
                "volume": "38", 
                "pages": {
                    "first": "27", 
                    "last": "83", 
                    "range": "27\u201383"
                }
            }, 
            {
                "type": "journal", 
                "id": "bib27", 
                "date": "2008", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Goldrick", 
                            "index": "Goldrick, M"
                        }
                    }
                ], 
                "articleTitle": "Does like attract like? Exploring the relationship between errors and representational structure in connectionist networks", 
                "journal": "Cognitive Neuropsychology", 
                "volume": "25", 
                "pages": {
                    "first": "287", 
                    "last": "313", 
                    "range": "287\u2013313"
                }, 
                "doi": "10.1080/02643290701417939", 
                "pmid": 18568818
            }, 
            {
                "type": "conference-proceeding", 
                "id": "bib28", 
                "date": "2013", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Graves", 
                            "index": "Graves, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Mohamed", 
                            "index": "Mohamed, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "G Hinton", 
                            "index": "Hinton, G"
                        }
                    }
                ], 
                "articleTitle": "Speech recognition with deep recurrent neural networks", 
                "conference": {
                    "name": [
                        "2013 IEEE International Conference on Acoustics, Speech and Signal Processing"
                    ]
                }, 
                "pages": {
                    "first": "6645", 
                    "last": "6649", 
                    "range": "6645\u20136649"
                }, 
                "doi": "10.1109/ICASSP.2013.6638947", 
                "uri": "https://doi.org/10.1109/ICASSP.2013.6638947"
            }, 
            {
                "type": "journal", 
                "id": "bib29", 
                "date": "2002", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "CG Gross", 
                            "index": "Gross, CG"
                        }
                    }
                ], 
                "articleTitle": "Genealogy of the \"grandmother cell\"", 
                "journal": "The Neuroscientist", 
                "volume": "8", 
                "pages": {
                    "first": "512", 
                    "last": "518", 
                    "range": "512\u2013518"
                }, 
                "doi": "10.1177/107385802237175", 
                "pmid": 12374433
            }, 
            {
                "type": "journal", 
                "id": "bib30", 
                "date": "2015", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "U G\u00fc\u00e7l\u00fc", 
                            "index": "G\u00fc\u00e7l\u00fc, U"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "MA van Gerven", 
                            "index": "van Gerven, MA"
                        }
                    }
                ], 
                "articleTitle": "Deep neural networks reveal a gradient in the complexity of neural representations across the ventral stream", 
                "journal": "Journal of Neuroscience", 
                "volume": "35", 
                "pages": {
                    "first": "10005", 
                    "last": "10014", 
                    "range": "10005\u201310014"
                }, 
                "doi": "10.1523/JNEUROSCI.5023-14.2015", 
                "pmid": 26157000
            }, 
            {
                "type": "journal", 
                "id": "bib31", 
                "date": "1966", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AG Hanlon", 
                            "index": "Hanlon, AG"
                        }
                    }
                ], 
                "articleTitle": "Content-Addressable and associative memory systems a survey", 
                "journal": "IEEE Transactions on Electronic Computers", 
                "volume": "EC-15", 
                "pages": {
                    "first": "509", 
                    "last": "521", 
                    "range": "509\u2013521"
                }, 
                "doi": "10.1109/PGEC.1966.264358"
            }, 
            {
                "type": "preprint", 
                "id": "bib32", 
                "date": "2015", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "G Hinton", 
                            "index": "Hinton, G"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "O Vinyals", 
                            "index": "Vinyals, O"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "J Dean", 
                            "index": "Dean, J"
                        }
                    }
                ], 
                "articleTitle": "Distilling the knowledge in a neural network", 
                "source": "arXiv", 
                "uri": "https://arxiv.org/abs/1503.02531"
            }, 
            {
                "type": "journal", 
                "id": "bib33", 
                "date": "2006", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "GE Hinton", 
                            "index": "Hinton, GE"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Osindero", 
                            "index": "Osindero, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "YW Teh", 
                            "index": "Teh, YW"
                        }
                    }
                ], 
                "articleTitle": "A fast learning algorithm for deep belief nets", 
                "journal": "Neural Computation", 
                "volume": "18", 
                "pages": {
                    "first": "1527", 
                    "last": "1554", 
                    "range": "1527\u20131554"
                }, 
                "doi": "10.1162/neco.2006.18.7.1527", 
                "pmid": 16764513
            }, 
            {
                "type": "journal", 
                "id": "bib34", 
                "date": "2007", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "GE Hinton", 
                            "index": "Hinton, GE"
                        }
                    }
                ], 
                "articleTitle": "Learning multiple layers of representation", 
                "journal": "Trends in Cognitive Sciences", 
                "volume": "11", 
                "pages": {
                    "first": "428", 
                    "last": "434", 
                    "range": "428\u2013434"
                }, 
                "doi": "10.1016/j.tics.2007.09.004", 
                "pmid": 17921042
            }, 
            {
                "type": "journal", 
                "id": "bib35", 
                "date": "2016", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "H Hong", 
                            "index": "Hong, H"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DL Yamins", 
                            "index": "Yamins, DL"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "NJ Majaj", 
                            "index": "Majaj, NJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JJ DiCarlo", 
                            "index": "DiCarlo, JJ"
                        }
                    }
                ], 
                "articleTitle": "Explicit information for category-orthogonal object properties increases along the ventral stream", 
                "journal": "Nature Neuroscience", 
                "volume": "19", 
                "pages": {
                    "first": "613", 
                    "last": "622", 
                    "range": "613\u2013622"
                }, 
                "doi": "10.1038/nn.4247", 
                "pmid": 26900926
            }, 
            {
                "type": "journal", 
                "id": "bib36", 
                "date": "1982", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JJ Hopfield", 
                            "index": "Hopfield, JJ"
                        }
                    }
                ], 
                "articleTitle": "Neural networks and physical systems with emergent collective computational abilities", 
                "journal": "PNAS", 
                "volume": "79", 
                "pages": {
                    "first": "2554", 
                    "last": "2558", 
                    "range": "2554\u20132558"
                }, 
                "doi": "10.1073/pnas.79.8.2554", 
                "pmid": 6953413
            }, 
            {
                "type": "journal", 
                "id": "bib37", 
                "date": "1959", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DH Hubel", 
                            "index": "Hubel, DH"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "TN Wiesel", 
                            "index": "Wiesel, TN"
                        }
                    }
                ], 
                "articleTitle": "Receptive fields of single neurones in the cat's striate cortex", 
                "journal": "The Journal of Physiology", 
                "volume": "148", 
                "pages": {
                    "first": "574", 
                    "last": "591", 
                    "range": "574\u2013591"
                }, 
                "doi": "10.1113/jphysiol.1959.sp006308", 
                "pmid": 14403679
            }, 
            {
                "type": "journal", 
                "id": "bib38", 
                "date": "1968", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DH Hubel", 
                            "index": "Hubel, DH"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "TN Wiesel", 
                            "index": "Wiesel, TN"
                        }
                    }
                ], 
                "articleTitle": "Receptive fields and functional architecture of monkey striate cortex", 
                "journal": "The Journal of Physiology", 
                "volume": "195", 
                "pages": {
                    "first": "215", 
                    "last": "243", 
                    "range": "215\u2013243"
                }, 
                "doi": "10.1113/jphysiol.1968.sp008455", 
                "pmid": 4966457
            }, 
            {
                "type": "book", 
                "id": "bib39", 
                "date": "2009", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "SA Huettel", 
                            "index": "Huettel, SA"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AW Song", 
                            "index": "Song, AW"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "G McCarthy", 
                            "index": "McCarthy, G"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "SA Huettel", 
                            "index": "Huettel, SA"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AW Song", 
                            "index": "Song, AW"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "G McCarthy", 
                            "index": "McCarthy, G"
                        }
                    }
                ], 
                "bookTitle": "Functional Magnetic Resonance Imaging", 
                "publisher": {
                    "name": [
                        "Sunauer Associates"
                    ]
                }
            }, 
            {
                "type": "journal", 
                "id": "bib40", 
                "date": "2005", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Y Kamitani", 
                            "index": "Kamitani, Y"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "F Tong", 
                            "index": "Tong, F"
                        }
                    }
                ], 
                "articleTitle": "Decoding the visual and subjective contents of the human brain", 
                "journal": "Nature Neuroscience", 
                "volume": "8", 
                "pages": {
                    "first": "679", 
                    "last": "685", 
                    "range": "679\u2013685"
                }, 
                "doi": "10.1038/nn1444", 
                "pmid": 15852014
            }, 
            {
                "type": "journal", 
                "id": "bib41", 
                "date": "1996", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "SM Katz", 
                            "index": "Katz, SM"
                        }
                    }
                ], 
                "articleTitle": "Distribution of content words and phrases in text and language modelling", 
                "journal": "Natural Language Engineering", 
                "volume": "2", 
                "pages": {
                    "first": "15", 
                    "last": "59", 
                    "range": "15\u201359"
                }, 
                "doi": "10.1017/S1351324996001246"
            }, 
            {
                "type": "journal", 
                "id": "bib42", 
                "date": "2014", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "SM Khaligh-Razavi", 
                            "index": "Khaligh-Razavi, SM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "N Kriegeskorte", 
                            "index": "Kriegeskorte, N"
                        }
                    }
                ], 
                "articleTitle": "Deep supervised, but not unsupervised, models may explain IT cortical representation", 
                "journal": "PLoS Computational Biology", 
                "volume": "10", 
                "pages": "e1003915", 
                "doi": "10.1371/journal.pcbi.1003915", 
                "pmid": 25375136
            }, 
            {
                "type": "journal", 
                "id": "bib43", 
                "date": "1984", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AG Knapp", 
                            "index": "Knapp, AG"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JA Anderson", 
                            "index": "Anderson, JA"
                        }
                    }
                ], 
                "articleTitle": "Theory of categorization based on distributed memory storage", 
                "journal": "Journal of Experimental Psychology: Learning, Memory, and Cognition", 
                "volume": "10", 
                "pages": {
                    "first": "616", 
                    "last": "637", 
                    "range": "616\u2013637"
                }, 
                "doi": "10.1037/0278-7393.10.4.616"
            }, 
            {
                "type": "journal", 
                "id": "bib44", 
                "date": "1975", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "GD Knott", 
                            "index": "Knott, GD"
                        }
                    }
                ], 
                "articleTitle": "Hashing functions", 
                "journal": "The Computer Journal", 
                "volume": "18", 
                "pages": {
                    "first": "265", 
                    "last": "278", 
                    "range": "265\u2013278"
                }, 
                "doi": "10.1093/comjnl/18.3.265"
            }, 
            {
                "type": "book", 
                "id": "bib45", 
                "date": "1987", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "T Kohonen", 
                            "index": "Kohonen, T"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "TS Huang", 
                            "index": "Huang, TS"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "MR Schroeder", 
                            "index": "Schroeder, MR"
                        }
                    }
                ], 
                "bookTitle": "Content-Addressable Memories", 
                "publisher": {
                    "name": [
                        "Springer-Verlag"
                    ]
                }, 
                "doi": "10.1007/978-3-642-83056-3"
            }, 
            {
                "type": "book", 
                "id": "bib46", 
                "date": "1967", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "J Konorski", 
                            "index": "Konorski, J"
                        }
                    }
                ], 
                "bookTitle": "Integrative Activity of the Brain", 
                "publisher": {
                    "name": [
                        "University of Chicago Press"
                    ]
                }
            }, 
            {
                "type": "journal", 
                "id": "bib47", 
                "date": "2010", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "N Kriegeskorte", 
                            "index": "Kriegeskorte, N"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Cusack", 
                            "index": "Cusack, R"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "P Bandettini", 
                            "index": "Bandettini, P"
                        }
                    }
                ], 
                "articleTitle": "How does an fMRI voxel sample the neuronal activity pattern: compact-kernel or complex spatiotemporal filter?", 
                "journal": "NeuroImage", 
                "volume": "49", 
                "pages": {
                    "first": "1965", 
                    "last": "1976", 
                    "range": "1965\u20131976"
                }, 
                "doi": "10.1016/j.neuroimage.2009.09.059", 
                "pmid": 19800408
            }, 
            {
                "type": "journal", 
                "id": "bib48", 
                "date": "2008", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "N Kriegeskorte", 
                            "index": "Kriegeskorte, N"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Mur", 
                            "index": "Mur, M"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "P Bandettini", 
                            "index": "Bandettini, P"
                        }
                    }
                ], 
                "articleTitle": "Representational similarity analysis - connecting the branches of systems neuroscience", 
                "journal": "Frontiers in Systems Neuroscience", 
                "volume": "2", 
                "pages": "4", 
                "doi": "10.3389/neuro.06.004.2008", 
                "pmid": 19104670
            }, 
            {
                "type": "journal", 
                "id": "bib49", 
                "date": "2009", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "N Kriegeskorte", 
                            "index": "Kriegeskorte, N"
                        }
                    }
                ], 
                "articleTitle": "Relating population-code representations between man, monkey, and computational models", 
                "journal": "Frontiers in Neuroscience", 
                "volume": "3", 
                "pages": {
                    "first": "363", 
                    "last": "373", 
                    "range": "363\u2013373"
                }, 
                "doi": "10.3389/neuro.01.035.2009", 
                "pmid": 20198153
            }, 
            {
                "type": "conference-proceeding", 
                "id": "bib50", 
                "date": "2012", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Krizhevsky", 
                            "index": "Krizhevsky, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "I Sutskever", 
                            "index": "Sutskever, I"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "GE Hinton", 
                            "index": "Hinton, GE"
                        }
                    }
                ], 
                "articleTitle": "Imagenet classification with deep convolutional neural networks", 
                "conference": {
                    "name": [
                        "In Advances in Neural Information Processing Systems"
                    ]
                }, 
                "pages": {
                    "first": "1097", 
                    "last": "1105", 
                    "range": "1097\u20131105"
                }
            }, 
            {
                "type": "journal", 
                "id": "bib51", 
                "date": "2000", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Laakso", 
                            "index": "Laakso, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "G Cottrell", 
                            "index": "Cottrell, G"
                        }
                    }
                ], 
                "articleTitle": "Content and cluster analysis: Assessing representational similarity in neural systems", 
                "journal": "Philosophical Psychology", 
                "volume": "13", 
                "pages": {
                    "first": "47", 
                    "last": "76", 
                    "range": "47\u201376"
                }, 
                "doi": "10.1080/09515080050002726"
            }, 
            {
                "type": "journal", 
                "id": "bib52", 
                "date": "2015", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Y LeCun", 
                            "index": "LeCun, Y"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Y Bengio", 
                            "index": "Bengio, Y"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "G Hinton", 
                            "index": "Hinton, G"
                        }
                    }
                ], 
                "articleTitle": "Deep learning", 
                "journal": "Nature", 
                "volume": "521", 
                "pages": {
                    "first": "436", 
                    "last": "444", 
                    "range": "436\u2013444"
                }, 
                "doi": "10.1038/nature14539", 
                "pmid": 26017442
            }, 
            {
                "type": "journal", 
                "id": "bib53", 
                "date": "1998", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Y Lecun", 
                            "index": "Lecun, Y"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "L Bottou", 
                            "index": "Bottou, L"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Y Bengio", 
                            "index": "Bengio, Y"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "P Haffner", 
                            "index": "Haffner, P"
                        }
                    }
                ], 
                "articleTitle": "Gradient-based learning applied to document recognition", 
                "journal": "Proceedings of the IEEE", 
                "volume": "86", 
                "pages": {
                    "first": "2278", 
                    "last": "2324", 
                    "range": "2278\u20132324"
                }, 
                "doi": "10.1109/5.726791"
            }, 
            {
                "type": "journal", 
                "id": "bib54", 
                "date": "2002", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "NK Logothetis", 
                            "index": "Logothetis, NK"
                        }
                    }
                ], 
                "articleTitle": "The neural basis of the blood-oxygen-level-dependent functional magnetic resonance imaging signal", 
                "journal": "Philosophical Transactions of the Royal Society B: Biological Sciences", 
                "volume": "357", 
                "pages": {
                    "first": "1003", 
                    "last": "1037", 
                    "range": "1003\u20131037"
                }, 
                "doi": "10.1098/rstb.2002.1114"
            }, 
            {
                "type": "journal", 
                "id": "bib55", 
                "date": "2008", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "NK Logothetis", 
                            "index": "Logothetis, NK"
                        }
                    }
                ], 
                "articleTitle": "What we can do and what we cannot do with fMRI", 
                "journal": "Nature", 
                "volume": "453", 
                "pages": {
                    "first": "869", 
                    "last": "878", 
                    "range": "869\u2013878"
                }, 
                "doi": "10.1038/nature06976", 
                "pmid": 18548064
            }, 
            {
                "type": "journal", 
                "id": "bib56", 
                "date": "2015", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "BC Love", 
                            "index": "Love, BC"
                        }
                    }
                ], 
                "articleTitle": "The algorithmic level is the bridge between computation and brain", 
                "journal": "Topics in Cognitive Science", 
                "volume": "7", 
                "pages": {
                    "first": "230", 
                    "last": "242", 
                    "range": "230\u2013242"
                }, 
                "doi": "10.1111/tops.12131", 
                "pmid": 25823496
            }, 
            {
                "type": "journal", 
                "id": "bib57", 
                "date": "2013", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "ML Mack", 
                            "index": "Mack, ML"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AR Preston", 
                            "index": "Preston, AR"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "BC Love", 
                            "index": "Love, BC"
                        }
                    }
                ], 
                "articleTitle": "Decoding the brain's algorithm for categorization from its neural implementation", 
                "journal": "Current Biology", 
                "volume": "23", 
                "pages": {
                    "first": "2023", 
                    "last": "2027", 
                    "range": "2023\u20132027"
                }, 
                "doi": "10.1016/j.cub.2013.08.035", 
                "pmid": 24094852
            }, 
            {
                "type": "journal", 
                "id": "bib58", 
                "date": "2016", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "ML Mack", 
                            "index": "Mack, ML"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AR Preston", 
                            "index": "Preston, AR"
                        }
                    }
                ], 
                "articleTitle": "Decisions about the past are guided by reinstatement of specific memories in the hippocampus and perirhinal cortex", 
                "journal": "NeuroImage", 
                "volume": "127", 
                "pages": {
                    "first": "144", 
                    "last": "157", 
                    "range": "144\u2013157"
                }, 
                "doi": "10.1016/j.neuroimage.2015.12.015", 
                "pmid": 26702775
            }, 
            {
                "type": "journal", 
                "id": "bib59", 
                "date": "2012", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "C Magri", 
                            "index": "Magri, C"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "U Schridde", 
                            "index": "Schridde, U"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Y Murayama", 
                            "index": "Murayama, Y"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Panzeri", 
                            "index": "Panzeri, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "NK Logothetis", 
                            "index": "Logothetis, NK"
                        }
                    }
                ], 
                "articleTitle": "The amplitude and timing of the BOLD signal reflects the relationship between local field potential power at different frequencies", 
                "journal": "Journal of Neuroscience", 
                "volume": "32", 
                "pages": {
                    "first": "1395", 
                    "last": "1407", 
                    "range": "1395\u20131407"
                }, 
                "doi": "10.1523/JNEUROSCI.3985-11.2012", 
                "pmid": 22279224
            }, 
            {
                "type": "book", 
                "id": "bib60", 
                "date": "1982", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "D Marr", 
                            "index": "Marr, D"
                        }
                    }
                ], 
                "bookTitle": "Vision: A Computational Investigation Into the Human Representation and Processing of Visual Information", 
                "publisher": {
                    "name": [
                        "Henry Holt and Co., Inc"
                    ], 
                    "address": {
                        "formatted": [
                            "New York, USA"
                        ], 
                        "components": {
                            "locality": [
                                "New York, USA"
                            ]
                        }
                    }
                }
            }, 
            {
                "type": "journal", 
                "id": "bib61", 
                "date": "1983", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JH Maunsell", 
                            "index": "Maunsell, JH"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DC Van Essen", 
                            "index": "Van Essen, DC"
                        }
                    }
                ], 
                "articleTitle": "Functional properties of neurons in middle temporal visual area of the macaque monkey. I. Selectivity for stimulus direction, speed, and orientation", 
                "journal": "Journal of Neurophysiology", 
                "volume": "49", 
                "pages": {
                    "first": "1127", 
                    "last": "1147", 
                    "range": "1127\u20131147"
                }, 
                "pmid": 6864242
            }, 
            {
                "type": "journal", 
                "id": "bib62", 
                "date": "2004", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "TM Mitchell", 
                            "index": "Mitchell, TM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Hutchinson", 
                            "index": "Hutchinson, R"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RS Niculescu", 
                            "index": "Niculescu, RS"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "F Pereira", 
                            "index": "Pereira, F"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "X Wang", 
                            "index": "Wang, X"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Just", 
                            "index": "Just, M"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Newman", 
                            "index": "Newman, S"
                        }
                    }
                ], 
                "articleTitle": "Learning to decode cognitive states from brain images", 
                "journal": "Machine Learning", 
                "volume": "57", 
                "pages": {
                    "first": "145", 
                    "last": "175", 
                    "range": "145\u2013175"
                }, 
                "doi": "10.1023/B:MACH.0000035475.85309.1b"
            }, 
            {
                "type": "book", 
                "id": "bib63", 
                "date": "2015", 
                "authors": [
                    {
                        "type": "group", 
                        "name": "National Institute of Standards and Technology"
                    }
                ], 
                "bookTitle": "Secure Hash Standard\u00a0(SHS)\u00a0(Standard No. 180)", 
                "publisher": {
                    "name": [
                        "FIPS PUB"
                    ], 
                    "address": {
                        "formatted": [
                            "Gaithersburg, USA"
                        ], 
                        "components": {
                            "locality": [
                                "Gaithersburg, USA"
                            ]
                        }
                    }
                }
            }, 
            {
                "type": "journal", 
                "id": "bib64", 
                "date": "2004", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Nevado", 
                            "index": "Nevado, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "MP Young", 
                            "index": "Young, MP"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Panzeri", 
                            "index": "Panzeri, S"
                        }
                    }
                ], 
                "articleTitle": "Functional imaging and neural information coding", 
                "journal": "NeuroImage", 
                "volume": "21", 
                "pages": {
                    "first": "1083", 
                    "last": "1095", 
                    "range": "1083\u20131095"
                }, 
                "doi": "10.1016/j.neuroimage.2003.10.043", 
                "pmid": 15006676
            }, 
            {
                "type": "journal", 
                "id": "bib65", 
                "date": "2006", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "KA Norman", 
                            "index": "Norman, KA"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "SM Polyn", 
                            "index": "Polyn, SM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "GJ Detre", 
                            "index": "Detre, GJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JV Haxby", 
                            "index": "Haxby, JV"
                        }
                    }
                ], 
                "articleTitle": "Beyond mind-reading: multi-voxel pattern analysis of fMRI data", 
                "journal": "Trends in Cognitive Sciences", 
                "volume": "10", 
                "pages": {
                    "first": "424", 
                    "last": "430", 
                    "range": "424\u2013430"
                }, 
                "doi": "10.1016/j.tics.2006.07.005", 
                "pmid": 16899397
            }, 
            {
                "type": "journal", 
                "id": "bib66", 
                "date": "2016", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "P O'Herron", 
                            "index": "O'Herron, P"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "PY Chhatbar", 
                            "index": "Chhatbar, PY"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Levy", 
                            "index": "Levy, M"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Z Shen", 
                            "index": "Shen, Z"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AE Schramm", 
                            "index": "Schramm, AE"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Z Lu", 
                            "index": "Lu, Z"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "P Kara", 
                            "index": "Kara, P"
                        }
                    }
                ], 
                "articleTitle": "Neural correlates of single-vessel haemodynamic responses in vivo", 
                "journal": "Nature", 
                "volume": "534", 
                "pages": {
                    "first": "378", 
                    "last": "382", 
                    "range": "378\u2013382"
                }, 
                "doi": "10.1038/nature17965", 
                "pmid": 27281215
            }, 
            {
                "type": "journal", 
                "id": "bib67", 
                "date": "2015", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Panzeri", 
                            "index": "Panzeri, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JH Macke", 
                            "index": "Macke, JH"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "J Gross", 
                            "index": "Gross, J"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "C Kayser", 
                            "index": "Kayser, C"
                        }
                    }
                ], 
                "articleTitle": "Neural population coding: combining insights from microscopic and mass signals", 
                "journal": "Trends in Cognitive Sciences", 
                "volume": "19", 
                "pages": {
                    "first": "162", 
                    "last": "172", 
                    "range": "162\u2013172"
                }, 
                "doi": "10.1016/j.tics.2015.01.002", 
                "pmid": 25670005
            }, 
            {
                "type": "journal", 
                "id": "bib68", 
                "date": "2002", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "L Pessoa", 
                            "index": "Pessoa, L"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "E Gutierrez", 
                            "index": "Gutierrez, E"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "P Bandettini", 
                            "index": "Bandettini, P"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "L Ungerleider", 
                            "index": "Ungerleider, L"
                        }
                    }
                ], 
                "articleTitle": "Neural correlates of visual working memory: fMRI amplitude predicts task performance", 
                "journal": "Neuron", 
                "volume": "35", 
                "pages": {
                    "first": "975", 
                    "last": "987", 
                    "range": "975\u2013987"
                }, 
                "pmid": 12372290
            }, 
            {
                "type": "journal", 
                "id": "bib69", 
                "date": "2000", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Pouget", 
                            "index": "Pouget, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "P Dayan", 
                            "index": "Dayan, P"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Zemel", 
                            "index": "Zemel, R"
                        }
                    }
                ], 
                "articleTitle": "Information processing with population codes", 
                "journal": "Nature Reviews. Neuroscience", 
                "volume": "1", 
                "pages": {
                    "first": "125", 
                    "last": "132", 
                    "range": "125\u2013132"
                }, 
                "doi": "10.1038/35039062", 
                "pmid": 11252775
            }, 
            {
                "type": "journal", 
                "id": "bib70", 
                "date": "2002", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "NJ Priebe", 
                            "index": "Priebe, NJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "D Ferster", 
                            "index": "Ferster, D"
                        }
                    }
                ], 
                "articleTitle": "A new mechanism for neuronal gain control (or how the gain in brains has mainly been explained)", 
                "journal": "Neuron", 
                "volume": "35", 
                "pages": {
                    "first": "602", 
                    "last": "604", 
                    "range": "602\u2013604"
                }, 
                "doi": "10.1016/S0896-6273(02)00829-2", 
                "pmid": 12194862
            }, 
            {
                "type": "journal", 
                "id": "bib71", 
                "date": "2005", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RQ Quiroga", 
                            "index": "Quiroga, RQ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "L Reddy", 
                            "index": "Reddy, L"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "G Kreiman", 
                            "index": "Kreiman, G"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "C Koch", 
                            "index": "Koch, C"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "I Fried", 
                            "index": "Fried, I"
                        }
                    }
                ], 
                "articleTitle": "Invariant visual representation by single neurons in the human brain", 
                "journal": "Nature", 
                "volume": "435", 
                "pages": {
                    "first": "1102", 
                    "last": "1107", 
                    "range": "1102\u20131107"
                }, 
                "doi": "10.1038/nature03687", 
                "pmid": 15973409
            }, 
            {
                "type": "journal", 
                "id": "bib72", 
                "date": "2013", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Ramscar", 
                            "index": "Ramscar, M"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Dye", 
                            "index": "Dye, M"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "J Klein", 
                            "index": "Klein, J"
                        }
                    }
                ], 
                "articleTitle": "Children value informativity over logic in word learning", 
                "journal": "Psychological Science", 
                "volume": "24", 
                "pages": {
                    "first": "1017", 
                    "last": "1023", 
                    "range": "1017\u20131023"
                }, 
                "doi": "10.1177/0956797612460691", 
                "pmid": 23610135
            }, 
            {
                "type": "journal", 
                "id": "bib73", 
                "date": "2009", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "L Reddy", 
                            "index": "Reddy, L"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "NG Kanwisher", 
                            "index": "Kanwisher, NG"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R VanRullen", 
                            "index": "VanRullen, R"
                        }
                    }
                ], 
                "articleTitle": "Attention and biased competition in multi-voxel object representations", 
                "journal": "PNAS", 
                "volume": "106", 
                "pages": {
                    "first": "21447", 
                    "last": "21452", 
                    "range": "21447\u201321452"
                }, 
                "doi": "10.1073/pnas.0907330106"
            }, 
            {
                "type": "unknown", 
                "id": "bib74", 
                "date": "1972", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RA Rescorla", 
                            "index": "Rescorla, RA"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AR Wagner", 
                            "index": "Wagner, AR"
                        }
                    }
                ], 
                "title": "Appleton-Century-Crofts", 
                "details": "64\u201399, Classical Conditioning II, Appleton-Century-Crofts"
            }, 
            {
                "type": "journal", 
                "id": "bib75", 
                "date": "1999", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Riesenhuber", 
                            "index": "Riesenhuber, M"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "T Poggio", 
                            "index": "Poggio, T"
                        }
                    }
                ], 
                "articleTitle": "Hierarchical models of object recognition in cortex", 
                "journal": "Nature Neuroscience", 
                "volume": "2", 
                "pages": {
                    "first": "1019", 
                    "last": "1025", 
                    "range": "1019\u20131025"
                }, 
                "doi": "10.1038/14819", 
                "pmid": 10526343
            }, 
            {
                "type": "journal", 
                "id": "bib76", 
                "date": "2000", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Riesenhuber", 
                            "index": "Riesenhuber, M"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "T Poggio", 
                            "index": "Poggio, T"
                        }
                    }
                ], 
                "articleTitle": "Models of object recognition", 
                "journal": "Nature Neuroscience", 
                "volume": "3 Suppl", 
                "pages": {
                    "first": "1199", 
                    "last": "1204", 
                    "range": "1199\u20131204"
                }, 
                "doi": "10.1038/81479", 
                "pmid": 11127838
            }, 
            {
                "type": "book-chapter", 
                "id": "bib77", 
                "date": "1995", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DE Rummelhart", 
                            "index": "Rummelhart, DE"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Durbin", 
                            "index": "Durbin, R"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Golden", 
                            "index": "Golden, R"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Y Chauvin", 
                            "index": "Chauvin, Y"
                        }
                    }
                ], 
                "editors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Y Chauvin", 
                            "index": "Chauvin, Y"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "D. E Rumelhart", 
                            "index": "Rumelhart, D. E"
                        }
                    }
                ], 
                "bookTitle": "Backpropagation: Theory, Architectures, and Applications", 
                "publisher": {
                    "name": [
                        "Lawrence Erlbaum associates Associates Inc"
                    ], 
                    "address": {
                        "formatted": [
                            "USA"
                        ], 
                        "components": {
                            "locality": [
                                "USA"
                            ]
                        }
                    }
                }, 
                "chapterTitle": "Backpropagation: Theory, architectures, and applications", 
                "pages": {
                    "first": "1", 
                    "last": "34", 
                    "range": "1\u201334"
                }
            }, 
            {
                "type": "journal", 
                "id": "bib78", 
                "date": "2015", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "O Russakovsky", 
                            "index": "Russakovsky, O"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "J Deng", 
                            "index": "Deng, J"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "H Su", 
                            "index": "Su, H"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "J Krause", 
                            "index": "Krause, J"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Satheesh", 
                            "index": "Satheesh, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Ma", 
                            "index": "Ma, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Z Huang", 
                            "index": "Huang, Z"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Karpathy", 
                            "index": "Karpathy, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Khosla", 
                            "index": "Khosla, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Bernstein", 
                            "index": "Bernstein, M"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AC Berg", 
                            "index": "Berg, AC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "L Fei-Fei", 
                            "index": "Fei-Fei, L"
                        }
                    }
                ], 
                "articleTitle": "ImageNet large scale visual recognition challenge", 
                "journal": "International Journal of Computer Vision", 
                "volume": "115", 
                "pages": {
                    "first": "211", 
                    "last": "252", 
                    "range": "211\u2013252"
                }, 
                "doi": "10.1007/s11263-015-0816-y"
            }, 
            {
                "type": "journal", 
                "id": "bib79", 
                "date": "2011", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Scheeringa", 
                            "index": "Scheeringa, R"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "P Fries", 
                            "index": "Fries, P"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "KM Petersson", 
                            "index": "Petersson, KM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Oostenveld", 
                            "index": "Oostenveld, R"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "I Grothe", 
                            "index": "Grothe, I"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DG Norris", 
                            "index": "Norris, DG"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "P Hagoort", 
                            "index": "Hagoort, P"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "MC Bastiaansen", 
                            "index": "Bastiaansen, MC"
                        }
                    }
                ], 
                "articleTitle": "Neuronal dynamics underlying high- and low-frequency EEG oscillations contribute independently to the human BOLD signal", 
                "journal": "Neuron", 
                "volume": "69", 
                "pages": {
                    "first": "572", 
                    "last": "583", 
                    "range": "572\u2013583"
                }, 
                "doi": "10.1016/j.neuron.2010.11.044", 
                "pmid": 21315266
            }, 
            {
                "type": "journal", 
                "id": "bib80", 
                "date": "2010", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "T Serre", 
                            "index": "Serre, T"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "T Poggio", 
                            "index": "Poggio, T"
                        }
                    }
                ], 
                "articleTitle": "A neuromorphic approach to computer vision", 
                "journal": "Communications of the ACM", 
                "volume": "53", 
                "pages": {
                    "first": "54", 
                    "last": "61", 
                    "range": "54\u201361"
                }, 
                "doi": "10.1145/1831407.1831425"
            }, 
            {
                "type": "journal", 
                "id": "bib81", 
                "date": "2007-03", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "T Serre", 
                            "index": "Serre, T"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "L Wolf", 
                            "index": "Wolf, L"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Bileschi", 
                            "index": "Bileschi, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Riesenhuber", 
                            "index": "Riesenhuber, M"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "T Poggio", 
                            "index": "Poggio, T"
                        }
                    }
                ], 
                "articleTitle": "Robust object recognition with Cortex-Like mechanisms", 
                "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", 
                "volume": "29", 
                "pages": {
                    "first": "411", 
                    "last": "426", 
                    "range": "411\u2013426"
                }, 
                "doi": "10.1109/TPAMI.2007.56"
            }, 
            {
                "type": "journal", 
                "id": "bib82", 
                "date": "1987", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RN Shepard", 
                            "index": "Shepard, RN"
                        }
                    }
                ], 
                "articleTitle": "Toward a universal law of generalization for psychological science", 
                "journal": "Science", 
                "volume": "237", 
                "pages": {
                    "first": "1317", 
                    "last": "1323", 
                    "range": "1317\u20131323"
                }, 
                "doi": "10.1126/science.3629243", 
                "pmid": 3629243
            }, 
            {
                "type": "journal", 
                "id": "bib83", 
                "date": "2010", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JD Swisher", 
                            "index": "Swisher, JD"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JC Gatenby", 
                            "index": "Gatenby, JC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JC Gore", 
                            "index": "Gore, JC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "BA Wolfe", 
                            "index": "Wolfe, BA"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "CH Moon", 
                            "index": "Moon, CH"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "SG Kim", 
                            "index": "Kim, SG"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "F Tong", 
                            "index": "Tong, F"
                        }
                    }
                ], 
                "articleTitle": "Multiscale pattern analysis of orientation-selective activity in the primary visual cortex", 
                "journal": "Journal of Neuroscience", 
                "volume": "30", 
                "pages": {
                    "first": "325", 
                    "last": "330", 
                    "range": "325\u2013330"
                }, 
                "doi": "10.1523/JNEUROSCI.4811-09.2010", 
                "pmid": 20053913
            }, 
            {
                "type": "conference-proceeding", 
                "id": "bib84", 
                "date": "2016", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "C Szegedy", 
                            "index": "Szegedy, C"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Ioffe", 
                            "index": "Ioffe, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "V Vanhoucke", 
                            "index": "Vanhoucke, V"
                        }
                    }
                ], 
                "articleTitle": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning", 
                "conference": {
                    "name": [
                        "CoRR"
                    ]
                }, 
                "source": "abs/1602.07261"
            }, 
            {
                "type": "conference-proceeding", 
                "id": "bib85", 
                "date": "2015", 
                "discriminator": "a", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "C Szegedy", 
                            "index": "Szegedy, C"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "W Liu", 
                            "index": "Liu, W"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Y Jia", 
                            "index": "Jia, Y"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "P Sermanet", 
                            "index": "Sermanet, P"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Reed", 
                            "index": "Reed, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "D Anguelov", 
                            "index": "Anguelov, D"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "D Erhan", 
                            "index": "Erhan, D"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "V Vanhoucke", 
                            "index": "Vanhoucke, V"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Rabinovich", 
                            "index": "Rabinovich, A"
                        }
                    }
                ], 
                "articleTitle": "Going deeper with convolutions", 
                "conference": {
                    "name": [
                        "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
                    ]
                }, 
                "doi": "10.1109/cvpr.2015.7298594", 
                "uri": "https://doi.org/10.1109/cvpr.2015.7298594"
            }, 
            {
                "type": "conference-proceeding", 
                "id": "bib86", 
                "date": "2015", 
                "discriminator": "b", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "C Szegedy", 
                            "index": "Szegedy, C"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "V Vanhoucke", 
                            "index": "Vanhoucke, V"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Ioffe", 
                            "index": "Ioffe, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "J Shlens", 
                            "index": "Shlens, J"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Z Wojna", 
                            "index": "Wojna, Z"
                        }
                    }
                ], 
                "articleTitle": "Rethinking the inception architecture for computer vision", 
                "conference": {
                    "name": [
                        "CoRR"
                    ]
                }, 
                "source": "abs/1512.00567"
            }, 
            {
                "type": "journal", 
                "id": "bib87", 
                "date": "2016", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Tompary", 
                            "index": "Tompary, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "K Duncan", 
                            "index": "Duncan, K"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "L Davachi", 
                            "index": "Davachi, L"
                        }
                    }
                ], 
                "articleTitle": "High-resolution investigation of memory-specific reinstatement in the hippocampus and perirhinal cortex", 
                "journal": "Hippocampus", 
                "volume": "26", 
                "pages": {
                    "first": "995", 
                    "last": "1007", 
                    "range": "995\u20131007"
                }, 
                "doi": "10.1002/hipo.22582"
            }, 
            {
                "type": "journal", 
                "id": "bib88", 
                "date": "2002", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Turner", 
                            "index": "Turner, R"
                        }
                    }
                ], 
                "articleTitle": "How much cortex can a vein drain? Downstream dilution of activation-related cerebral blood oxygenation changes", 
                "journal": "NeuroImage", 
                "volume": "16", 
                "pages": {
                    "first": "1062", 
                    "last": "1067", 
                    "range": "1062\u20131067"
                }, 
                "doi": "10.1006/nimg.2002.1082", 
                "pmid": 12202093
            }, 
            {
                "type": "journal", 
                "id": "bib89", 
                "date": "2016", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "E Underwood", 
                            "index": "Underwood, E"
                        }
                    }
                ], 
                "articleTitle": "Barcoding the brain", 
                "journal": "Science", 
                "volume": "351", 
                "pages": {
                    "first": "799", 
                    "last": "800", 
                    "range": "799\u2013800"
                }, 
                "doi": "10.1126/science.351.6275.799"
            }, 
            {
                "type": "journal", 
                "id": "bib90", 
                "date": "2006", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "KF Wong", 
                            "index": "Wong, KF"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "XJ Wang", 
                            "index": "Wang, XJ"
                        }
                    }
                ], 
                "articleTitle": "A recurrent network mechanism of time integration in perceptual decisions", 
                "journal": "Journal of Neuroscience", 
                "volume": "26", 
                "pages": {
                    "first": "1314", 
                    "last": "1328", 
                    "range": "1314\u20131328"
                }, 
                "doi": "10.1523/JNEUROSCI.3733-05.2006", 
                "pmid": 16436619
            }, 
            {
                "type": "journal", 
                "id": "bib91", 
                "date": "2016", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DL Yamins", 
                            "index": "Yamins, DL"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JJ DiCarlo", 
                            "index": "DiCarlo, JJ"
                        }
                    }
                ], 
                "articleTitle": "Using goal-driven deep learning models to understand sensory cortex", 
                "journal": "Nature Neuroscience", 
                "volume": "19", 
                "pages": {
                    "first": "356", 
                    "last": "365", 
                    "range": "356\u2013365"
                }, 
                "doi": "10.1038/nn.4244", 
                "pmid": 26906502
            }, 
            {
                "type": "journal", 
                "id": "bib92", 
                "date": "2014", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DL Yamins", 
                            "index": "Yamins, DL"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "H Hong", 
                            "index": "Hong, H"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "CF Cadieu", 
                            "index": "Cadieu, CF"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "EA Solomon", 
                            "index": "Solomon, EA"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "D Seibert", 
                            "index": "Seibert, D"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JJ DiCarlo", 
                            "index": "DiCarlo, JJ"
                        }
                    }
                ], 
                "articleTitle": "Performance-optimized hierarchical models predict neural responses in higher visual cortex", 
                "journal": "PNAS", 
                "volume": "111", 
                "pages": {
                    "first": "8619", 
                    "last": "8624", 
                    "range": "8619\u20138624"
                }, 
                "doi": "10.1073/pnas.1403112111", 
                "pmid": 24812127
            }
        ], 
        "acknowledgements": [
            {
                "type": "paragraph", 
                "text": "This work was supported by the Leverhulme Trust (Grant RPG-2014-075), the NIH (Grant 1P01HD080679), and a Wellcome Trust Investigator Award (Grant WT106931MA) to BCL, as well as The Alan Turing Institute under the EPSRC grant EP/N510129/1. Correspondences regarding this work can be sent to o.guest@ucl.ac.uk or b.love@ucl.ac.uk. The authors declare that they have no competing interests. The authors would like to thank Sabine Kastner,\u00a0Russ Poldrack, Tal Yarkoni, Niko Kriegeskorte, Sam Schwarzkopf, Christiane Ahlheim, and Johan Carlin for their thoughtful feedback on the preprint version, <a href=\"http://dx.doi.org/10.1101/071076\">http://dx.doi.org/10.1101/071076</a>. The code used to run these experiments is freely available, <a href=\"http://osf.io/v8baz\">http://osf.io/v8baz</a>."
            }
        ], 
        "decisionLetter": {
            "doi": "10.7554/eLife.21397.008", 
            "description": [
                {
                    "type": "paragraph", 
                    "text": "In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included."
                }
            ], 
            "content": [
                {
                    "type": "paragraph", 
                    "text": "Thank you for submitting your article \"What the Success of Brain Imaging Implies about the Neural Code\" for consideration by <i>eLife</i>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Sabine Kastner as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Rogier Andrew Kievit (Reviewer #1); Stefano Panzeri (Reviewer #2)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Summary:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "This paper asks how the success of fMRI (particularly in the context of representational analysis) has implications for the structure of the neural code. The authors first argue that neural representations must be smooth enough in the spatial and temporal domains to afford effective measurement with fMRI. They then argue that the neural code must also obey a principle of \"functional smoothness\", such that similar stimuli map to similar neural representations. Using a range of coding schemes, they examine which ones could potentially satisfy this requirement for functional smoothness and thus allow successful neural decoding from fMRI. They show that a number of simple neural models demonstrate such representational isomorphism; in particular, they demonstrate at the earlier layers of a deep convolutional neural network (CNN) show functional similarity, whereas the later layers in the hierarchy do not. The authors conclude that the success of fMRI places limits on the range of plausible coding schemes, and in particular that it implies that neural coding schemes must be both spatiotemporally and functionally smooth."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Essential revisions:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "The three reviewers and I all agree that this paper raises an interesting set of questions. However, there were a number of concerns about the paper as it is currently written. Here are the main concerns as I see them, and how they should be addressed:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "\u2013 Two reviewers raise the question of whether your claims are fully supported by the results, suggesting in many cases that you are making strong claims that are not fully supported by your results. I think that in general the revision needs to better calibrate the claims to the evidence, and avoid overreaching. In particular, the fact that fMRI is successful does not mean that it is capturing all, or even the majority, of interesting neural signals. This issue needs to be clearly addressed in the revision."
                }, 
                {
                    "type": "paragraph", 
                    "text": "\u2013 The concept of \"functional smoothness\" is central to your manuscript, but the reviewers raised multiple questions regarding the clarity of this concept in your paper. The revision needs to be much clearer about what this concept means and how it relates more specifically to the other concepts of smoothness."
                }, 
                {
                    "type": "paragraph", 
                    "text": "\u2013 Reviewer 2 points out that your paper needs to make better contact with the literature that has investigated the neural basis of the BOLD signal. In particular, specific attention must be paid to the points raised by reviewer 2 regarding the implications for temporal aspects of the BOLD signal."
                }, 
                {
                    "type": "paragraph", 
                    "text": "\u2013 Reviewer 3 points out that the paper lacks methodological details, and that they were not able to access the materials linked at OSF. In the revision, please include a detailed description of your methods along with a working link to the code and materials."
                }, 
                {
                    "type": "paragraph", 
                    "text": "I am including the reviewers' comments below, which provide greater detail regarding the issues outlined above."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Reviewer #1:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "In this paper, Guest and Love propose an interesting and provocative claim: The success of fMRI writ large can, and should, constrain theories about the underlying neural code. The paper is engaging and provides a considerable amount of food for thought. However, upon close reading a number of problems are present, including the scope and precision of the central claims, the use and definition of terminology, the choice of models and appropriate engagement with relevant literature. These problems are outlined below. Given the scope of the paper the comments are lengthy, but necessary to clearly describe what we found challenging about the manuscript."
                }, 
                {
                    "type": "paragraph", 
                    "text": "1) What are the scopes of the claims being made?"
                }, 
                {
                    "type": "paragraph", 
                    "text": "One main issue with the paper is the precise nature of the central claim. This claim varies in scope throughout the paper from more modest and well-evidenced to more all-encompassing and arguably beyond the evidence put forth. The main claim can loosely be phrased as: The fact that fMRI writ large \u201cworks\u201d tells us something about the underlying neural mechanisms. The precise cashing out of this claim includes the following descriptions:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Abstract \u201ccertain neural coding schemes are more likely than others\u201d (Plausible but not necessarily true)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Subsection \u201cSub-voxel Smoothness\u201d, \u201cthe rate of change (i.e., smoothness) of neural activity must not exceed what can be measured within a voxel.\u201d (This phrasing seems overly general \u2013 There is no reason why rates of change couldn't also exceed what can be measured. All that is compellingly shown is that a non-trivial part of the neural code behaves in a temporally smooth manner)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "In the same section \u201ctemporally demanding coding schemes cannot carry the day\u201d (Not clear what \u201ccarry the day\u201d means \u2013 If it means \u201cCan't fully explain all patterns\u201d then it is likely true and well supported, if it means \u201ctemporally demanding coding schemes cannot play an important role also\u201d I think it's too strong a claim)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Also in this section \u201cthe neural code must be spatially and temporally smooth with respect to neural activity\u201d (Overly general in that it implies there is only one neural code ('The'))."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Discussion section first paragraph \u201cthe neural code must be smooth, both at the sub-voxel and functional levels.\u201d (overly general \u2013 It can be smooth and non-smooth simultaneously to currently unknown degrees, e.g. <a href=\"#fig1\">Figure 1</a> left and right could be overlapping)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Discussion section paragraph ten \u201cHowever, fMRI's success might mean that when one is interested in the nature of computations carried out by the brain, the level of analysis where fMRI applies should be preferred.\u201d (A considerable overgeneralisation \u2013 All we know for sure is that fMRI can provide important information, but there is no reason why lower (or higher) levels of temporal or spatial abstraction can't be even more informative.)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "More limited and arguably more accurate are:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "\u2013 Abstract section \u201cDeep neural network approaches, are consistent with the success of fMRI\u201d (True and well-supported)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "\u2013 Subsection \u201cSub-voxel Smoothness\u201d, \u201cThe success of fMRI does not imply that the brain does not utilize precise timing information\u201d (an important explication of the point raised above that multiple coding schemes could operate concurrently, and that fMRI would 'work' if it only picks up parts)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Similarly in subsection \u201cFactorial Design Coding\u201d, discussing factorial coding, the authors state \u201cInterestingly, if any region in the brain had such a distribution of voxels, neural similarity would be impossible to recover by fMRI.\u201d And later \u201cIf the neural code for a region was employing a technique similar to factorial design, neuroimaging studies would never recover similarity structures by looking at the patterns of active voxels in that region.\u201d These statements are only true if other coding schemes aren't allowed to co-exist. It may well be that factorial coding schemes co-exist alongside spatially smooth codes but simply cannot be detected using current methods and/or analyses. Or, to couch it in terms of <a href=\"#fig1\">Figure 1</a>, there is no reason why the neural code might not be an overlay, or mixture, of A and B. This implicit suggestion that there must be a single coding scheme is reflected in the title, which refers to 'The' neural code."
                }, 
                {
                    "type": "paragraph", 
                    "text": "As can be seen when read in succession, these are not interchangeable epistemic claims \u2013 Some are 'merely' existence claims whereas others rule out alternative explanations."
                }, 
                {
                    "type": "paragraph", 
                    "text": "In our view, the main claim of that article, that is important and well supported, can be phrased as follows:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "The success of fMRI makes it highly likely that at least some non-trivial subset of the signal/computations made by the neural code must be smooth."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Or, in the authors words \u201cOne general conclusion is that important aspects of the neural code are spatially and temporally smooth at the sub-voxel level\u201d."
                }, 
                {
                    "type": "paragraph", 
                    "text": "In other words, the article provides solid evidence for a more modest positive claim but at times shifts into language that suggests it has ruled out (or rendered exceedingly unlikely) other neural codes. We do not believe this is the case (nor, for that matter, do I think this is an achievable goal in the context of any single paper, for both principled mathematical reasons that every data pattern is compatible with an infinity of data generating mechanisms, and the pragmatic reasons of scope). In other words, we would suggest that the precise scope of the central claim is delineated more clearly, and that this scope is retained throughout"
                }, 
                {
                    "type": "paragraph", 
                    "text": "2) Is \"sub-voxel smoothness\" an accurate and clear description of what is required for successful fMRI?"
                }, 
                {
                    "type": "paragraph", 
                    "text": "The other main challenge in the article is the introduction of two new terms, spatial and functional smoothness. It seems as though these are not entirely precisely defined, and to the extent that they are, one might wonder whether a) 'smoothness' is the best term and b) what, if anything, is similar about spatial and functional smoothness such that they share a conceptual term. We outline these challenges below."
                }, 
                {
                    "type": "paragraph", 
                    "text": "With regards to spatial smoothness, I wonder whether the term inhomogeneity isn't more appropriate or central to the claim being made. For instance, it seems as though one could rearrange the voxel columns in <a href=\"#fig1\">Figure 1B</a> whilst preserving sub-voxel smoothness as well as functional smoothness \u2013 The arrangement of the voxels as a gradient could be misunderstood as being about super-voxel smoothness (especially in the light of evidence for early visual retinotopic mapping). (more detail below)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "The paper distinguishes between the concepts of sub-voxel and super-voxel smoothness. These concepts appear to be independent \u2013 i.e. one could have subvoxel smoothness combined with non-smooth super-voxel patterns. i.e., it's not entirely clear why \u201cIn such a spatially smooth representation, the transitions from red to yellow occur in progressive increments\u201d follows necessarily from subvoxel smoothness? The later definition that voxel size can be changed arbitrarily does capture this, but for a *given* voxel size a pattern could be subvoxel smooth and super-voxel non-smooth. Note that the empirical examples outlines in subsection \u201cSub-voxel Smoothness\u201d are compelling evidence that sub and super-voxel smoothness are related, but in principle they needn't be (this point is made by the authors in subsection \u201cFunctional Smoothness\u201d with respect to functional smoothness)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "It might be helpful to show in <a href=\"#fig1\">Figure 1</a> examples of all four possible combinations. In the current <a href=\"#fig1\">Figure 1</a>, the left panels appear to show both sub- and super-voxel smoothness (there is a smooth gradient of functional tunings both within a voxel, and across voxels once tunings have been averaged within each voxel). The right panel appears to show a case where neither hold (within a single voxel, tunings are arranged into jagged repeating stripes, and across voxels all tunings are identical once averaged). It would also be possible to have sub-voxel smoothness without super-voxel smoothness (e.g. if one were to shuffle the \"columns\" of the arrangement on the left), and vice versa (e.g. a version of the arrangement on the right in which the red stripes became progressively thinner and the yellow stripes progressively wider as one moved across the cortical sheet)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Picturing these four alternatives, it seems that in order for different stimuli to create different patterns at the level of fMRI voxels, the important factor is neither sub-voxel nor super-voxel smoothness, but something which might be termed \"across-voxel inhomogeneity\" \u2013 i.e. that different voxels sample populations of neurons with different functional properties. For example, in the example just suggested, wherein the 'columns' of the left-hand panel are shuffled, there would no longer be a smooth gradient in the functional selectivities of voxels as one moves across the cortical sheet, but different stimuli could still evoke unique multi-voxel patterns."
                }, 
                {
                    "type": "paragraph", 
                    "text": "It is important here to engage with previous literature on fMRI decoding, especially Kamitani &amp; Tong (2005) and subsequent reflections on why stimulus orientation can be decoded from V1 via fMRI (e.g. Alink et al. 2013; Carlson, 2014). Orientation columns in V1 are arranged in a similar fashion to the \"sub-voxel non-smooth\" depiction in <a href=\"#fig1\">Figure 1</a>, yet orientation can reliably be decoded. One plausible reason is that the chance of each voxel sampling all orientation selectivities exactly equally is very low, so even if neuronal selectivities are intermixed at a sub-voxel level, slight differences in orientation preference are likely to emerge at the voxel level."
                }, 
                {
                    "type": "paragraph", 
                    "text": "The caption of <a href=\"#fig1\">Figure 1</a> suggests non-smoothness is preserved \u201cregardless of the precise boundaries of the voxels which quantize the brain\u201d but it seems that this would only be true conditional on preserving approximate voxel size? If I am allowed to change both the size and boundaries I could create mostly-yellow and mostly-red voxels from <a href=\"#fig1\">Figure 1B</a>? Moreover, as mentioned above, random variations in sampling can lead to successful decoding of schemes similar to the non-smooth pattern."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Sub-voxel smoothness might not be the most intuitive term to use, not only for the reasons mentioned under point 2, but also because it implies spatial and not temporal smoothness. It seems more appropriate to talk about spatial and temporal scales at which useful information (about stimuli, thoughts, actions) is represented by brain activity."
                }, 
                {
                    "type": "paragraph", 
                    "text": "3) \"Functional smoothness\" is a relational property between two models or between data and a model, not an inherent property of one model."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Arguably the most challenging term introduced by the paper is \"functional smoothness.\" It is not made clear what this is a property of. From the definition, that \"similar stimuli map to similar representations,\" a model is \"functionally smooth\" with respect to some second representational model if it preserves the representational geometry of that target model. In the first set of simulations involving noise-corrupted images, the target model is pixel space. In the second set of simulations involving objects of different categories being presented to a deep neural network, the target model is a semantic or conceptual space. In other words, functional smoothness is not an objective property of the model, but a relational property between an input and an output space. This seems to be recognised in some sections, e.g. subsection \u201cVector Space Coding\u201d: \"vector space coding is functionally smooth in the trivial sense as the function is identity.\""
                }, 
                {
                    "type": "paragraph", 
                    "text": "However, many other phrases in the paper imply that smoothness is intrinsic to models, e.g.:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "\u2013 subsection \u201cDeep Learning Networks\u201d: \"one key question is whether functional smoothness breaks down at more advanced layers in DLNs\u2026\""
                }, 
                {
                    "type": "paragraph", 
                    "text": "\u2013 subsection \u201cDeep Learning Network Simulation\u201d: \"We consider whether functional smoothness declines as stimuli progress to more advanced layers\u2026\""
                }, 
                {
                    "type": "paragraph", 
                    "text": "\u2013 and: \"Violating functional smoothness, all other similarity structure is discarded\u2026\""
                }, 
                {
                    "type": "paragraph", 
                    "text": "The simulations underlying <a href=\"#fig2\">Figures 2</a> and <a href=\"#fig3\">3</a> add to this confusion rather than illustrating functional smoothness. Presumably the weights within the weight matrices used in the models from \"matrix multiplication coding\" onwards were random? If so, then <a href=\"#fig3\">Figure 3</a> seems to illustrate the trivial effect that as one performs increasingly many random nonlinear transformations on an input, distances between stimuli in the input space will be less and less well correlated with distances in the output. This result doesn't seem to reveal anything fundamental about the merit of (non-random) deep nonlinear networks as models of brain representation."
                }, 
                {
                    "type": "paragraph", 
                    "text": "To highlight the fact that functional smoothness is a relational property, it might instead be helpful to create a simulation akin to these, but using a trained network, and adding noise in a more abstract \"target space\" (e.g. noise could be added to the location of an object within an image, for example by sliding around the location of a dog image superimposed on a natural background). The earliest layer of the network should be \"functionally smooth\" w.r.t. changes in pixels but not location (i.e. pixelwise differences will make a large difference to early representations); middle layers may be \"functionally smooth\" w.r.t. location but not pixels (e.g. the same dog at nearby locations will activate the same feature detectors looking for eyes, legs, etc), while the final categorical layer would ideally be wholly invariant both to pixel and location changes provided the image continues to contain a dog."
                }, 
                {
                    "type": "paragraph", 
                    "text": "It would also help to distinguish between coding schemes that have the capacity to be functionally smooth, vs. those that actually functionally smooth, with respect to a particular input space. Factorial and hash coding are raised as examples of codes that are \"not functionally smooth,\" while neural-network-style encodings of various complexity are evaluated for whether the simulated examples happen to be functionally smooth with respect to the input spaces (pixel space, then semantic similarity space). However, there is an important difference in the sense in which factorial coding is \"not functionally smooth\" and that in which the late layers of GoogLeNet are not \u2013 factorial and hash coding are not capable of being functionally smooth (because every representation is orthogonal to every other), whereas the neural networks considered are capable in principle of strongly preserving the representational geometry of any input space desired (although see Point 6)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "4) What is the relationship, if any, between spatial and functional smoothness?"
                }, 
                {
                    "type": "paragraph", 
                    "text": "It seems as if spatial and functional smoothness, as defined in the paper, should be completely independent of one another, and they are described in paragraph two of subsection \u201cFunctional Smoothness\u201d as \"distinct concepts.\" However:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Subsection \u201cMatrix Multiplication Coding\u201d: \"\u2026the internal representation of this coding scheme is completely nonsensical to the human eye and is not super-voxel smooth.\""
                }, 
                {
                    "type": "paragraph", 
                    "text": "This is confusing for two reasons. First, there is no reason for any internal representation to be \"sensible to the human eye.\" The fact that the input representation is \"sensible\" is just an artefact of using images as the inputs. Even then, the image is only understandable by the eye if one preserves the exact spatial order of units and arranges them into rows and columns of exactly the right dimensions. Any shuffling or re-arrangement of the pixels would constitute an identical representation, and yet would no longer be sensible to the eye \u2013 so sensibility to the eye does not seem relevant."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Second, how does this minimal model (a transformation of the input by a single matrix multiplication) specify properties about the spatial arrangement of voxels? Paragraph two subsection \u201cFunctional Smoothness\u201d states that functional smoothness is defined at the level of voxels (although this seems a little counter-intuitive, since brains and neural networks encode information at the level of neurons). So in the \"matrix multiplication code,\" we should imagine a case where there are as many voxels in the output as there are pixels in the input image, and the activation level of each one is determined by an arbitrary linear combination of all input pixels. This output will be \"functionally smooth\" w.r.t. pixel space if the matrix transformation is one that preserves representational geometry (e.g. a rotation matrix; see first comment under \"Smaller points\" below for more on this\u2026). This will be true however one arranges the voxels spatially. Some possible arrangements will appear super-voxel smooth (e.g. if voxels are placed next to those with the most similar selectivities), and some will not (e.g. if voxels are randomly placed), but all arrangements will be functionally smooth."
                }, 
                {
                    "type": "paragraph", 
                    "text": "If there is some deeper connection between functional and spatial smoothness, this needs to be more clearly explained and illustrated."
                }, 
                {
                    "type": "paragraph", 
                    "text": "5) Different neural code properties may be required for \"successful fMRI\" when doing mean-activation vs. decoding vs. representational similarity analyses."
                }, 
                {
                    "type": "paragraph", 
                    "text": "The title-bearing central claim refers to the \u201csuccess\u201d of brain imaging, but it is not entirely clear how this should be conceived. It might be worth briefly describing what counts as success, and how each result constrains possible neural codes. For example, it would be good to separately consider what findings from (1) old school mean-activation \u201cblobology\u201d, (2) classifiers performing above chance, (3) RSA imply about neural coding. It seems uncontroversial that all require \"temporal smoothness\" and some form of across-voxel spatial inhomogeneity in order for different stimuli to create detectably different fMRI activations. But they may have different further implications, for example:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "1) The success of \"blobology\" in finding multi-voxel clusters with similar functional properties suggests some degree of super-voxel smoothness."
                }, 
                {
                    "type": "paragraph", 
                    "text": "2) Above-chance decoding does not seem to even require a neural code capable of functional smoothness. E.g. in a factorial code, although every stimulus elicits a pattern orthogonal to that elicited by any other, one could still do successful \"mind-reading\" as long as one had access to data from previous trials on which subjects had viewed that stimulus."
                }, 
                {
                    "type": "paragraph", 
                    "text": "3) The success of RSA (i.e. finding interesting and nuanced similarity patterns between patterns evoked by different stimuli, which seem to bear some relation to the geometry of those stimuli within other models such as pixel space or semantic space and can be compared to predictions from computational models) does require a neural code which is capable of functional smoothness. The importance of functional smoothness only to RSA does seem to be recognised in the paper, but could be made more explicit, e.g.:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Subsection \u201cFactorial Design Coding\u201d paragraph five: \"If the neural code for a region was employing a technique similar to factorial design, neuroimaging studies would never recover similarity structures by looking at the patterns of active voxels in that region.\""
                }, 
                {
                    "type": "paragraph", 
                    "text": "One thing to note here is that model comparisons do not necessarily require RSA. Does the success of other analysis methods that compare models (e.g. voxel-receptive-field modelling) also point to functional smoothness? Or is this term strongly linked to RSA as an analysis framework, to the extent that it does not have a meaning outside it? If so, why do the authors focus so strongly on functional smoothness? (RSA is successful, but so are (linear) classifiers)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "6) Simulations with a network trained on a task other than categorisation would help justify the claim that \"non-smoothness\" is an inevitable property of deep nonlinear neural networks."
                }, 
                {
                    "type": "paragraph", 
                    "text": "The final simulations, in which distances within a \u201csemantic space\u201d are informally compared to distances within successive layers of the deep neural network GoogLeNet, conclude that later layers are less functionally smooth w.r.t. semantic space than early ones (since they lose between-category similarity information), and that \u201cthe decline in functional smoothness at later layers does not appear to be a straightforward consequence of training these networks to classify stimuli.\u201d This latter conclusion is likely to be controversial, and is not strongly supported by the sparsity analysis."
                }, 
                {
                    "type": "paragraph", 
                    "text": "The simplest way to clarify the contribution of the training task to the representational geometry in the final layers would be to show RDMs from (a) randomly-weighted networks, and (b) an unsupervised network, or one trained on a task orthogonal to categorisation. A good candidate would be the unsupervised seven layer neural network in Wang &amp; Gupta (2015), which is available from <a href=\"https://github.com/xiaolonw/caffe-video_triplet\">https://github.com/xiaolonw/caffe-video_triplet</a>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Again though, this would not reveal anything about the \"functional smoothness of the model,\" since that is not an inherent property, but only the similarity between the representations within the model and in semantic space."
                }, 
                {
                    "type": "paragraph", 
                    "text": "7) Previous work"
                }, 
                {
                    "type": "paragraph", 
                    "text": "One key feature missing from this paper is closer engagement with previous literature on decoding, such as the seminal findings in Kamitani & Tong (2005) (discussed above in Point 2), computational accounts (e.g. Kriegeskorte, N., Cusack, R., & Bandettini, P. (2010) or de Beeck, H. P. O. (2010), and those discussing the plausibility of more trivial structural explanations such as differences in vasculature (e.g. Shmuel, A., Chaimow, D., Raddatz, G., Ugurbil, K., & Yacoub, E. (2010))."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Miscellaneous"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Subsection \u201cMatrix Multiplication Coding\u201d states \u201cMatrix multiplication maps similar inputs to similar internal representations.\u201d The claim seems to refer to multiplication of a 1xn input by an arbitrary nxn matrix (such as would be implemented by a 1-layer fully connected linear neural network). Although there are some such matrix multiplications which would perfectly preserve distances between different inputs in their original vs. transformed spaces (e.g. rotation matrices), and with random matrices, distances in the original and transformed spaces will tend to correlate (as your simulations show), the claim is not generally true. There are many matrix multiplications which will completely disrupt representational geometry."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Subsection \u201cDeep Learning Network Simulation\u201d paragraph three states that sparseness of representation does not decline for a \"later advanced layer\" of the category-supervised deep neural net. Which layer is this? It seems surprising that sparseness does not increase in at least the final layer (i.e. the output of the softmax operation). Relatedly, is it worth showing more layers in Figure 5? If not, why are these two layers shown?"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Related to Point 3 above, it would help to use more precise language about the nature of the sensory inputs or brain representations being discussed. For example, subsection \u201cMatrix Multiplication Coding\u201d says that a particular coding scheme \"takes an input stimulus (e.g. a dog) and multiplies it by a weight matrix\" \u2013 given that a dog is not the sort of thing that can be multiplied by a weight matrix, does this mean either (specifically) an image of a dog, or (generally) the activity within a preceding layer of neurons in a neural network model? Referring to the (arbitrary) input images in the simulations as \"prototypes\" is also confusing, as it suggests they have some special status to the models."
                }, 
                {
                    "type": "paragraph", 
                    "text": "\u2013 Although I like the hash coding example in subsection \u201cHash Function Coding\u201d says it's \u201cpotentially useful for biological systems\u201d \u2013 it might be worth elaborating briefly in what circumstances a biological system would evolve something akin to hashcoding for certain stimuli? It seems rather inefficient and hard to reconcile with basic facts about learning (e.g. co-occurrence increasing association strengths, and thereby similarity) and memory (e.g. semantic co-activation)? I appreciate the later evidence for the compatibility of higher layers with hash coding but the above claim seems more general \u2013 This relates to the above discussion on what"
                }, 
                {
                    "type": "paragraph", 
                    "text": "\u2013 The selection of coding schemes cover interesting (and rhetorically convincing) ground but the motivation for this set of coding schemes doesn't seem to be motivated. E.g., why focus on hash coding and factorial mapping \u2013 Are those a subset of a broader range that could be considered? Something similar could be said about the selection of NN algorithms. The selection of codes seems to constitute an input being transformed by successively more complex neural networks (\"vector space coding\" = no transformation of the input; \"gain control coding\" = one nonlinearity; \"matrix multiplication coding\" = one linear transformation; \"perceptron coding\" = one linear transformation plus one nonlinearity; \"multi-layer neural network\"\u2026.etc). Although this is logical, the descriptions (e.g. \"vector space coding\") misleadingly imply that these are qualitatively distinct strategies for encoding a stimulus, and leave it to the reader to discover the logic of selecting these particular \"codes\"."
                }, 
                {
                    "type": "paragraph", 
                    "text": "\u2013 The paper by Bracci & de Boeck (2016) seems worth discussing in more detail, as it provides potential direct evidence for the hierarchy of smoothness. One wonders whether there are plausible alternative explanations that should be taken into account wrt varying levels of prediction accuracy across the ventral stream? For instance, the noise ceiling also often goes down (i.e. there is less signal to be explained in principle)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Reviewer #2:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "This paper addresses an interesting subject, that of what we can learn about the neural code from fMRI. The paper makes a valuable conceptual effort to think about which neural codes are supported by fMRI observations and which are not. Much as I like the paper and I think it is important to discuss these issues, I think that the connection between neural activity and fMRI, which should be central to this topic, is not sufficiently well discussed. My fear is that places of the current manuscript would look insufficiently developed to neurophysiologists investigating neural coding. In the following I raise the attention of the authors to what are in my view problems in the current manuscript that need addressing, and I provide a few suggestions. I hope that this will improve their paper."
                }, 
                {
                    "type": "paragraph", 
                    "text": "The current writing of the paper may be taken at specific places to argue that the success of fMRI implies that a coding scheme that does not come though fMRI is not one used by the brain to compute. (\"Through proof and simulation, we determine which coding schemes are plausible given both fMRI's successes and its limitations in measuring neural activity\"\u2026 \"The neural code must have certain properties for this state of affairs to hold. What kinds of models or computations are consistent with the success of fMRI?\" \u2026 \"The success of fMRI does not imply that the brain does not utilize precise timing information, but it does mean that such temporally demanding coding schemes cannot carry the day given the successes fMRI has enjoyed in understanding neural representations.\")"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Of course there would be no basis for such a strong claim, and the authors should state and discuss this clearly. It is for example possible that fMRI gets only a part of the neural code used by the brain, and that other parts, perhaps as important as others, are simply lost by the limitations of fMRI but are important for brain function. Another example of the possible dangers of this argument is reported in my comments about the temporal domain. I think that the authors should carefully reconsider how they write these statements."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Subsection \u201cSub-voxel Smoothness\u201d paragraph four: the problems related to temporal domain seem to be conceptualized in a way that is at odds with what we know of how fMRI is sensitive to the timing of neural population activity. The authors seem to put forward the idea that BOLD fMRI roughly corresponds to a firing rate averaged over long time windows, and that it will be insensitive to timing of spikes for example synchronous firing:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "\"BOLD will fail to measure other temporal coding schemes, such as neural coding chemes that rely on the precise timing of neural events, as required by accounts that posit that the synchronous firing of neurons is relevant to coding (Abeles, Bergman, Margalit, & Vaadia, 1993; Gray & Singer, 1989). Unless synchronous firing is accompanied by changes in activity that fMRI can measure, such as mean population activity, it will be invisible to fMRI\".. \"Because the BOLD signal roughly summates through time..\""
                }, 
                {
                    "type": "paragraph", 
                    "text": "This reasoning appears at odds with what concurrent recordings of neural activity and fMRI show. First, as the pioneering work of Logothetis et al. (Nature 2001) already revealed and many studies from his groups confirmed over the years, the BOLD correlates strongly with LFPs (a measure of mass synaptic activity) and it correlates with spike rates only when those correlate with LFPs. Second, the degree of millisecond-scale synchronization among neurons is not only picked by BOLD: it actually seems to be a primary correlate of fMRI BOLD, and much more so than the firing rate or multi-unit activity computed over long windows. One study of Logothetis group (Magri et al. J Neurosci 2012) showed that the primary correlate of BOLD is the \u03b3-band LFP power. \u0393 band power expressed the strength of local neural synchronization over a scales of few ms to one or two tens of ms. These results are also reported in human studies using EEG with fMRI (see Scheeringa et al. Neuron 2011)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "So, my suggestion is to rewrite completely the \"temporal dimension\" part of this paper. This can also serve as an example suggestion of how very dangerous it would be to rule out a coding scheme based considering the success of fMRI and its spatio-temporal limitations (see my comments above)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Reviewer #3:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Summary:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "The authors applied an fMRI data analysis method called representational similarity analysis (RSA) to artificial neural network data. They argued that neural code must be both sub-voxel smooth and functionally smooth for RSA to recover the neural similarities from fMRI data."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Comments:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "1) What is the definition of the term \"functional smoothness\"? In the \"Functional smoothness\" section, the authors only stated that factorial design coding and hash function coding are not functionally smooth, but neural network models are functional smooth. I only see examples but no definition."
                }, 
                {
                    "type": "paragraph", 
                    "text": "2) If the main contribution of the paper is that the neural code must be smooth for RSA method to decode. Then the authors should provide necessity and sufficiency proofs of this statement (Discussion section first paragraph): (1) if RSA can decode the similarity in the fMRI data, then the neural code must be sub- voxel smooth and functional smooth. (2) As long as the neural code is sub- voxel smooth and functional smooth, RSA can encode the similarity in the fMRI data."
                }, 
                {
                    "type": "paragraph", 
                    "text": "3) The authors should explain the reason they choose Deep Neural Network for their experiments. Friston 2003's dynamic causal model is a popular model for fMRI data simulation. Spiking neural network is another candidate used to study neural code. Please explain why Deep Neural Network is favorable for the experiments in this paper."
                }, 
                {
                    "type": "paragraph", 
                    "text": "4) Experimental detail is lacking. There is no methods section. I also tried to look at the code the author provided at <a href=\"http://osf.io/v8baz\">http://osf.io/v8baz</a>, but the access was forbidden. It seems like the code folder is private. So there is not much I can comment on the methods used in this paper."
                }
            ]
        }, 
        "authorResponse": {
            "doi": "10.7554/eLife.21397.009", 
            "content": [
                {
                    "type": "paragraph", 
                    "text": "<i>Essential revisions:</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>The three reviewers and I all agree that this paper raises an interesting set of questions. However, there were a number of concerns about the paper as it is currently written. Here are the main concerns as I see them, and how they should be addressed:</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>\u2013 Two reviewers raise the question of whether your claims are fully supported by the results, suggesting in many cases that you are making strong claims that are not fully supported by your results. I think that in general the revision needs to better calibrate the claims to the evidence, and avoid overreaching. In particular, the fact that fMRI is successful does not mean that it is capturing all, or even the majority, of interesting neural signals. This issue needs to be clearly addressed in the revision.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "As detailed below, we made an effort throughout the manuscript to qualify our claims. The changes, following the reviewers\u2019 suggestions, include being clear that the brain may use other coding schemes that are inconsistent with the success of fMRI. We make clear that our results do not rule out these coding schemes, but do suggest that the brain is using coding schemes that are to some extent consistent with fMRI\u2019s success. To flesh out this idea, we introduce the notion that the neural code could consist of a mixture of coding schemes and that at least some portion of this mixture is consistent with the success of fMRI."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>\u2013 The concept of \"functional smoothness\" is central to your manuscript, but the reviewers raised multiple questions regarding the clarity of this concept in your paper. The revision needs to be much clearer about what this concept means and how it relates more specifically to the other concepts of smoothness.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "As detailed below, we made substantial improvements that include formalizing functional smoothness as a straightforward equation and applying this measure to the simulation results. We also made an effort to improve the discussion of functional smoothness, as well as to disentangle it from related concepts."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>\u2013 Reviewer 2 points out that your paper needs to make better contact with the literature that has investigated the neural basis of the BOLD signal. In particular, specific attention must be paid to the points raised by reviewer 2 regarding the implications for temporal aspects of the BOLD signal.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We have incorporated all the literature that reviewer 2 suggested. In particular, reviewer 2\u2019s pointers helped us improve the subsection on the temporal aspects of the BOLD signal."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>\u2013 Reviewer 3 points out that the paper lacks methodological details, and that they were not able to access the materials linked at OSF. In the revision, please include a detailed description of your methods along with a working link to the code and materials.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We regret that the OSF repository was set to be private at the time of submission. We have made the repository public, which contains all scripts and readme files to guide the user. We also now provide complete methods to the simulations in the main text."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>I am including the reviewers' comments below, which provide greater detail regarding the issues outlined above.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Reviewer #1:</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>[\u2026]</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>1) What are the scopes of the claims being made?</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>One main issue with the paper is the precise nature of the central claim. This claim varies in scope throughout the paper from more modest and well-evidenced to more all-encompassing and arguably beyond the evidence put forth. The main claim can loosely be phrased as: The fact that fMRI writ large \u201cworks\u201d tells us something about the underlying neural mechanisms. The precise cashing out of this claim includes the following descriptions:</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Abstract \u201ccertain neural coding schemes are more likely than others\u201d (Plausible but not necessarily true).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Subsection \u201cSub-voxel Smoothness\u201d, \u201cthe rate of change (i.e., smoothness) of neural activity must not exceed what can be measured within a voxel.\u201d (This phrasing seems overly general \u2013 There is no reason why rates of change couldn't also exceed what can be measured. All that is compellingly shown is that a non-trivial part of the neural code behaves in a temporally smooth manner).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Thank you, we now make clear that multiple codes could coexist and that our results imply that the mixture will contain components with certain properties."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>In the same section \u201ctemporally demanding coding schemes cannot carry the day\u201d (Not clear what \u201ccarry the day\u201d means \u2013 If it means \u201cCan't fully explain all patterns\u201d then it is likely true and well supported, if it means 'temporally demanding coding schemes cannot play an important role also' I think it's too strong a claim).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Also in this section \u201cthe neural code must be spatially and temporally smooth with respect to neural activity\u201d (Overly general in that it implies there is only one neural code ('The')).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Edited."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Discussion section first paragraph \u201cthe neural code must be smooth, both at the sub-voxel and functional levels.\u201d (overly general \u2013 It can be smooth and non-smooth simultaneously to currently unknown degrees, e.g. <a href=\"#fig1\">Figure 1</a> left and right could be overlapping).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We revised <a href=\"#fig1\">Figure 1</a> and the supporting discussion to make the concepts clearer."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Discussion section paragraph ten \u201cHowever, fMRI's success might mean that when one is interested in the nature of computations carried out by the brain, the level of analysis where fMRI applies should be preferred.\u201d (A considerable overgeneralisation \u2013 All we know for sure is that fMRI can provide important information, but there is no reason why lower (or higher) levels of temporal or spatial abstraction can't be even more informative.).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "There were already qualifications in surrounding passages, but we have further tempered this statement."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>More limited and arguably more accurate are:</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>\u2013 Abstract section \u201cDeep neural network approaches, are consistent with the success of fMRI\u201d (True and well-supported).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>\u2013 Subsection \u201cSub-voxel Smoothness\u201d, \u201cThe success of fMRI does not imply that the brain does not utilize precise timing information\u201d (an important explication of the point raised above that multiple coding schemes could operate concurrently, and that fMRI would \u201cwork\u201d if it only picks up parts).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We agree and have increased discussion of what fMRI may be missing and the possibility of code mixtures."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Similarly in subsection \u201cFactorial Design Coding\u201d, discussing factorial coding, the authors state \u201cInterestingly, if any region in the brain had such a distribution of voxels, neural similarity would be impossible to recover by fMRI.\u201d And later \u201cIf the neural code for a region was employing a technique similar to factorial design, neuroimaging studies would never recover similarity structures by looking at the patterns of active voxels in that region.\u201d These statements are only true if other coding schemes aren't allowed to co-exist. It may well be that factorial coding schemes co-exist alongside spatially smooth codes but simply cannot be detected using current methods and/or analyses. Or, to couch it in terms of <a href=\"#fig1\">Figure 1</a>, there is no reason why the neural code might not be an overlay, or mixture, of A and B. This implicit suggestion that there must be a single coding scheme is reflected in the title, which refers to \u201cThe\u201d neural code.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "This is addressed in the mixture concept, as well as qualifying statements throughout to make clear such results would hold only if that were the \u201csole\u201d code used. One contribution of this paper is to work through the properties of several coding schemes with respect to the BOLD response. In some circumstances, it is helpful to consider the properties of single coding schemes in isolation for purposes of clarity, though we make clear that the brain may utilize mixtures."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>As can be seen when read in succession, these are not interchangeable epistemic claims \u2013 Some are \u201cmerely\u201d existence claims whereas others rule out alternative explanations.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>In our view, the main claim of that article, that is important and well supported, can be phrased as follows:</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>The success of fMRI makes it highly likely that at least some non-trivial subset of the signal/computations made by the neural code must be smooth.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Or, in the authors words \u201cOne general conclusion is that important aspects of the neural code are spatially and temporally smooth at the sub-voxel level\u201d.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>In other words, the article provides solid evidence for a more modest positive claim but at times shifts into language that suggests it has ruled out (or rendered exceedingly unlikely) other neural codes. We do not believe this is the case (nor, for that matter, do I think this is an achievable goal in the context of any single paper, for both principled mathematical reasons that every data pattern is compatible with an infinity of data generating mechanisms, and the pragmatic reasons of scope). In other words, we would suggest that the precise scope of the central claim is delineated more clearly, and that this scope is retained throughout</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We believe that the claims and the supporting evidence are now better aligned."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>2) Is \"sub-voxel smoothness\" an accurate and clear description of what is required for successful fMRI?</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>The other main challenge in the article is the introduction of two new terms, spatial and functional smoothness. It seems as though these are not entirely precisely defined, and to the extent that they are, one might wonder whether a) \u201csmoothness\u201d is the best term and b) what, if anything, is similar about spatial and functional smoothness such that they share a conceptual term. We outline these challenges below.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>With regards to spatial smoothness, I wonder whether the term inhomogeneity isn't more appropriate or central to the claim being made. For instance, it seems as though one could rearrange the voxel columns in <a href=\"#fig1\">Figure 1B</a> whilst preserving sub-voxel smoothness as well as functional smoothness \u2013 The arrangement of the voxels as a gradient could be misunderstood as being about super-voxel smoothness (especially in the light of evidence for early visual retinotopic mapping). (more detail below).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We are essentially in agreement, though perhaps this was not clear in the original submission. Indeed, we retitled a subsection \u201cVoxel Inhomogeneity Across Space and Time\u201d and have used this language throughout in light of your comments. Subvoxel smoothness in the original manuscript was motivated by the mathematical concept of smoothness, which involves \u201cclumpiness\u201d and lack of sharp discontinuities. In other words, the concept does not imply smooth global changes in responses and would be consistent with your thought experiment of rearranging elements. One peril in related thought experiments is assuming that the brain somehow \u201cknows\u201d the voxel size or that voxels favorably align."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>The paper distinguishes between the concepts of sub-voxel and super-voxel smoothness. These concepts appear to be independent \u2013 i.e. one could have subvoxel smoothness combined with non-smooth super-voxel patterns. i.e., it's not entirely clear why \u201cIn such a spatially smooth representation, the transitions from red to yellow occur in progressive increments\u201d follows necessarily from subvoxel smoothness? The later definition that voxel size can be changed arbitrarily does capture this, but for a *given* voxel size a pattern could be subvoxel smooth and super-voxel non-smooth. Note that the empirical examples outlines in subsection \u201cSub-voxel Smoothness\u201d are compelling evidence that sub and super-voxel smoothness are related, but in principle they needn't be (this point is made by the authors in subsection \u201cFunctional Smoothness\u201d with respect to functional smoothness).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>[\u2026]</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Picturing these four alternatives, it seems that in order for different stimuli to create different patterns at the level of fMRI voxels, the important factor is neither sub-voxel nor super-voxel smoothness, but something which might be termed \"across-voxel inhomogeneity\" \u2013 i.e. that different voxels sample populations of neurons with different functional properties. For example, in the example just suggested, wherein the \u201ccolumns\u201d of the left-hand panel are shuffled, there would no longer be a smooth gradient in the functional selectivities of voxels as one moves across the cortical sheet, but different stimuli could still evoke unique multi-voxel patterns.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We now better define functional smoothness, going as far as to formalize it. We made an effort in the original manuscript to note how functional and super-voxel smoothness were distinct, which is what motivated the inclusion of <a href=\"#fig4\">Figure 4</a> (now <a href=\"#fig3\">Figure 3</a>). We now go further throughout and have added a paragraph discussing how these concepts diverge (subsection \u201cFunctional Smoothness\u201d)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "We also discussed the importance of voxel size in the original manuscript, but these points were too obscured. We now highlight these points more (subsection \u201cVoxel Inhomogeneity Across Space and Time\u201d) and have amended the <a href=\"#fig1\">Figure 1</a> example to demonstrate the role of voxel size. This might be a case of agreement that was not made sufficiently clear in the original manuscript."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>It is important here to engage with previous literature on fMRI decoding, especially Kamitani &amp; Tong (2005) and subsequent reflections on why stimulus orientation can be decoded from V1 via fMRI (e.g. Alink et al. 2013; Carlson, 2014). Orientation columns in V1 are arranged in a similar fashion to the \"sub-voxel non-smooth\" depiction in <a href=\"#fig1\">Figure 1</a>, yet orientation can reliably be decoded. One plausible reason is that the chance of each voxel sampling all orientation selectivities exactly equally is very low, so even if neuronal selectivities are intermixed at a sub-voxel level, slight differences in orientation preference are likely to emerge at the voxel level.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We enjoyed reading these papers and now cite Kamitani and Tong (2005) and Alink et al. (2013) as additional examples of successful decoding."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>The caption of <a href=\"#fig1\">Figure 1</a> suggests non-smoothness is preserved \u201cregardless of the precise boundaries of the voxels which quantize the brain\u201d but it seems that this would only be true conditional on preserving approximate voxel size? If I am allowed to change both the size and boundaries I could create mostly-yellow and mostly-red voxels from <a href=\"#fig1\">Figure 1B</a>? Moreover, as mentioned above, random variations in sampling can lead to successful decoding of schemes similar to the non-smooth pattern.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Issues of voxel size are covered above."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Sub-voxel smoothness might not be the most intuitive term to use, not only for the reasons mentioned under point 2, but also because it implies spatial and not temporal smoothness. It seems more appropriate to talk about spatial and temporal scales at which useful information (about stimuli, thoughts, actions) is represented by brain activity.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "This issue has also been covered above."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>3) \"Functional smoothness\" is a relational property between two models or between data and a model, not an inherent property of one model.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Arguably the most challenging term introduced by the paper is \"functional smoothness.\" It is not made clear what this is a property of. From the definition, that \"similar stimuli map to similar representations,\" a model is \"functionally smooth\" with respect to some second representational model if it preserves the representational geometry of that target model. In the first set of simulations involving noise-corrupted images, the target model is pixel space. In the second set of simulations involving objects of different categories being presented to a deep neural network, the target model is a semantic or conceptual space. In other words, functional smoothness is not an objective property of the model, but a relational property between an input and an output space. This seems to be recognised in some sections, e.g. subsection \u201cVector Space Coding\u201d: \"vector space coding is functionally smooth in the trivial sense as the function is identity.\"</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We now make the definition of functional smoothness more clear and discuss after the definition how it can apply."
                }, 
                {
                    "type": "paragraph", 
                    "text": "We also removed the random network simulations involving images and instead report the simulations with the Gaussian vectors. We only included the simulations with the images because we thought they would be more intuitive, but that seems to not be the case and they might lead to confusion in some readers with the deep learning simulations that classify photographs."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>However, many other phrases in the paper imply that smoothness is intrinsic to models, e.g.:</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>\u2013 subsection \u201cDeep Learning Networks\u201d: \"one key question is whether functional smoothness breaks down at more advanced layers in DLNs\u2026\"</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>\u2013 subsection \u201cDeep Learning Network Simulation\u201d: \"We consider whether functional smoothness declines as stimuli progress to more advanced layers\u2026\"</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>\u2013 and: \"Violating functional smoothness, all other similarity structure is discarded\u2026\"</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "These issues are addressed in a comment above."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>The simulations underlying <a href=\"#fig2\">Figures 2</a> and <a href=\"#fig3\">3</a> add to this confusion rather than illustrating functional smoothness. Presumably the weights within the weight matrices used in the models from \"matrix multiplication coding\" onwards were random? If so, then <a href=\"#fig3\">Figure 3</a> seems to illustrate the trivial effect that as one performs increasingly many random nonlinear transformations on an input, distances between stimuli in the input space will be less and less well correlated with distances in the output. This result doesn't seem to reveal anything fundamental about the merit of (non-random) deep nonlinear networks as models of brain representation.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We made the methods for these simulations more clear. Yes, the random network simulations show that functional smoothness will break down, even in an untrained network, such that more advanced layers should be harder to recover similarity spaces from using fMRI. Prior to this paper, I don\u2019t think people appreciated the basic geometry of projecting vectors repeatedly would have these effects as every neural network paper we have read focuses on the role of training! Correspondingly, imaging researchers speak of the signal to noise ratio or noise ceiling of various regions as if these are basic properties of those regions as opposed to a consequence of receiving input that has been several times over quasi-linearly transformed."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>To highlight the fact that functional smoothness is a relational property, it might instead be helpful to create a simulation akin to these, but using a trained network, and adding noise in a more abstract \"target space\" (e.g. noise could be added to the location of an object within an image, for example by sliding around the location of a dog image superimposed on a natural background). The earliest layer of the network should be \"functionally smooth\" w.r.t. changes in pixels but not location (i.e. pixelwise differences will make a large difference to early representations); middle layers may be \"functionally smooth\" w.r.t. location but not pixels (e.g. the same dog at nearby locations will activate the same feature detectors looking for eyes, legs, etc), while the final categorical layer would ideally be wholly invariant both to pixel and location changes provided the image continues to contain a dog.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "I think the simulations should now be clearer as we have replaced the dog and truck image inputs with vectors drawn from a Gaussian."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>It would also help to distinguish between coding schemes that have the capacity to be functionally smooth, vs. those that actually functionally smooth, with respect to a particular input space. Factorial and hash coding are raised as examples of codes that are \"not functionally smooth,\" while neural-network-style encodings of various complexity are evaluated for whether the simulated examples happen to be functionally smooth with respect to the input spaces (pixel space, then semantic similarity space). However, there is an important difference in the sense in which factorial coding is \"not functionally smooth\" and that in which the late layers of GoogLeNet are not \u2013 factorial and hash coding are not capable of being functionally smooth (because every representation is orthogonal to every other), whereas the neural networks considered are capable in principle of strongly preserving the representational geometry of any input space desired (although see Point 6).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Interestingly, the neural networks essentially do hash coding as additional layers are added. We note this connection in two places in the manuscript, final paragraph of subsection \u201cHash Function Coding\u201d and Discussion section paragraph three. Like the neural networks, intermediate steps in a hash coding algorithm may be functionally smooth with only the end step non-smooth,"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>4) What is the relationship, if any, between spatial and functional smoothness?</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>It seems as if spatial and functional smoothness, as defined in the paper, should be completely independent of one another, and they are described in paragraph two of subsection \u201cFunctional Smoothness\u201d as \"distinct concepts.\" However:</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Subsection \u201cMatrix Multiplication Coding\u201d: \"\u2026the internal representation of this coding scheme is completely nonsensical to the human eye and is not super-voxel smooth.\"</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>This is confusing for two reasons. First, there is no reason for any internal representation to be \"sensible to the human eye.\" The fact that the input representation is \"sensible\" is just an artefact of using images as the inputs. Even then, the image is only understandable by the eye if one preserves the exact spatial order of units and arranges them into rows and columns of exactly the right dimensions. Any shuffling or re-arrangement of the pixels would constitute an identical representation, and yet would no longer be sensible to the eye \u2013 so sensibility to the eye does not seem relevant.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "You are grasping our intended point perfectly \u2013 that figure and caption were included to demonstrate a case in which functional smoothness is preserved but super-voxel smoothness is not. We now make this clearer, as well as expand on the differences between these concepts. Particular care was paid to this issue in the section on Voxel Inhomogeneity Across Space and Time and in the caption of what is now <a href=\"#fig3\">Figure 3</a>."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Second, how does this minimal model (a transformation of the input by a single matrix multiplication) specify properties about the spatial arrangement of voxels? Paragraph two subsection \u201cFunctional Smoothness\u201d states that functional smoothness is defined at the level of voxels (although this seems a little counter-intuitive, since brains and neural networks encode information at the level of neurons). So in the \"matrix multiplication code,\" we should imagine a case where there are as many voxels in the output as there are pixels in the input image, and the activation level of each one is determined by an arbitrary linear combination of all input pixels. This output will be \"functionally smooth\" w.r.t. pixel space if the matrix transformation is one that preserves representational geometry (e.g. a rotation matrix; see first comment under \"Smaller points\" below for more on this\u2026). This will be true however one arranges the voxels spatially. Some possible arrangements will appear super-voxel smooth (e.g. if voxels are placed next to those with the most similar selectivities), and some will not (e.g. if voxels are randomly placed), but all arrangements will be functionally smooth.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We moved away from the images in the random networks to reduce this confusion."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>If there is some deeper connection between functional and spatial smoothness, this needs to be more clearly explained and illustrated.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Thank you, as mentioned above this was one of the major revisions of the paper. We also view it as critical to make this distinction clear."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>5) Different neural code properties may be required for \"successful fMRI\" when doing mean-activation vs. decoding vs. representational similarity analyses.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>The title-bearing central claim refers to the \u201csuccess\u201d of brain imaging, but it is not entirely clear how this should be conceived. It might be worth briefly describing what counts as success, and how each result constrains possible neural codes. For example, it would be good to separately consider what findings from (1) old school mean-activation \u201cblobology\u201d, (2) classifiers performing above chance, (3) RSA imply about neural coding. It seems uncontroversial that all require \"temporal smoothness\" and some form of across-voxel spatial inhomogeneity in order for different stimuli to create detectably different fMRI activations. But they may have different further implications, for example:</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>1) The success of \"blobology\" in finding multi-voxel clusters with similar functional properties suggests some degree of super-voxel smoothness.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>2) Above-chance decoding does not seem to even require a neural code capable of functional smoothness. E.g. in a factorial code, although every stimulus elicits a pattern orthogonal to that elicited by any other, one could still do successful \"mind-reading\" as long as one had access to data from previous trials on which subjects had viewed that stimulus.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>3) The success of RSA (i.e. finding interesting and nuanced similarity patterns between patterns evoked by different stimuli, which seem to bear some relation to the geometry of those stimuli within other models such as pixel space or semantic space and can be compared to predictions from computational models) does require a neural code which is capable of functional smoothness. The importance of functional smoothness only to RSA does seem to be recognised in the paper, but could be made more explicit, e.g.:</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "These are good points which we tried to bring forward throughout and in particular in an added paragraph in the Discussion, paragraph seven."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Subsection \u201cFactorial Design Coding\u201d paragraph five: \"If the neural code for a region was employing a technique similar to factorial design, neuroimaging studies would never recover similarity structures by looking at the patterns of active voxels in that region.\"</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>One thing to note here is that model comparisons do not necessarily require RSA. Does the success of other analysis methods that compare models (e.g. voxel-receptive-field modelling) also point to functional smoothness? Or is this term strongly linked to RSA as an analysis framework, to the extent that it does not have a meaning outside it? If so, why do the authors focus so strongly on functional smoothness? (RSA is successful, but so are (linear) classifiers).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We focused on recovering similarity spaces, but do discuss the implications for other analysis approaches in the aforementioned added Discussion paragraph."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>6) Simulations with a network trained on a task other than categorisation would help justify the claim that \"non-smoothness\" is an inevitable property of deep nonlinear neural networks.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>The final simulations, in which distances within a \u201csemantic space\u201d are informally compared to distances within successive layers of the deep neural network GoogLeNet, conclude that later layers are less functionally smooth w.r.t. semantic space than early ones (since they lose between-category similarity information), and that \u201cthe decline in functional smoothness at later layers does not appear to be a straightforward consequence of training these networks to classify stimuli.\u201d This latter conclusion is likely to be controversial, and is not strongly supported by the sparsity analysis.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>The simplest way to clarify the contribution of the training task to the representational geometry in the final layers would be to show RDMs from (a) randomly-weighted networks, and (b) an unsupervised network, or one trained on a task orthogonal to categorisation. A good candidate would be the unsupervised seven layer neural network in Wang &amp; Gupta (2015), which is available from <a href=\"https://github.com/xiaolonw/caffe-video_triplet\">https://github.com/xiaolonw/caffe-video_triplet</a> </i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Again though, this would not reveal anything about the \"functional smoothness of the model,\" since that is not an inherent property, but only the similarity between the representations within the model and in semantic space.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "This was a very nice suggestion. We spent some weeks getting their code to run and made some interesting discoveries. In this literature, classification decisions are made by unsupervised networks by first training the networks on unlabelled data (i.e., unsupervised learning). The final layer of such networks is then considered to have distilled the meaning of the image. To evaluate the performance of the unsupervised network, a simple classifier is then trained using this final layer as input. Wang and Gupta did not include this critical component in their code repository, but we corresponded with them extensively on email to discuss the myriad of ways in which they boosted performance with their network."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Unfortunately, the bottom line is that their unsupervised network coupled with a classifier operating over the final layer only retrieves the correct label for an image in its top 20 guesses 40% of the time, which is not in the same league as InceptionV3 model which achieves 97% accuracy in only its top 5 guesses. In short, we can\u2019t use this mostly unsupervised network to compare to the supervised network because it can\u2019t properly classify images. In light of their model\u2019s troubles, we made an edit to our discussion unsupervised methods that now focuses on performance rather than scope."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>7) Previous work</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>One key feature missing from this paper is closer engagement with previous literature on decoding, such as the seminal findings in Kamitani &amp; Tong (2005) (discussed above in Point 2), computational accounts (e.g. Kriegeskorte, N., Cusack, R., &amp; Bandettini, P. (2010) or de Beeck, H. P. O. (2010), and those discussing the plausibility of more trivial structural explanations such as differences in vasculature (e.g. Shmuel, A., Chaimow, D., Raddatz, G., Ugurbil, K., &amp; Yacoub, E. (2010)).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We included some of this work in places where we could find a fit."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Miscellaneous</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Subsection \u201cMatrix Multiplication Coding\u201d states \u201cMatrix multiplication maps similar inputs to similar internal representations.\u201d The claim seems to refer to multiplication of a 1xn input by an arbitrary nxn matrix (such as would be implemented by a 1-layer fully connected linear neural network). Although there are some such matrix multiplications which would perfectly preserve distances between different inputs in their original vs. transformed spaces (e.g. rotation matrices), and with random matrices, distances in the original and transformed spaces will tend to correlate (as your simulations show), the claim is not generally true. There are many matrix multiplications which will completely disrupt representational geometry.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "The methods now make clear that the matrices were random, which makes it extremely unlikely they will be rank deficient. As a further safeguard, the simulation results are averaged over 100 different networks, which is now made clear in the methods description."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Subsection \u201cDeep Learning Network Simulation\u201d paragraph three states that sparseness of representation does not decline for a \"later advanced layer\" of the category-supervised deep neural net. Which layer is this? It seems surprising that sparseness does not increase in at least the final layer (i.e. the output of the softmax operation). Relatedly, is it worth showing more layers in Figure 5? If not, why are these two layers shown?</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We tried to keep it simple and ensure that the comparison was not biased in our favor. We chose these layers because sparsity (which we quantified with the Gini coefficient) goes against our hypothesis. We also tried to compare two layers that had the same structure (both pooling layers) to make sure we were comparing apples to apples. We didn\u2019t explicitly number the layers because the architecture of the model is so complicated that three people may number the layers three different ways. Fortunately, the OSF repository and code makes clear which structures we used from InceptionV3 for those interested."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Related to Point 3 above, it would help to use more precise language about the nature of the sensory inputs or brain representations being discussed. For example, subsection \u201cMatrix Multiplication Coding\u201d says that a particular coding scheme \"takes an input stimulus (e.g. a dog) and multiplies it by a weight matrix\" \u2013 given that a dog is not the sort of thing that can be multiplied by a weight matrix, does this mean either (specifically) an image of a dog, or (generally) the activity within a preceding layer of neurons in a neural network model? Referring to the (arbitrary) input images in the simulations as \"prototypes\" is also confusing, as it suggests they have some special status to the models.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Fixed. Again, we switched to Gaussian vectors here to avoid such confusions. We do retain the one figure with the image matrix multiplication because it makes it easier to see that even when the network states look \u201cscrambled\u201d they actually preserve functional smoothness, which was discussed above."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>\u2013 Although I like the hash coding example in subsection \u201cHash Function Coding\u201d says it's \u201cpotentially useful for biological systems\u201d \u2013 it might be worth elaborating briefly in what circumstances a biological system would evolve something akin to hashcoding for certain stimuli? It seems rather inefficient and hard to reconcile with basic facts about learning (e.g. co-occurrence increasing association strengths, and thereby similarity) and memory (e.g. semantic co-activation)? I appreciate the later evidence for the compatibility of higher layers with hash coding but the above claim seems more general \u2013 This relates to the above discussion on what.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We mention one possible mental function in the final paragraph of subsection \u201cHash Function Coding\u201d."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>\u2013 The selection of coding schemes cover interesting (and rhetorically convincing) ground but the motivation for this set of coding schemes doesn't seem to be motivated. E.g., why focus on hash coding and factorial mapping \u2013 Are those a subset of a broader range that could be considered? Something similar could be said about the selection of NN algorithms. The selection of codes seems to constitute an input being transformed by successively more complex neural networks (\"vector space coding\" = no transformation of the input; \"gain control coding\" = one nonlinearity; \"matrix multiplication coding\" = one linear transformation; \"perceptron coding\" = one linear transformation plus one nonlinearity; \"multi-layer neural network\"\u2026.etc). Although this is logical, the descriptions (e.g. \"vector space coding\") misleadingly imply that these are qualitatively distinct strategies for encoding a stimulus, and leave it to the reader to discover the logic of selecting these particular \"codes\".</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We chose popular coding schemes and models that helped illustrate the key concepts. We state in subsection \u201cVector Space Coding\u201d that the neural network models are all components that can be assembled to form one larger model, as opposed to distinct coding strategies. Hopefully, this nicely transitions to the deep learning network simulation."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>\u2013 The paper by Bracci &amp; de Boeck (2016) seems worth discussing in more detail, as it provides potential direct evidence for the hierarchy of smoothness. One wonders whether there are plausible alternative explanations that should be taken into account wrt varying levels of prediction accuracy across the ventral stream? For instance, the noise ceiling also often goes down (i.e. there is less signal to be explained in principle).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We agree and actually mention this work both in the original submission and revision (Discussion section paragraph six). We suggest that our work may help explain this noise ceiling."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Reviewer #2:</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>This paper addresses an interesting subject, that of what we can learn about the neural code from fMRI. The paper makes a valuable conceptual effort to think about which neural codes are supported by fMRI observations and which are not. Much as I like the paper and I think it is important to discuss these issues, I think that the connection between neural activity and fMRI, which should be central to this topic, is not sufficiently well discussed. My fear is that places of the current manuscript would look insufficiently developed to neurophysiologists investigating neural coding. In the following I raise the attention of the authors to what are in my view problems in the current manuscript that need addressing, and I provide a few suggestions. I hope that this will improve their paper.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>The current writing of the paper may be taken at specific places to argue that the success of fMRI implies that a coding scheme that does not come though fMRI is not one used by the brain to compute. (\"Through proof and simulation, we determine which coding schemes are plausible given both fMRI's successes and its limitations in measuring neural activity\"\u2026 \"The neural code must have certain properties for this state of affairs to hold. What kinds of models or computations are consistent with the success of fMRI?\" \u2026 \"The success of fMRI does not imply that the brain does not utilize precise timing information, but it does mean that such temporally demanding coding schemes cannot carry the day given the successes fMRI has enjoyed in understanding neural representations.\").</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "As mentioned in response to reviewer 1, we have made efforts to moderate these claims."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Of course there would be no basis for such a strong claim, and the authors should state and discuss this clearly. It is for example possible that fMRI gets only a part of the neural code used by the brain, and that other parts, perhaps as important as others, are simply lost by the limitations of fMRI but are important for brain function. Another example of the possible dangers of this argument is reported in my comments about the temporal domain. I think that the authors should carefully reconsider how they write these statements.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Thank you. We have done so and made an effort throughout to correct the tone and try to find the balancing point between claims and supporting evidence."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Subsection \u201cSub-voxel Smoothness\u201d paragraph four: the problems related to temporal domain seem to be conceptualized in a way that is at odds with what we know of how fMRI is sensitive to the timing of neural population activity. The authors seem to put forward the idea that BOLD fMRI roughly corresponds to a firing rate averaged over long time windows, and that it will be insensitive to timing of spikes for example synchronous firing:</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>\"BOLD will fail to measure other temporal coding schemes, such as neural coding chemes that rely on the precise timing of neural events, as required by accounts that posit that the synchronous firing of neurons is relevant to coding (Abeles, Bergman, Margalit, &amp; Vaadia, 1993; Gray &amp; Singer, 1989). Unless synchronous firing is accompanied by changes in activity that fMRI can measure, such as mean population activity, it will be invisible to fMRI\".. \"Because the BOLD signal roughly summates through time..\"</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "This was not our intent and these passages have been heavily edited in response to reviewer 2\u2019s comments. The overarching intended point was that BOLD will be blind to such temporal coding schemes unless they have a correlate that BOLD is sensitive to."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>This reasoning appears at odds with what concurrent recordings of neural activity and fMRI show. First, as the pioneering work of Logothetis et al. (Nature 2001) already revealed and many studies from his groups confirmed over the years, the BOLD correlates strongly with LFPs (a measure of mass synaptic activity) and it correlates with spike rates only when those correlate with LFPs. Second, the degree of millisecond-scale synchronization among neurons is not only picked by BOLD: it actually seems to be a primary correlate of fMRI BOLD, and much more so than the firing rate or multi-unit activity computed over long windows. One study of Logothetis group (Magri et al. J Neurosci 2012) showed that the primary correlate of BOLD is the \u03b3-band LFP power. \u0393 band power expressed the strength of local neural synchronization over a scales of few ms to one or two tens of ms. These results are also reported in human studies using EEG with fMRI (see Scheeringa et al. Neuron 2011).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We have reworked the discussion to center upon these contributions. One point that we enjoyed in Magri et al. (2012) that is now a center point of this section is that different mixes of activity at different bands can lead to an identical BOLD response. These kinds of points are exactly what we tried to bring out in this section in the original manuscript. We now believe we are more successful in doing so."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>So, my suggestion is to rewrite completely the \"temporal dimension\" part of this paper. This can also serve as an example suggestion of how very dangerous it would be to rule out a coding scheme based considering the success of fMRI and its spatio-temporal limitations (see my comments above).</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "That was always part of our intended message, which should now be clearer. At a very broad level, we needed to bring out these issues clearly because establishing these views makes it surprising (i.e., informative) at some level that BOLD is useful in recovering similarity spaces, despite limitations in what it measures."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Reviewer #3:</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Summary:</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>The authors applied an fMRI data analysis method called representational similarity analysis (RSA) to artificial neural network data. They argued that neural code must be both sub-voxel smooth and functionally smooth for RSA to recover the neural similarities from fMRI data.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "Thank you for your time and useful input. As discussed below, we have improved the formal presentation in light of reviewer 3\u2019s comments."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>Comments:</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>1) What is the definition of the term \"functional smoothness\"? In the \"Functional smoothness\" section, the authors only stated that factorial design coding and hash function coding are not functionally smooth, but neural network models are functional smooth. I only see examples but no definition.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We tried to be clear, but at times a formal definition is useful. We now offer a formal definition (Equation 1) and apply this measure to the simulations. For example, the measure of functional smoothness does decline as layers in a neural network are traversed."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>2) If the main contribution of the paper is that the neural code must be smooth for RSA method to decode. Then the authors should provide necessity and sufficiency proofs of this statement (Discussion section first paragraph): (1) if RSA can decode the similarity in the fMRI data, then the neural code must be sub- voxel smooth and functional smooth. (2) As long as the neural code is sub- voxel smooth and functional smooth, RSA can encode the similarity in the fMRI data.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We now make clear that similarity spaces by definition require functional smoothness (Equation 1). We discuss how RSA solutions and decoding solutions without functional smoothness would be degenerate in that any positive results would need to be driven by self-similarity."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>3) The authors should explain the reason they choose Deep Neural Network for their experiments. Friston 2003's dynamic causal model is a popular model for fMRI data simulation. Spiking neural network is another candidate used to study neural code. Please explain why Deep Neural Network is favorable for the experiments in this paper.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We now explain the motivation for this choice on subsection \u201cDeep Learning Networks\u201d. Importantly, these models are not only simulating neural data, but are actually completing the behavioral task (in this case object recognition) at human-level proficiency."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>4) Experimental detail is lacking. There is no methods section. I also tried to look at the code the author provided at <a href=\"http://osf.io/v8baz\">http://osf.io/v8baz</a>, but the access was forbidden. It seems like the code folder is private. So there is not much I can comment on the methods used in this paper.</i>"
                }, 
                {
                    "type": "paragraph", 
                    "text": "We apologise for not making the repository public at the time of submission. It is now public with all code fully documented. We also have provided full methods for the simulations in the main text."
                }
            ]
        }, 
        "stage": "published", 
        "statusDate": "2099-01-01T00:00:00Z"
    }
}