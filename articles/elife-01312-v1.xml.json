{
    "journal": {
        "id": "eLife", 
        "title": "eLife", 
        "issn": "2050-084X"
    }, 
    "snippet": {
        "status": "vor", 
        "id": "01312", 
        "version": 1, 
        "type": "research-article", 
        "doi": "10.7554/eLife.01312", 
        "authorLine": "Dan FM Goodman et al", 
        "title": "Decoding neural responses to temporal cues for sound localization", 
        "published": "2013-12-03T00:00:00Z", 
        "versionDate": "2013-12-03T00:00:00Z", 
        "volume": 2, 
        "elocationId": "e01312", 
        "pdf": "https://publishing-cdn.elifesciences.org/01312/elife-01312-v1.pdf", 
        "subjects": [
            {
                "id": "neuroscience", 
                "name": "Neuroscience"
            }
        ], 
        "researchOrganisms": [
            "None"
        ], 
        "abstract": {
            "doi": "10.7554/eLife.01312.001", 
            "content": [
                {
                    "type": "paragraph", 
                    "text": "The activity of sensory neural populations carries information about the environment. This may be extracted from neural activity using different strategies. In the auditory brainstem, a recent theory proposes that sound location in the horizontal plane is decoded from the relative summed activity of two populations in each hemisphere, whereas earlier theories hypothesized that the location was decoded from the identity of the most active cells. We tested the performance of various decoders of neural responses in increasingly complex acoustical situations, including spectrum variations, noise, and sound diffraction. We demonstrate that there is insufficient information in the pooled activity of each hemisphere to estimate sound direction in a reliable way consistent with behavior, whereas robust estimates can be obtained from neural activity by taking into account the heterogeneous tuning of cells. These estimates can still be obtained when only contralateral neural responses are used, consistently with unilateral lesion studies."
                }
            ]
        }, 
        "copyright": {
            "license": "CC-BY-3.0", 
            "holder": "Goodman et al", 
            "statement": "This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use and redistribution provided that the original author and source are credited."
        }, 
        "authors": [
            {
                "type": "person", 
                "name": {
                    "preferred": "Dan FM Goodman", 
                    "index": "Goodman, Dan FM"
                }, 
                "affiliations": [
                    {
                        "name": [
                            "Laboratoire de Psychologie de la Perception", 
                            "CNRS and Universit\u00e9 Paris Descartes"
                        ], 
                        "address": {
                            "formatted": [
                                "Paris", 
                                "France"
                            ], 
                            "components": {
                                "locality": [
                                    "Paris"
                                ], 
                                "country": "France"
                            }
                        }
                    }, 
                    {
                        "name": [
                            "D\u00e9partement d\u2019Etudes Cognitives", 
                            "Ecole Normale Sup\u00e9rieure"
                        ], 
                        "address": {
                            "formatted": [
                                "Paris", 
                                "France"
                            ], 
                            "components": {
                                "locality": [
                                    "Paris"
                                ], 
                                "country": "France"
                            }
                        }
                    }
                ], 
                "emailAddresses": [
                    "dan_goodman@meei.harvard.edu"
                ], 
                "contribution": "DFMG, Wrote and carried out simulations, Conception and design, Analysis and interpretation of data, Drafting or revising the article", 
                "competingInterests": "The authors declare that no competing interests exist."
            }, 
            {
                "type": "person", 
                "name": {
                    "preferred": "Victor Benichoux", 
                    "index": "Benichoux, Victor"
                }, 
                "affiliations": [
                    {
                        "name": [
                            "Laboratoire de Psychologie de la Perception", 
                            "CNRS and Universit\u00e9 Paris Descartes"
                        ], 
                        "address": {
                            "formatted": [
                                "Paris", 
                                "France"
                            ], 
                            "components": {
                                "locality": [
                                    "Paris"
                                ], 
                                "country": "France"
                            }
                        }
                    }, 
                    {
                        "name": [
                            "D\u00e9partement d\u2019Etudes Cognitives", 
                            "Ecole Normale Sup\u00e9rieure"
                        ], 
                        "address": {
                            "formatted": [
                                "Paris", 
                                "France"
                            ], 
                            "components": {
                                "locality": [
                                    "Paris"
                                ], 
                                "country": "France"
                            }
                        }
                    }
                ], 
                "contribution": "VB, Recorded HRTFs, Acquisition of data", 
                "competingInterests": "The authors declare that no competing interests exist."
            }, 
            {
                "type": "person", 
                "name": {
                    "preferred": "Romain Brette", 
                    "index": "Brette, Romain"
                }, 
                "affiliations": [
                    {
                        "name": [
                            "Laboratoire de Psychologie de la Perception", 
                            "CNRS and Universit\u00e9 Paris Descartes"
                        ], 
                        "address": {
                            "formatted": [
                                "Paris", 
                                "France"
                            ], 
                            "components": {
                                "locality": [
                                    "Paris"
                                ], 
                                "country": "France"
                            }
                        }
                    }, 
                    {
                        "name": [
                            "D\u00e9partement d\u2019Etudes Cognitives", 
                            "Ecole Normale Sup\u00e9rieure"
                        ], 
                        "address": {
                            "formatted": [
                                "Paris", 
                                "France"
                            ], 
                            "components": {
                                "locality": [
                                    "Paris"
                                ], 
                                "country": "France"
                            }
                        }
                    }
                ], 
                "emailAddresses": [
                    "romain.brette@ens.fr"
                ], 
                "contribution": "RB, Conception and design, Analysis and interpretation of data, Drafting or revising the article", 
                "competingInterests": "The authors declare that no competing interests exist."
            }
        ], 
        "funding": {
            "awards": [
                {
                    "id": "par-1", 
                    "source": {
                        "name": [
                            "European Research Council"
                        ]
                    }, 
                    "awardId": "ERC StG 240132", 
                    "recipients": [
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Dan FM Goodman", 
                                "index": "Goodman, Dan FM"
                            }
                        }, 
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Victor Benichoux", 
                                "index": "Benichoux, Victor"
                            }
                        }, 
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Romain Brette", 
                                "index": "Brette, Romain"
                            }
                        }
                    ]
                }, 
                {
                    "id": "par-2", 
                    "source": {
                        "name": [
                            "Agence Nationale de la Recherche"
                        ]
                    }, 
                    "awardId": "ANR-11-BSH2-0004, ANR-11-0001-02 PSL* and ANR-10-LABX-0087", 
                    "recipients": [
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Dan FM Goodman", 
                                "index": "Goodman, Dan FM"
                            }
                        }, 
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Victor Benichoux", 
                                "index": "Benichoux, Victor"
                            }
                        }, 
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Romain Brette", 
                                "index": "Brette, Romain"
                            }
                        }
                    ]
                }
            ], 
            "statement": "The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication."
        }, 
        "impactStatement": "Computer simulations of interaural time difference decoders show that heterogeneous tuning of binaural neurons leads to accurate sound localization in natural environments."
    }, 
    "article": {
        "status": "vor", 
        "id": "01312", 
        "version": 1, 
        "type": "research-article", 
        "doi": "10.7554/eLife.01312", 
        "authorLine": "Dan FM Goodman et al", 
        "title": "Decoding neural responses to temporal cues for sound localization", 
        "published": "2013-12-03T00:00:00Z", 
        "versionDate": "2013-12-03T00:00:00Z", 
        "volume": 2, 
        "elocationId": "e01312", 
        "pdf": "https://publishing-cdn.elifesciences.org/01312/elife-01312-v1.pdf", 
        "subjects": [
            {
                "id": "neuroscience", 
                "name": "Neuroscience"
            }
        ], 
        "researchOrganisms": [
            "None"
        ], 
        "abstract": {
            "doi": "10.7554/eLife.01312.001", 
            "content": [
                {
                    "type": "paragraph", 
                    "text": "The activity of sensory neural populations carries information about the environment. This may be extracted from neural activity using different strategies. In the auditory brainstem, a recent theory proposes that sound location in the horizontal plane is decoded from the relative summed activity of two populations in each hemisphere, whereas earlier theories hypothesized that the location was decoded from the identity of the most active cells. We tested the performance of various decoders of neural responses in increasingly complex acoustical situations, including spectrum variations, noise, and sound diffraction. We demonstrate that there is insufficient information in the pooled activity of each hemisphere to estimate sound direction in a reliable way consistent with behavior, whereas robust estimates can be obtained from neural activity by taking into account the heterogeneous tuning of cells. These estimates can still be obtained when only contralateral neural responses are used, consistently with unilateral lesion studies."
                }
            ]
        }, 
        "copyright": {
            "license": "CC-BY-3.0", 
            "holder": "Goodman et al", 
            "statement": "This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use and redistribution provided that the original author and source are credited."
        }, 
        "authors": [
            {
                "type": "person", 
                "name": {
                    "preferred": "Dan FM Goodman", 
                    "index": "Goodman, Dan FM"
                }, 
                "affiliations": [
                    {
                        "name": [
                            "Laboratoire de Psychologie de la Perception", 
                            "CNRS and Universit\u00e9 Paris Descartes"
                        ], 
                        "address": {
                            "formatted": [
                                "Paris", 
                                "France"
                            ], 
                            "components": {
                                "locality": [
                                    "Paris"
                                ], 
                                "country": "France"
                            }
                        }
                    }, 
                    {
                        "name": [
                            "D\u00e9partement d\u2019Etudes Cognitives", 
                            "Ecole Normale Sup\u00e9rieure"
                        ], 
                        "address": {
                            "formatted": [
                                "Paris", 
                                "France"
                            ], 
                            "components": {
                                "locality": [
                                    "Paris"
                                ], 
                                "country": "France"
                            }
                        }
                    }
                ], 
                "emailAddresses": [
                    "dan_goodman@meei.harvard.edu"
                ], 
                "contribution": "DFMG, Wrote and carried out simulations, Conception and design, Analysis and interpretation of data, Drafting or revising the article", 
                "competingInterests": "The authors declare that no competing interests exist."
            }, 
            {
                "type": "person", 
                "name": {
                    "preferred": "Victor Benichoux", 
                    "index": "Benichoux, Victor"
                }, 
                "affiliations": [
                    {
                        "name": [
                            "Laboratoire de Psychologie de la Perception", 
                            "CNRS and Universit\u00e9 Paris Descartes"
                        ], 
                        "address": {
                            "formatted": [
                                "Paris", 
                                "France"
                            ], 
                            "components": {
                                "locality": [
                                    "Paris"
                                ], 
                                "country": "France"
                            }
                        }
                    }, 
                    {
                        "name": [
                            "D\u00e9partement d\u2019Etudes Cognitives", 
                            "Ecole Normale Sup\u00e9rieure"
                        ], 
                        "address": {
                            "formatted": [
                                "Paris", 
                                "France"
                            ], 
                            "components": {
                                "locality": [
                                    "Paris"
                                ], 
                                "country": "France"
                            }
                        }
                    }
                ], 
                "contribution": "VB, Recorded HRTFs, Acquisition of data", 
                "competingInterests": "The authors declare that no competing interests exist."
            }, 
            {
                "type": "person", 
                "name": {
                    "preferred": "Romain Brette", 
                    "index": "Brette, Romain"
                }, 
                "affiliations": [
                    {
                        "name": [
                            "Laboratoire de Psychologie de la Perception", 
                            "CNRS and Universit\u00e9 Paris Descartes"
                        ], 
                        "address": {
                            "formatted": [
                                "Paris", 
                                "France"
                            ], 
                            "components": {
                                "locality": [
                                    "Paris"
                                ], 
                                "country": "France"
                            }
                        }
                    }, 
                    {
                        "name": [
                            "D\u00e9partement d\u2019Etudes Cognitives", 
                            "Ecole Normale Sup\u00e9rieure"
                        ], 
                        "address": {
                            "formatted": [
                                "Paris", 
                                "France"
                            ], 
                            "components": {
                                "locality": [
                                    "Paris"
                                ], 
                                "country": "France"
                            }
                        }
                    }
                ], 
                "emailAddresses": [
                    "romain.brette@ens.fr"
                ], 
                "contribution": "RB, Conception and design, Analysis and interpretation of data, Drafting or revising the article", 
                "competingInterests": "The authors declare that no competing interests exist."
            }
        ], 
        "funding": {
            "awards": [
                {
                    "id": "par-1", 
                    "source": {
                        "name": [
                            "European Research Council"
                        ]
                    }, 
                    "awardId": "ERC StG 240132", 
                    "recipients": [
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Dan FM Goodman", 
                                "index": "Goodman, Dan FM"
                            }
                        }, 
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Victor Benichoux", 
                                "index": "Benichoux, Victor"
                            }
                        }, 
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Romain Brette", 
                                "index": "Brette, Romain"
                            }
                        }
                    ]
                }, 
                {
                    "id": "par-2", 
                    "source": {
                        "name": [
                            "Agence Nationale de la Recherche"
                        ]
                    }, 
                    "awardId": "ANR-11-BSH2-0004, ANR-11-0001-02 PSL* and ANR-10-LABX-0087", 
                    "recipients": [
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Dan FM Goodman", 
                                "index": "Goodman, Dan FM"
                            }
                        }, 
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Victor Benichoux", 
                                "index": "Benichoux, Victor"
                            }
                        }, 
                        {
                            "type": "person", 
                            "name": {
                                "preferred": "Romain Brette", 
                                "index": "Brette, Romain"
                            }
                        }
                    ]
                }
            ], 
            "statement": "The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication."
        }, 
        "impactStatement": "Computer simulations of interaural time difference decoders show that heterogeneous tuning of binaural neurons leads to accurate sound localization in natural environments.", 
        "keywords": [
            "sound localization", 
            "neural coding", 
            "audition"
        ], 
        "digest": {
            "doi": "10.7554/eLife.01312.002", 
            "content": [
                {
                    "type": "paragraph", 
                    "text": "Having two ears allows animals to localize the source of a sound. For example, barn owls can snatch their prey in complete darkness by relying on sound alone. It has been known for a long time that this ability depends on tiny differences in the sounds that arrive at each ear, including differences in the time of arrival: in humans, for example, sound will arrive at the ear closer to the source up to half a millisecond earlier than it arrives at the other ear. These differences are called interaural time differences. However, the way that the brain processes this information to figure out where the sound came from has been the source of much debate."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Several theories have been proposed for how the brain calculates position from interaural time differences. According to the hemispheric theory, the activities of particular binaurally sensitive neurons in each of side of the brain are added together: adding signals in this way has been shown to maximize sensitivity to time differences under simple, controlled circumstances. The peak decoding theory proposes that the brain can work out the location of a sound on the basis of which neurons responded most strongly to the sound."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Both theories have their potential advantages, and there is evidence in support of each. Now, Goodman et al<i>.</i> have used computational simulations to compare the models under ecologically relevant circumstances. The simulations show that the results predicted by both models are inconsistent with those observed in real animals, and they propose that the brain must use the full pattern of neural responses to calculate the location of a sound."
                }, 
                {
                    "type": "paragraph", 
                    "text": "One of the parts of the brain that is responsible for locating sounds is the inferior colliculus. Studies in cats and humans have shown that damage to the inferior colliculus on one side of the brain prevents accurate localization of sounds on the opposite side of the body, but the animals are still able to locate sounds on the same side. This finding is difficult to explain using the hemispheric model, but Goodman et al. show that it can be explained with pattern-based models."
                }
            ]
        }, 
        "body": [
            {
                "type": "section", 
                "id": "s1", 
                "title": "Introduction", 
                "content": [
                    {
                        "type": "paragraph", 
                        "text": "To localize sound sources in the horizontal plane, humans and many other species use submillisecond timing differences in the signals arriving at the two ears (<a href=\"#bib2\">Ashida and Carr, 2011</a>). The ear closer to the source receives the sound earlier than the other. These interaural time differences (ITDs) are encoded in the auditory brainstem by binaural neurons, which are tuned to both frequency and ITD. An influential theory proposes that ITD is represented by the activity pattern of cells with heterogeneous tunings, a pattern code for sound location (<a href=\"#bib31\">Jeffress, 1948</a>). In a stronger version, ITD is represented by the identity of the most active cell in each frequency band, a labeled line code for sound location. Although this theory has proved successful in barn owls (<a href=\"#bib35\">Konishi, 2003</a>), discrepancies have been observed in mammals. In particular, at low frequencies, many cells have best delays (BDs) larger than the physiological range of ITDs experienced by the animal (<a href=\"#bib47\">McAlpine et al., 2001</a>). In a labeled line code, these cells would not have any function. An alternative theory was proposed, in which ITD is coded not by the firing of individual cells, but by the relative summed activity of each hemisphere, a summation code for sound location (<a href=\"#bib56\">Stecker et al., 2005</a>; <a href=\"#bib24\">Grothe et al., 2010</a>)."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "The nature of the neural code for ITD in mammals is still contentious because it is not known whether the auditory system sums activity or uses cell identity in decoding responses. In favor of the summation code hypothesis, cells with large BDs maximize ITD sensitivity of firing rate in the physiological range, whereas they are useless in a labeled line code. However, most of the cells with BDs inside the physiological range (most cells in cats; <a href=\"#bib39\">Kuwada and Yin, 1983</a>; <a href=\"#bib67\">Yin and Chan, 1990a</a>) actually degrade a summation code because their rates do not vary monotonically with ITD."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "In simple situations where there is a single acoustical stimulus (e.g., tone) with unknown ITD, theoretical arguments show that a summation code is optimal at low frequencies (<a href=\"#bib26\">Harper and McAlpine, 2004</a>). Previous studies have also shown that with simple stimuli, taking into account cell identity rather than simply summing all responses does not improve performance (<a href=\"#bib41\">Lesica et al., 2010</a>; <a href=\"#bib43\">L\u00fcling et al., 2011</a>). However, what is optimal in a simple world may not be optimal in an ecological environment. In a simple situation where only the ITD varies, the optimal code is the most sensitive one. In complex situations where other dimensions also vary, there is a trade-off between sensitivity and robustness, so the optimal code is not the most sensitive one (<a href=\"#bib4\">Brette, 2010</a>). In fact, theory predicts that in complex situations, the heterogeneity of ITD tunings is critical to produce robust estimates."
                    }, 
                    {
                        "type": "paragraph", 
                        "text": "To address this, we studied the performance of different decoders in increasingly complex situations, including variations in spectrum, background noise, and head-related acoustic filtering. We found that summing cell responses is strongly suboptimal and that heterogeneity in tunings is information rather than noise."
                    }
                ]
            }, 
            {
                "type": "section", 
                "id": "s2", 
                "title": "Results", 
                "content": [
                    {
                        "type": "section", 
                        "id": "s2-1", 
                        "title": "Decoding the sound\u2019s ITD from cell responses", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "Previous studies have tested the performance of simple decoders based on single-unit cell responses to acoustical stimuli (<a href=\"#bib17\">Fitzpatrick et al., 1997</a>; <a href=\"#bib25\">Hancock and Delgutte, 2004</a>; <a href=\"#bib56\">Stecker et al., 2005</a>; <a href=\"#bib14\">Devore et al., 2009</a>; <a href=\"#bib48\">Miller and Recanzone, 2009</a>; <a href=\"#bib41\">Lesica et al., 2010</a>; <a href=\"#bib43\">L\u00fcling et al., 2011</a>). However, this approach is limited to a small number of acoustical stimuli and cells. Here, we wanted to test the performance of different decoders based on the response of a large population (up to 480 cells) to a large variety of sounds totaling 11 hr of sound per cell. Obtaining this amount of data from electrophysiological recordings is not feasible because it would correspond to more than 7 months of single-unit recordings. We therefore decided to base our comparison on responses generated by a standard computational model, fitted with empirical data, which has been shown to produce realistic responses (\u2018Materials and methods\u2019)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "First, we sampled many cells from a distribution of BD vs best frequency (BF) (<a href=\"#fig1\">Figure 1A</a>, left). For guinea pigs, the distribution was defined by the measured mean and variance of BD as a function of BF (<a href=\"#bib47\">McAlpine et al., 2001</a>). For cats, we fitted a distribution to a set of measurements of BDs and BFs in 192 cells (the source data was in terms of characteristic frequency rather than BF, but these are equivalent for the linear model used here) (<a href=\"#bib33\">Joris et al., 2006</a>). The cells are then modeled as generalized cross-correlators with an internal delay BD (<a href=\"#bib69\">Yin et al., 1987</a>) (<a href=\"#fig1\">Figure 1A</a>, right). <a href=\"#fig1\">Figure 1B</a> illustrates the details of the model. We first model the acoustical propagation of the sound to the two ears. In the first part of this study, we consider only fixed ITDs, ignoring diffraction effects. In the second part, we move toward more realistic cues, using measured head-related transfer functions (HRTFs). The signals are then band-pass filtered around the cell\u2019s BF using gammatone filters and normalized (representing the saturation seen in bushy cells; <a href=\"#bib37\">Kuenzel et al., 2011</a>) and then crosscorrelated with an internal delay equal to the cell\u2019s BD (\u2018Materials and methods\u2019). The result is the firing rate of the cell, and we generate spikes with Poisson statistics. <a href=\"#fig1\">Figure 1C</a> displays the responses of 480 cells of the guinea pig model to white noise (left column) and to a natural sound (right column) at two different ITDs (top and bottom). We will then estimate the sound\u2019s ITD from these population responses, using various decoders."
                            }, 
                            {
                                "type": "image", 
                                "doi": "10.7554/eLife.01312.003", 
                                "id": "fig1", 
                                "label": "Figure 1.", 
                                "title": "Overview of model.", 
                                "caption": [
                                    {
                                        "type": "paragraph", 
                                        "text": "(<b>A</b>) The distribution of best delay vs best frequency for cells in the guinea pig model (left), with the physiological range of ITDs shown in gray, and a sample tuning curve (right). (<b>B</b>) Illustration of the model: a sound source is filtered via position-dependent HRTFs to give left and right channels. For each best frequency on each channel, the signal undergoes cochlear filtering using gammatone filters. An internal delay is added, and the two channels are combined and sent to a binaural neuron model that produces Poisson distributed spikes. (<b>C</b>) The response of the cells to sounds at two different ITDs (rows) for white noise (left column) and a natural sound (right column). The ITD is indicated by the black dashed line. Each cell is surrounded by a disc with a color indicating the response of that neuron (hot colors corresponding to strong responses). When two or more discs overlap, each point is colored according to the closest cell. The strongest responses lie along the line of the ITD."
                                    }
                                ], 
                                "alt": "", 
                                "uri": "https://publishing-cdn.elifesciences.org/01312/elife-01312-fig1-v1.tif", 
                                "filename": "elife-01312-fig1-v1.tif"
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "<a href=\"#fig2\">Figure 2A</a> illustrates the peak and hemispheric decoders. A 100-ms sound is presented at 200 \u00b5s ITD. The peak decoder picks the most active cell and reports its BD as the estimated ITD. We observe already that although we chose cells with BFs in a narrow frequency band (640\u2013760 Hz), the peak decoder performs poorly because of the noise in spiking. Therefore, we introduce a smoothed peak decoder. We first discard the information about BF, and simply consider the spike count of cells as a function of their BD. This relationship is smoothed to reduce noise, and we take the BD at the peak of the smoothed curve (one of the possible variations of crosscorrelation models; <a href=\"#bib58\">Stern and Trahiotis, 1995</a>). Smoothing could be neurally implemented by pooling the activity of cells with similar tuning. This decoder is less noisy. Finally, we consider the hemispheric decoder, in which we also discard information about BD in each hemisphere. To simplify, we define each hemisphere as the set of cells with BDs of the same sign. We calculate the total spike count for each hemisphere (yellow and orange rectangles) and compute the difference, normalized by the total activity. This gives a value between \u22121 and 1, the hemispheric difference, which varies systematically with ITD (<a href=\"#fig2\">Figure 2A</a>, right). Therefore, from the observation of the difference, one can invert the relationship and infer the ITD. Note, however, that this relationship depends on the frequency band in which the hemispheric difference is computed. In blue, cells are picked with BFs around 700 Hz and the hemispheric difference varies almost linearly with ITD. In purple, cells are picked with BFs around 1300 Hz and the curve is a sigmoid. More importantly, ambiguities start to occur at these high BFs: for example, a hemispheric difference of \u22120.8 is consistent with ITDs of both 100 and 300 \u00b5s. This occurs when the physiological range of ITD represents more than one period of the auditory filter\u2019s center frequency."
                            }, 
                            {
                                "type": "image", 
                                "doi": "10.7554/eLife.01312.004", 
                                "id": "fig2", 
                                "label": "Figure 2.", 
                                "title": "Decoders in single frequency bands.", 
                                "caption": [
                                    {
                                        "type": "paragraph", 
                                        "text": "(<b>A</b>) Peak and hemispheric decoders. Left: response of binaural neurons to sound at ITD = 0.2 ms (dashed line), in a narrow frequency band. The size of points is proportionate to spike count, and the crossed point corresponds to the highest spike count. Middle: the same cell responses are displayed as best delay vs spike count (note the different horizontal axis). The solid black line is the Gaussian smoothed spike count, whose peak (circle) is the ITD estimate. The maximally responsive neuron is also indicated with a circle for comparison. The yellow and orange bars give the mean response of neurons with positive and negative best delays, respectively, from which the normalized hemispheric difference is computed. Right: the hemispheric difference as a function of ITD at 700 Hz (blue) and 1.3 kHz (purple). At 1.3 kHz, the difference shown by the dashed line gives an ambiguous estimate of the ITD. (<b>B</b>) Mean error for the guinea pig and cat, for the peak (blue, dashed), smoothed peak (blue, solid), hemispheric (red), and pattern match (green) decoders. The distribution of BD vs BF is shown in the inset. (<b>C</b>) Illustration of the pattern match decoder and a neural circuit that implements it. The response (left) is compared to two patterns A and B, corresponding to two different ITDs (right). Each response neuron is connected to a pattern-sensitive neuron with weights proportional to the stored response of each pattern. When the weights match the responses, the output of the pattern-sensitive neuron is strongest."
                                    }
                                ], 
                                "alt": "", 
                                "uri": "https://publishing-cdn.elifesciences.org/01312/elife-01312-fig2-v1.tif", 
                                "filename": "elife-01312-fig2-v1.tif"
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "We now systematically test the estimation error of these three decoders for cells whose BFs are in narrow frequency bands within the range 100\u20131500 Hz (<a href=\"#fig2\">Figure 2B</a>). Stimuli are white noise bursts lasting 100 ms. For the hemispheric decoder, we use the hemispheric difference curve calculated in the same frequency band in which it is tested. Thus, there is a specific decoder for each frequency band tested, which is the most favorable scenario. As expected, the peak decoder performs very poorly, both for the guinea pig and the cat models. The two animal models differed by the BD distributions and by the physiological range of ITDs (300 \u00b5s for the guinea pig model, <a href=\"#bib57\">Sterbing et al., 2003</a>; 450 \u00b5s for the cat model, <a href=\"#bib61\">Tollin and Koka, 2009a</a>). Using the smoothed peak decoder improves substantially on these results. The hemispheric decoder performs better than both decoders for the guinea pig model at all frequencies, but for the cat, it is only better than the smoothed peak decoder for frequencies below 600 Hz. Thus, it appears that even for this simple scenario, the hemispheric decoder is a very poor decoder of ITD for the cat model, except at very low frequency. The fact that the estimation error of the hemispheric decoder starts increasing at a lower frequency for the cat than for the guinea pig model was expected based on the larger head size of the cat (<a href=\"#bib26\">Harper and McAlpine, 2004</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "The reasons for the limitations of the different decoders are simple. Because the peak decoder selects a single cell, its estimation error reflects the level of noise in individual responses, which is high. The smoothed decoder improves on this matter, but still mostly uses the responses of cells with similar tuning. In addition, at low frequencies, both estimators rely on the responses of a small pool of cells with BDs inside the physiological range. The hemispheric decoder sums all responses, which reduces noise but also discards all information about BF and BD."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "We introduce the pattern match decoder, a simple decoder that addresses both problems (<a href=\"#fig2\">Figure 2C</a>). We calculate the average response of cells to sounds presented at each ITD to be identified. This population response, which we call a pattern, is stored in a vector (w<sub>1</sub>, \u2026, w<sub>n</sub>), normalized to have length 1. When a sound is presented, the cell responses are compared with the patterns by computing a normalized dot product between the responses and the patterns, varying between 0 (perfectly dissimilar) and 1 (perfectly similar) (\u2018Materials and methods\u2019 for formulae). This can be implemented by a single-layer neural network in which the output neurons encode the preferred ITD and the synaptic weights represent the patterns. The reported ITD is the ITD associated to the most similar pattern, that is, with the highest dot product."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "<a href=\"#fig2\">Figure 2B</a> also shows the performance of the pattern matching decoder. As for the hemispheric decoder, patterns were computed in the same frequency band in which the decoder is tested. The pattern match decoder performs better than both the other decoders, both for the guinea pig and the cat models. The difference with the hemispheric decoder is very large for the cat model, but for the guinea pig model, it only starts being substantial above 1 kHz. The pattern match decoder combines the advantages of the hemispheric and peak decoders: it averages spiking noise over all cells, but it still uses individual information about BF and BD. The purpose of introducing this decoder is not to suggest that the auditory system extracts information about sound location in this exact way, but rather to estimate how much information can be obtained from the heterogeneous responses of these neurons. We also tested several other standard decoders from machine learning, including optimal linear decoding, maximum likelihood estimation, and nearest neighbor regression, but the pattern match decoder outperformed them in all cases and so we do not present the results of these decoders here (although see <a href=\"#fig3s1\">Figure 3\u2014figure supplement 1</a> for a sample of these results)."
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s2-2", 
                        "title": "Integrating information across frequency", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "The estimation task in <a href=\"#fig2\">Figure 2</a> was very simple because we trained and tested the decoders in the same narrow frequency bands. In <a href=\"#fig3\">Figure 3</a>, we investigate the issue of frequency integration. All decoders are now trained with white noise at various ITDs, considering all cells with BFs between 100 Hz and 1.5 kHz. For the hemispheric decoder, this means that we pool the responses of all cells in the same hemisphere, for all BFs, and we use a single broadband hemispheric difference curve to estimate ITDs. Decoder performance is then tested with white noise. For this more realistic task, it appears that the error made by the pattern match decoder is about half the error of the hemispheric decoder for the guinea pig model. For the cat models, this difference is even larger. In fact, it turns out that for the cat, the smoothed peak decoder performs better than the hemispheric decoder. To understand why, we now test the decoders on band-pass noises, as a function of the center frequency, while the decoders are still trained with broadband noise (<a href=\"#fig3\">Figure 3B</a>). This test addresses the robustness of these decoders to changes in sound spectrum. We make two observations. First, all decoders perform much worse than when decoders are trained and tested in the same frequency bands (compare with <a href=\"#fig2\">Figure 2B</a>; the unsmoothed peak decoder performs very poorly and is not shown). This means that frequency integration is indeed an issue. Second, the hemispheric decoder performs worse than the two other decoders above 700 Hz for the guinea pig models and above 500 Hz for the cat. This was expected for two reasons: (1) the hemispheric difference is ambiguous at high frequency (above about 1200 Hz for both animals), and (2) the hemispheric difference depends not only on ITD but also on frequency (<a href=\"#fig2\">Figure 2A</a>, right). We attempt to solve the first problem by discarding all cells with BF higher than a specified cutoff frequency (<a href=\"#fig3\">Figure 3C</a>). Performance is tested again with white noise. Both for the guinea pig and the cat models, the error of the hemispheric decoder starts increasing when cells with BF above 1.2 kHz are included. For this reason and because the hemispheric difference becomes ambiguous above 1.2 kHz in both models, we restrict to cells with BF &lt;1.2 kHz in the rest of this study. We note, however, that the error of the pattern match decoder continues decreasing as cells with high frequency are added."
                            }, 
                            {
                                "type": "image", 
                                "doi": "10.7554/eLife.01312.005", 
                                "id": "fig3", 
                                "label": "Figure 3.", 
                                "title": "Integration across frequencies.", 
                                "caption": [
                                    {
                                        "type": "paragraph", 
                                        "text": "(<b>A</b>) Mean error in estimating ITD for white noise using the smoothed peak (blue), hemispheric (red), and pattern match (green) decoders, as a function of the number of binaural cells. Training and testing of the decoders are both performed using white noise. (<b>B</b>) Mean error as a function of frequency band when decoders are trained on white noise but tested on band-pass noise centered at the given frequency. Notice the different vertical scale between (<b>A</b> and <b>B</b>). (<b>C</b>) Performance when cells with a frequency above the cutoff are discarded. (<b>D</b>) Mean error and bias to center in the decoders for guinea pig (with a maximum frequency of 1.2 kHz) when trained on white noise and tested on colored noise."
                                    }
                                ], 
                                "alt": "", 
                                "uri": "https://publishing-cdn.elifesciences.org/01312/elife-01312-fig3-v1.tif", 
                                "supplements": [
                                    {
                                        "type": "image", 
                                        "doi": "10.7554/eLife.01312.006", 
                                        "id": "fig3s1", 
                                        "label": "Figure 3\u2014figure supplement 1.", 
                                        "title": "Comparison with standard machine learning decoders.", 
                                        "caption": [
                                            {
                                                "type": "paragraph", 
                                                "text": "As for <a href=\"#fig3\">Figure 3</a>, except that the main decoders are shown in light colors, and there are two additional decoders: ridge regression (magenta) and nearest neighbor regression (black)."
                                            }
                                        ], 
                                        "alt": "", 
                                        "uri": "https://publishing-cdn.elifesciences.org/01312/elife-01312-fig3-figsupp1-v1.tif", 
                                        "filename": "elife-01312-fig3-figsupp1-v1.tif"
                                    }
                                ], 
                                "filename": "elife-01312-fig3-v1.tif"
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "We have seen that estimation error depends on the frequency band of the presented sound (<a href=\"#fig3\">Figure 3B</a>). This observation extends to broadband sounds that vary in spectrum. We tested the estimation performance for the guinea pig models when the decoders are trained on white noise and tested with 1/<i>f</i><sup>\u03b1</sup> noise: from white noise (\u03b1 = 0) to pink (\u03b1 = 1) and brown (\u03b1 = 2) (<a href=\"#fig3\">Figure 3D</a>). The hemispheric decoder is not robust to changes in spectrum, as the error increases with noise color \u03b1. The pattern match decoder shows the same trend, but the error remains constant on a larger range. The error of the smoothed peak decoder does not depend on sound spectrum. The main reason for the lack of robustness of the hemispheric decoder is shown in <a href=\"#fig3\">Figure 3D</a> (bottom). As \u03b1 increases, the estimate of the ITD becomes more and more biased to the center. This is because with high \u03b1, every cell receives more low frequencies than high frequencies compared to the white noise case, and therefore the hemispheric difference curve changes and becomes flatter (<a href=\"#fig2\">Figure 2A</a>, right). Note that this happens not by the recruitment of more low-frequency cells but also by the change in the hemispheric difference for all cells."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "We now attempt to improve frequency integration in the hemispheric decoder by taking into account the change in hemispheric difference with frequency (<a href=\"#fig4\">Figure 4A</a>). The ITD tuning curves have different shapes, depending on the cell\u2019s BF (left). As a result, the hemispheric difference in each frequency band varies with the center frequency (middle). The curves are shallower in low frequency and sharper in high frequency (right). In fact, the slope is expected to be proportional to frequency: the hemispheric difference is determined by the interaural phase difference, which is the product of frequency and ITD. Therefore, we fix this issue by normalizing the cell responses by their BF in the calculation of the hemispheric difference (\u2018Materials and methods\u2019). This produces hemispheric differences with similar slopes in all frequency bands. Note that there are constant biases due to the fact that the cells\u2019 BDs are not exactly symmetrical between the two hemispheres (only their distribution is)."
                            }, 
                            {
                                "type": "image", 
                                "doi": "10.7554/eLife.01312.007", 
                                "id": "fig4", 
                                "label": "Figure 4.", 
                                "title": "Frequency-dependent improvements.", 
                                "caption": [
                                    {
                                        "type": "paragraph", 
                                        "text": "(<b>A</b>) Comparing hemispheric differences across frequency channels. In each plot, color indicates frequency with red being high frequency and blue being low frequency. Left: tuning curves for a few binaural neurons. Middle: hemispheric difference (L \u2212 R)/(L + R). Right: frequency-dependent hemispheric difference (1/<i>f</i>) (L \u2212 R)/(L + R). (<b>B</b>) Mean error as a function of frequency band in the guinea pig model, for hemispheric (red) and pattern match (green) decoders (dashed lines), and frequency-dependent hemispheric and pattern match (solid) decoders. The shaded regions show the difference between the simple and frequency-dependent versions. The dotted lines show the mean error for band-pass noise if the decoder is trained and tested on the same frequency band, as shown in <a href=\"#fig2\">Figure 2B</a> (guinea pig). This represents the lower bound for the error."
                                    }
                                ], 
                                "alt": "", 
                                "uri": "https://publishing-cdn.elifesciences.org/01312/elife-01312-fig4-v1.tif", 
                                "filename": "elife-01312-fig4-v1.tif"
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "This frequency-dependent correction indeed improves ITD estimation when the decoder is trained on broadband noise and on band-passed noise (<a href=\"#fig4\">Figure 4B</a>). However, the error still remains higher than in the simple case when the decoder is trained and tested in the same frequency band. In the same way, we improved frequency integration for the pattern match decoder by calculating intermediate estimates in each frequency band and combining the results (\u2018Materials and methods\u2019). This correction improves the performance above 600 Hz, where it is close to the performance obtained in the simple case. In the remainder of this study, we only consider these two frequency-corrected decoders."
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s2-3", 
                        "title": "Background noise and sound diffraction", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "We then test the decoders in increasingly realistic situations. First, we consider the effect of background noise on performance (<a href=\"#fig5\">Figure 5</a>). Interaural correlation is decreased by adding dichotic background noise to the binaural signals, and the estimation error is computed as a function of signal-to-noise ratio (SNR). All decoders were trained in quiet. In all cases, the pattern match decoder performs best, but for the guinea pig models, it substantially outperforms the hemispheric decoder at low SNR, whereas it showed similar performance in quiet. Interestingly, the smoothed peak decoder also outperforms the hemispheric decoder at SNR below 10 dB, both for the guinea pig and the cat models. Indeed, although this decoder performs worst in quiet, it proves more robust than the hemispheric decoder. The poor performance of the hemispheric decoder can again be accounted for by a bias problem. At high SNR, the hemispheric difference curves become shallower, which implies that ITD estimation is biased toward the center. The problem is less present for the pattern match decoder. Note that the smoothed peak decoder tends to be biased away from the center. This is simply because BDs are more represented away from the center."
                            }, 
                            {
                                "type": "image", 
                                "doi": "10.7554/eLife.01312.008", 
                                "id": "fig5", 
                                "label": "Figure 5.", 
                                "title": "Background acoustic noise.", 
                                "caption": [
                                    {
                                        "type": "paragraph", 
                                        "text": "(<b>A</b>) Illustration of protocol: a binaural sound is presented with a given ITD, with independent white noise added to the two channels. (<b>B</b>) Mean error (left column) and central bias (right column) at different signal to noise levels. Decoders are smoothed peak (blue), hemispheric (red), and pattern match (green)."
                                    }
                                ], 
                                "alt": "", 
                                "uri": "https://publishing-cdn.elifesciences.org/01312/elife-01312-fig5-v1.tif", 
                                "filename": "elife-01312-fig5-v1.tif"
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "Previously, we considered a simplistic model of sound propagation, in which sounds are simply delayed. In reality, sounds are diffracted by the head. A better description of this process is that sounds arriving at the two ears are two filtered versions of the original sound, with filters depending on source direction. These are called HRTFs and can be measured in anechoic chambers. We measured high-resolution HRTFs of a stuffed guinea pig in a natural posture (<a href=\"#fig6\">Figure 6A</a>). It is known that diffraction produces ITDs that depend on frequency for the same source direction, with larger ITDs in low frequency (<a href=\"#bib38\">Kuhn, 1977</a>). We find the same pattern in our measurements (<a href=\"#fig6\">Figure 6B</a>), and the range of ITDs is similar to previously reported measurements in live guinea pigs (<a href=\"#bib57\">Sterbing et al., 2003</a>). For the cat model, we used HRTFs measured in an anesthetized cat (<a href=\"#bib61\">Tollin and Koka, 2009a</a>)."
                            }, 
                            {
                                "type": "image", 
                                "doi": "10.7554/eLife.01312.009", 
                                "id": "fig6", 
                                "label": "Figure 6.", 
                                "title": "Realistic head-related transfer functions.", 
                                "caption": [
                                    {
                                        "type": "paragraph", 
                                        "text": "(<b>A</b>) Photograph of stuffed guinea pig used for HRTF recordings, and three pairs of left/right ear impulse responses corresponding to the directions marked on the photograph. (<b>B</b>) Frequency dependence of ITD for the three azimuths shown in panel (<b>A</b>), in guinea pig and cat HRTFs. (<b>C</b>) Mean response of the model to white noise stimuli at the same azimuth (90\u00b0) for both animals, the frequency-dependent ITD curve is shown for this azimuth (dashed). (<b>D</b>) Performance of the model as a function of the number of cells for hemispheric (red) and pattern match (green) decoders."
                                    }
                                ], 
                                "alt": "", 
                                "uri": "https://publishing-cdn.elifesciences.org/01312/elife-01312-fig6-v1.tif", 
                                "filename": "elife-01312-fig6-v1.tif"
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "<a href=\"#fig6\">Figure 6C</a> displays the cell responses for sounds presented at 90\u00b0 azimuth, where we used the HRTFs to filter the sound in an acoustically realistic way. We then test the estimation error in azimuth, rather than in ITD, for white noise presented in quiet (<a href=\"#fig6\">Figure 6D</a>). For both animals, the pattern match decoder is substantially better than the hemispheric decoder. Indeed, since the hemispheric decoder discards all information about BF and BD, it cannot take advantage of the frequency variation of ITDs, whereas the pattern match decoder does. The difference is particularly striking for the cat due to its larger head size."
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s2-4", 
                        "title": "Tuning heterogeneity as information", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "We have argued that the hemispheric decoder performs poorly because it discards the information present in the heterogeneity of ITD tunings of the cells. We demonstrate this point in <a href=\"#fig7\">Figure 7A</a> by varying the amount of heterogeneity in the BDs of the guinea pig model. The standard deviation of the BD is multiplied by a \u2018spread factor\u2019: below 1, the BD distribution is less heterogeneous than in the original distribution; above 1, it is more heterogeneous. We then test the estimation error for white noise as a function of spread factor. When the BDs are less heterogeneous, there is little difference between the performance of the hemispheric and pattern match decoder. But as heterogeneity increases, the pattern match decoder performs better, whereas the hemispheric decoder shows little change in performance. Therefore, heterogeneity of tunings is indeed useful to estimate the ITD, and pooling the responses discards this information. Performance remains stable when the distribution is made more heterogeneous than the actual distribution (spread factor &gt;1)."
                            }, 
                            {
                                "type": "image", 
                                "doi": "10.7554/eLife.01312.010", 
                                "id": "fig7", 
                                "label": "Figure 7.", 
                                "title": "Effect of heterogeneity and lesions.", 
                                "caption": [
                                    {
                                        "type": "paragraph", 
                                        "text": "(<b>A</b>) Mean error for the hemispheric (red) and pattern match (green) decoders in the guinea pig model, depending on the spread of the best delays, for white noise presented with acoustic noise (SNR between \u22125 and 5 dB, no HRTF filtering). For every frequency, the standard deviation of BDs is multiplied by the spread factor: lower than 1 denotes less heterogeneous than the original distribution (top left), greater than 1 denotes more heterogeneous (top right). Dashed lines represent the estimation error for the original distribution. (<b>B</b>) Mean error for the pattern match (green) and smooth peak (blue) decoders before (dashed) and after (solid) lesioning one hemisphere in the guinea pig, as a function of presented ITD. The model is retrained after lesioning. The error curves are Gaussian smoothed to reduce noise and improve readability."
                                    }
                                ], 
                                "alt": "", 
                                "uri": "https://publishing-cdn.elifesciences.org/01312/elife-01312-fig7-v1.tif", 
                                "filename": "elife-01312-fig7-v1.tif"
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s2-5", 
                        "title": "Effect of lesions", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "Lesion studies in cats (<a href=\"#bib32\">Jenkins and Masterton, 1982</a>) and in humans (<a href=\"#bib42\">Litovsky et al., 2002</a>) show that when one inferior colliculus is removed, the sound localization performance in the contralateral field drops but remains almost intact in the ipsilateral field. This is not compatible with an ITD estimation based on the comparison between the activity of the two hemispheres. We simulated a hemispheric lesion in the pattern match and smoothed peak decoders (<a href=\"#fig7\">Figure 7B</a>), by removing all cells with negative BDs. The performance for positive ITDs is essentially unchanged, whereas it is highly degraded for negative ITDs, especially for the smoothed peak decoder. Lesion data indicate that sound localization performance is greatly degraded in the contralateral hemifield, but not completely abolished, which would discard the smoothed peak decoder\u2014although lesions might not have been complete, and those were free-field experiments involving other cues than ITD."
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s2-6", 
                        "title": "Owls and humans", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "Finally, we test the estimation performance in barn owls and humans, for white noise filtered through measured HRTFs (\u2018Materials and methods\u2019) (<a href=\"#fig8\">Figure 8</a>). For barn owls, we used a previously measured distribution of BD vs BF (<a href=\"#bib64\">Wagner et al., 2007</a>). Barn owls are sensitive to ITDs in very high frequency (about 2\u20138 kHz), and therefore, as expected, the hemispheric decoder performs very badly compared to the pattern match decoder (<a href=\"#fig8\">Figure 8A</a>). For humans, the distribution of BD vs BF is unknown. Some indirect evidence from MRI and EEG studies suggests that BD is not uniformly distributed (<a href=\"#bib60\">Thompson et al., 2006</a>; <a href=\"#bib5\">Briley et al., 2013</a>). We tested three possibilities: uniformly distributed BD within the pi-limit, similar to what is observed in birds (<a href=\"#fig8\">Figure 8B</a>), BD distribution of the guinea pig model (<a href=\"#fig8\">Figure 8C</a>), and BD distribution of the cat model (<a href=\"#fig8\">Figure 8D</a>). In all cases, the estimation error of the hemispheric decoder is very high, an order of magnitude larger than human sound localization acuity (on the order of 3\u00b0) (<a href=\"#bib7\">Carlile et al., 1997</a>)."
                            }, 
                            {
                                "type": "image", 
                                "doi": "10.7554/eLife.01312.011", 
                                "id": "fig8", 
                                "label": "Figure 8.", 
                                "title": "Humans and owls.", 
                                "caption": [
                                    {
                                        "type": "paragraph", 
                                        "text": "(<b>A</b>) Mean error for the pattern match (green) and hemispheric (red) decoders for the barn owl model, with sounds presented through measured HRTFs. (<b>B</b>) Performance in the human model with uniformly distributed best interaural phase differences. (<b>C</b>) Performance in the human model with best delays distributed as in the guinea pig model. (<b>D</b>) Performance in the human model with best delays distributed as in the cat model."
                                    }
                                ], 
                                "alt": "", 
                                "uri": "https://publishing-cdn.elifesciences.org/01312/elife-01312-fig8-v1.tif", 
                                "filename": "elife-01312-fig8-v1.tif"
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s2-7", 
                        "title": "Comparison with behavioral performance", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "Our results can be compared with behavioral performance measured in psychophysical experiments. One may immediately object that the pattern decoder is in fact too accurate compared to natural performance, in particular for humans (<a href=\"#fig8\">Figure 8</a>). Therefore, we must stress again that the performance obtained by a decoder in a given context is always overestimated, compared to the same decoder adapted to a more general context, \u2018even when tested with the same sounds\u2019. To give an example, all decoders are much more accurate when trained and tested on a single narrow frequency band (<a href=\"#fig2\">Figure 2B</a>) than when trained with broadband sounds and tested with exactly the same narrowband sounds (<a href=\"#fig3\">Figure 3B</a>). Additional imprecision is introduced by other uncontrolled sources of variability in the sounds, many of which we have not considered:"
                            }, 
                            {
                                "type": "list", 
                                "prefix": "bullet", 
                                "items": [
                                    [
                                        {
                                            "type": "paragraph", 
                                            "text": "1. Sound locations differ not only by azimuth but also elevation and distance, both of which impact binaural cues"
                                        }
                                    ], 
                                    [
                                        {
                                            "type": "paragraph", 
                                            "text": "2. Reflections on the ground and objects impact ITDs (<a href=\"#bib23\">Gour\u00e9vitch and Brette, 2012</a>)"
                                        }
                                    ], 
                                    [
                                        {
                                            "type": "paragraph", 
                                            "text": "3. There are often multiple sound sources"
                                        }
                                    ], 
                                    [
                                        {
                                            "type": "paragraph", 
                                            "text": "4. Sound sources are generally not point sources and are directional"
                                        }
                                    ], 
                                    [
                                        {
                                            "type": "paragraph", 
                                            "text": "5. Natural sounds have widely diverse spectrotemporal properties"
                                        }
                                    ]
                                ]
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "A sound localization system adapted for the full range of ecological variability necessarily performs worse in a narrower range of conditions than a system specifically optimized for that narrow range. In addition, acoustical cues must be associated with sound location through some feedback mechanism, and therefore sound localization acuity is constrained by the precision of this feedback. Indeed a comparative study across 23 mammalian species shows that sound localization acuity is best explained by the width of the field of best vision (<a href=\"#bib30\">Heffner and Heffner, 1992</a>). Therefore, our model results should be understood as a lower bound for the accuracy of these decoders. In particular, the poor performance of the hemispheric decoder is actually optimistic, all the more so as we made specific efforts to enhance it by taking into account nonlinearities (<a href=\"#fig2\">Figure 2A</a>) and by applying frequency-dependent corrections (<a href=\"#fig4\">Figure 4</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "Most psychophysical studies in animals have focused on the measurement of the minimum audible angle (MAA), which is a discrimination threshold for sources near the midline. In cats, the MAA is about 5\u00b0 for broadband noises longer than 40 ms (defined as the speaker separation given 75% correct responses) (<a href=\"#bib8\">Casseday and Neff, 1973</a>; <a href=\"#bib28\">Heffner and Heffner, 1988a</a>). <a href=\"#bib63\">Tollin et al. (2005)</a> measured accuracy in an absolute localization study in the \u221225\u00b0 to 25\u00b0 range. When the cat\u2019s head is unrestrained, direction estimates show little bias and the standard deviation is 3\u20134\u00b0, which corresponds to a mean unsigned error (the measure used in this article) of 2.4\u20133.2\u00b0 (assuming normally distributed responses). In <a href=\"#bib50\">Moore et al. (2008)</a>, the mean unsigned error was directly reported (although only for directions near the midline) and was in the 2\u20134\u00b0 range. In a behavioral study in which cats were trained to walk to a target speaker in the \u221290\u00b0 to 90\u00b0 range, the animals could do the task with nearly 100% accuracy, with no apparent dependence on speaker azimuth (<a href=\"#bib46\">Malhotra et al., 2004</a>)\u2014but speakers were spaced by 15\u00b0. In <a href=\"#fig6\">Figure 6D</a>, we report a mean unsigned error of 5\u00b0 for the optimized hemispheric model (including frequency-dependent and nonlinear corrections; error for the pattern decoder was nearly 0\u00b0). The model was trained and tested in quiet with broadband noises, with sources constrained to the horizontal plane. Therefore, it is a very optimistic estimate, especially given that the sound localization tasks mentioned above were two-dimensional (i.e., the elevation had to be estimated as well). It could be argued that the behavioral task included additional cues, in particular interaural intensity differences, because the sounds were broadband. However, <a href=\"#bib50\">Moore et al. (2008)</a> showed for sources near the midline that sound localization accuracy in the horizontal plane is very similar for broadband and low-pass filtered noises (&lt;5 kHz), which do not include these cues."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "In cats, the just noticeable difference in ITD is similar for tones of 500 Hz and 1 kHz, about 25 \u00b5s (<a href=\"#bib65\">Wakeford and Robinson, 1974</a>). The performance of the pattern decoder is generally not strongly dependent on frequency in the 500\u20131200 Hz range (<a href=\"#fig2 fig3 fig4\">Figures 2\u20134</a>), whereas the performance of the hemispheric decoder consistently increases with frequency (between about 500 and 1 kHz in <a href=\"#fig2\">Figure 2</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "Unfortunately, there are no behavioral studies in guinea pigs. In the gerbil, another small mammal with low-frequency hearing, the MAA is 27\u00b0 (<a href=\"#bib29\">Heffner and Heffner, 1988b</a>). This makes sound localization acuity in gerbils one of the worst of all mammalian species in which it has been measured (<a href=\"#bib30\">Heffner and Heffner, 1992</a>). Given that the maximum ITD is about 120 \u00b5s (<a href=\"#bib44\">Maki and Furukawa, 2005</a>), the threshold ITD should be about 54 \u00b5s (using Kuhn\u2019s formula; <a href=\"#bib38\">Kuhn, 1977</a>). Given that this threshold is so high, and in the absence of absolute localization studies in these two species, it is difficult to discard any model on the basis of the existing behavioral data alone. We note however that, for a given accuracy, the hemispheric decoder requires many more neurons than the pattern match decoder (<a href=\"#fig3\">Figure 3A</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "In owls, ITD is a cue to azimuth, whereas interaural level difference is a cue to elevation (<a href=\"#bib59\">Takahashi et al., 1984</a>; <a href=\"#bib49\">Moiseff, 1989</a>). We found that the mean unsigned error with the hemispheric decoder was greater than 30\u00b0, when trained and tested in quiet with HRTFs (<a href=\"#fig8\">Figure 8A</a>). Behaviorally, barn owls localize broadband sounds with azimuthal error smaller than about 10\u00b0 at all azimuths (<a href=\"#bib34\">Knudsen et al., 1979</a>), and a large part of this error is due to an underestimate of eccentric azimuths that can be accounted for by a prior for frontal directions (<a href=\"#bib16\">Fischer and Pe\u00f1a, 2011</a>). In humans, behavioral estimates of azimuth are largely dominated by low-frequency ITDs (<a href=\"#bib66\">Wightman and Kistler, 1992</a>), and the mean unsigned error with broadband noise bursts (open-loop condition) is about 5\u00b0 in the frontal hemifield (2\u201310\u00b0 depending on azimuth) in a two-dimensional absolute localization task (<a href=\"#bib45\">Makous and Middlebrooks, 1990</a>). In contrast, the hemispheric decoder has an average error of about 10\u00b0 in the most favorable scenario (<a href=\"#fig8\">Figure 8B</a>), although sources are constrained to the horizontal plane."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "In summary, our results with the hemispheric decoder appear inconsistent with behavioral data for cats, humans, and owls. In contrast, the results obtained by the pattern match decoder imply that there is enough information in the activity of binaural neurons to account for the sound localization accuracy of these species. There is insufficient behavioral data in the guinea pig model to distinguish between different decoders."
                            }
                        ]
                    }
                ]
            }, 
            {
                "type": "section", 
                "id": "s3", 
                "title": "Discussion", 
                "content": [
                    {
                        "type": "paragraph", 
                        "text": "There are two major theories of ITD processing in mammals. One theory, initially proposed by <a href=\"#bib31\">Jeffress (1948)</a>, asserts that ITD is represented in the activity pattern of neurons with heterogeneous tunings to ITD. A more recent theory claims that ITD is represented by the relative activity of the two MSOs, irrespective of the tunings of the cells (<a href=\"#bib24\">Grothe et al., 2010</a>). We compared different ways of extracting information about sound location from the responses of a model population of binaural neurons constrained by electrophysiological data and acoustical recordings, to a large variety of sounds\u2014which would be infeasible with single-unit recordings in animals and impossible in humans. Our results demonstrate that, although a labeled line code for ITD\u2014the most literal interpretation of the Jeffress model\u2014is too inefficient, summing the activity in each hemisphere discards too much of the information that is present in neural activity patterns. In addition, the heterogeneity of ITD tunings is important for decoding performance, rather than being meaningless variability (<a href=\"#fig7\">Figure 7</a>). This loss of information is large enough that the hemispheric decoder cannot account for behavioral performance measured in cats and humans, although we improved it by taking into account nonlinearities (<a href=\"#fig2\">Figure 2A</a>) and by applying frequency-dependent corrections (<a href=\"#fig4\">Figure 4</a>). The critical flaw lies in the fact that an estimate of ITD based on global hemispheric activity is not robust to changes in sound properties other than ITD."
                    }, 
                    {
                        "type": "section", 
                        "id": "s3-1", 
                        "title": "Optimal coding of ITD", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "Our results appear to contradict the previous studies showing that hemispheric codes for ITD are optimal (<a href=\"#bib26\">Harper and McAlpine, 2004</a>) and that response patterns do not provide more information than simply summing (<a href=\"#bib41\">Lesica et al., 2010</a>; <a href=\"#bib43\">L\u00fcling et al., 2011</a>). However, these studies focused on a simple task, in which only the ITD was allowed to vary. This is an elementary task for a decoder because any variation in the pattern of responses can be attributed to a change in sound location. It is much more difficult to estimate location independently of irrelevant dimensions found in ecological situations, such as level, spectrum, and background noise. This point is related to the concept of \u2018overfitting\u2019 in statistical learning theory: an estimator may be very accurate when trained and tested with the same data, while in fact very poor when tested on new data. This is precisely what happens with the hemispheric decoder. When tested with the same sounds used to calibrate the decoder, its performance is indeed very good for the guinea pig model (<a href=\"#fig2\">Figure 2B</a>), consistently with previous results. However, when the decoder is calibrated for broadband sounds and tested with the same sounds as before, performance degrades drastically (<a href=\"#fig3\">Figure 3B</a>). Thus, our results directly demonstrate that indiscriminate pooling of the activity in each hemisphere is a poor way to decode information about sound location. <a href=\"#fig7\">Figure 7A</a> also directly contradicts the claim that the optimal code for ITD consists of two populations of identically tuned neurons (<a href=\"#bib26\">Harper and McAlpine, 2004</a>). On the contrary, heterogeneity of tunings is critical for robust estimation, consistently with theoretical arguments (<a href=\"#bib4\">Brette, 2010</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "The discrepancy with previous arguments in favor of hemispheric or \u2018slope\u2019 coding seems to stem from a confusion between accuracy and acuity (<a href=\"#bib27\">Heffner and Heffner, 2005</a>; <a href=\"#bib63\">Tollin et al., 2005</a>): accuracy measures how well one can estimate the correct value (absolute localization); acuity measures how easily one can distinguish between two values (discrimination). Acuity can be directly related to ITD sensitivity of neural responses (favoring a \u2018slope code\u2019), but accuracy is in fact the relevant ecological concept for the animal."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "It may be objected that the focus on optimality may be irrelevant because animals only need to be accurate enough, given the ecologically relevant tasks. However, our results also imply that for a given level of accuracy, the hemispheric decoder requires many more neurons than the pattern match decoder (<a href=\"#fig3 fig6\">Figures 3A and 6D</a>), and therefore it is energetically inefficient. Although there may be little evolutionary pressure for very accurate sound localization in some species, the same argument does not apply to energy consumption in the brain (<a href=\"#bib3\">Attwell and Laughlin, 2001</a>). Nevertheless, there are also physiological constraints on the way information can be extracted, which we examine in the section \u2018Physiological mechanisms\u2019 below."
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s3-2", 
                        "title": "Correlations and coding", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "It is known that the structure of neural correlations can be critical to optimal decoding. There are different sources of correlations: anatomical divergence (overlap in the sets of presynaptic neurons), shared variability due to feedback or lateral connections, and stimulus-dependent variability (e.g., changes in level). In the medial superior olive (MSO), the earliest nucleus with ITD-sensitive neurons, correlations due to anatomical divergence are probably limited because frequencies are narrowly tuned in these binaural neurons and receive inputs from few monaural neurons (<a href=\"#bib10\">Couchman et al., 2010</a>). The second source of correlations is also likely to be weak because there are no identified lateral connections within the MSO and little evidence of feedback connections, although GABAergic receptors have been recently characterized (<a href=\"#bib11\">Couchman et al., 2012</a>). Thus, neural correlations in this early sound localization circuit are presumably mainly due to the shared acoustic stimulus."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "When these correlations are neglected and neurons are assumed to fire independently, conditionally to the ITD, then the optimal code is the most sensitive one (<a href=\"#bib26\">Harper and McAlpine, 2004</a>), and reliable estimates can be obtained by simply pooling the estimates obtained from individual responses. This conclusion is wrong in general when there are stimulus-dependent correlations (<a href=\"#bib4\">Brette, 2010</a>). In this case, as we have shown, the structure of neural correlations contains useful information that can be exploited by simple decoders. For example, changes in various aspects of the sound induce shared variability in individual responses, which results in the same variability in pooled responses, but little variability in the relative activity of neurons (used by the pattern decoder)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "Another mechanism to reduce the impact of shared stimulus-dependent variability is divisive normalization (<a href=\"#bib6\">Carandini and Heeger, 2011</a>). Level normalization was in fact included in all the models we tested, so as to focus on ITD cues (rather than interaural level differences)."
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s3-3", 
                        "title": "Pattern decoders", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "Previous studies have assessed the performance of pattern decoders in estimating sound location from the responses of ensembles of cortical neurons. These decoders included artificial neural networks using spike counts or relative spike timing (<a href=\"#bib19\">Furukawa et al., 2000</a>; <a href=\"#bib56\">Stecker et al., 2005</a>; <a href=\"#bib40\">Lee and Middlebrooks, 2013</a>) and maximum likelihood estimation (<a href=\"#bib48\">Miller and Recanzone, 2009</a>), which is close to the pattern decoder used in this study. It is generally found that good performance can be achieved provided that the set of neurons is large enough. A previous study also found good performance with an opponent channel model, similar to the hemispheric model we tested in our study (<a href=\"#bib56\">Stecker et al., 2005</a>). However, these studies tested the decoders on responses to a single type of sound (white noise), although with several levels, and as we have shown, substantial differences between the performances of decoding mechanisms only arise when sounds are allowed to vary in dimensions other than the dimension being estimated (e.g., spectrum)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "In a recent experimental study, a maximum likelihood decoder was found to outperform a hemispheric decoder in estimating sound location from responses of neurons in the inferior colliculus (<a href=\"#bib12\">Day and Delgutte, 2013</a>), which is consistent with our study. However, as in previous studies, only responses to a single type of sound were used, which implies that performance in more realistic scenarios was overestimated."
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s3-4", 
                        "title": "Physiological mechanisms", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "The pattern decoder is essentially a perceptron (<a href=\"#bib13\">Dayan and Abbott, 2001</a>): spatially tuned neurons are formed by simply pooling neural responses with different weights, and then the maximally active neuron indicates source location. These weights reflect the average activity pattern for the preferred location, and thus could be learned by standard Hebbian plasticity mechanisms. The smoothed peak decoder is essentially the same, except the weights are not learned. In the cat model, most low-frequency neurons in the central nucleus of the inferior colliculus are spatially tuned, with preferred azimuth homogeneously distributed in the contralateral hemifield (<a href=\"#bib1\">Aitkin et al., 1985</a>). These neurons receive excitatory inputs from ITD-sensitive neurons in the MSO. In addition, when one inferior colliculus is removed, sound localization performance drops only in the contralateral field. Both the pattern and smooth peak decoders are in line with these findings."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "The hemispheric decoder pools neural activity from each hemisphere, and then calculates the normalized difference, which are both simple operations. However, two remarks are in order. First, contrary to the other decoders, the presence of both functional hemispheres is required to estimate sound direction in either hemifield. Second, these operations produce a graded estimate of sound direction, not a spatially tuned response. Therefore, producing spatially tuned responses requires an additional step, with neurons tuned to a specific ratio of hemispheric activity. The firing rate of these neurons must then depend nonmonotonically on the activity of each side. Thus, the hemispheric decoder appears more complex, in terms of neural circuitry, than any of the other decoders. It could be argued that creating spatially tuned responses is in fact not necessary for sound localization behavior. For example, movements toward the sound source could be generated with activity in the two hemispheres controlling opposite muscles (<a href=\"#bib25\">Hancock and Delgutte, 2004</a>). However, in addition to the fact that there are spatially tuned neurons in the inferior colliculus (<a href=\"#bib1\">Aitkin et al., 1985</a>), this idea does not fit with what is known of the physiology of eye movements. Cats orient their gaze toward a briefly presented sound, a behavioral response that has been used to measure sound localization accuracy (<a href=\"#bib63\">Tollin et al., 2005</a>). Eye movements are controlled by neurons in the superior colliculus (SC), which form a map (a \u2018place code\u2019): stimulation of neurons in the SC produces saccades whose amplitude and direction depend on the site of stimulation, but not on intensity or frequency of stimulation (<a href=\"#bib55\">Sparks and Nelson, 1987</a>). Some of these neurons are tuned to sound location (<a href=\"#bib52\">Populin et al., 2004</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "The anatomy and physiology of the ITD processing pathway are very similar across mammalian species (<a href=\"#bib24\">Grothe et al., 2010</a>). However, while hemispheric decoding might be consistent with behavioral data in small mammals, it is not with data in cats and humans. Therefore, if there is a common mechanism for ITD processing in mammals, it cannot be based on pooling neural activity on each hemisphere. A traditional argument in favor of the hemispheric model of ITD processing or \u2018slope coding\u2019 is that in small mammals, there are many binaural neurons with large BDs, which is contradictory with a labeled line code. However, it should be noted that the exact symmetrical argument applies as well: there are many binaural neurons with small BDs (within the ecological range), both in small and large mammals, which is contradictory with the slope coding hypothesis."
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s3-5", 
                        "title": "Experimental predictions", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "Traditionally, physiological studies of ITD processing have focused on the question of sensitivity: how responses vary along the dimension to be estimated (ITD), which is typically measured by recording ITD selectivity curves. Indeed, there can be no information about ITD in responses that are insensitive to ITD. But sensitivity is only a necessary condition. To understand how ITD is extracted, one must identify those aspects of neural responses that are specific to ITD. In other words, one must analyze not only what varies with ITD but also what is invariant when properties other than ITD vary."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "This point is related to the difference in behavioral studies between acuity, a measure of discriminability between stimuli, and accuracy, a more ecologically relevant measure of how well the animal can reach a target (<a href=\"#bib27\">Heffner and Heffner, 2005</a>; <a href=\"#bib63\">Tollin et al., 2005</a>). Indeed, the computationally challenging task for a sensory system is not to discriminate between two signals, but to extract meaningful information in face of the tremendous diversity of sensory inputs in ecological environments."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "Such an analysis requires recording neural responses to a large variety of sounds. For practical reasons, we based our study on model responses. In principle, the same analysis could be done experimentally by recording the responses of a large number of cells to a broad set of sounds and levels presented at different locations. Given the large number of stimuli, such a study might require imaging or multielectrode recordings. An initial approach could be to look for invariant properties in the response of a subset of neurons to natural sounds presented at the same spatial location."
                            }
                        ]
                    }
                ]
            }, 
            {
                "type": "section", 
                "id": "s4", 
                "title": "Materials and methods", 
                "content": [
                    {
                        "type": "section", 
                        "id": "s4-1", 
                        "title": "Response model", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "The basic model consists of the following stages, illustrated in <a href=\"#fig1\">Figure 1B</a>."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "A sound S has a location \u03b8, which could be an ITD or azimuth. Sounds are either (i) white noise, (ii) band-passed white noise, or (iii) colored noise with a <math id=\"inf1\"><mrow><mfrac><mn>1</mn><mrow><msup><mi>f</mi><mi>\u03b1</mi></msup></mrow></mfrac></mrow></math> spectrum with color parameter \u03b1 between 0 and 2 (0 = white noise, 1 = pink noise, 2 = brown noise)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "The signal received at the two ears is this sound transformed by a pair of HRTFs for that location. We consider two HRTF models: (i) no diffraction, that is, frequency-independent ITDs, and (ii) HRTFs measured in an anechoic chamber (<a href=\"#fig6 fig8\">Figures 6 and 8</a>). In addition to the target sound, each ear can receive an acoustic noise (<a href=\"#fig5\">Figure 5</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "The signal received at each ear is then monaurally filtered by a gammatone filter bank (<a href=\"#bib20\">Glasberg and Moore, 1990</a>; <a href=\"#bib54\">Slaney, 1993</a>) with center frequencies and bandwidths defined by the animal model (see below). The equivalent rectangular bandwidth (ERB) Q factor of a filter is defined as <math id=\"inf2\"><mrow><msub><mi>Q</mi><mrow><mi mathvariant=\"normal\">ERB</mi></mrow></msub><mrow><mo>(</mo><mi>f</mi><mo>)</mo></mrow><mo>=</mo><mfrac><mi>f</mi><mrow><mi mathvariant=\"normal\">ERB</mi><mrow><mo>(</mo><mi>f</mi><mo>)</mo></mrow></mrow></mfrac></mrow></math> where ERB(<i>f</i>) is the width of a rectangular filter that would pass as much power as the filter (for white noise). Following <a href=\"#bib53\">Shera et al. (2002)</a>, we use the formula <math id=\"inf3\"><mrow><msub><mi>Q</mi><mrow><mi mathvariant=\"normal\">ERB</mi></mrow></msub><mo>=</mo><mi>\u03b2</mi><msup><mrow><mrow><mo>(</mo><mrow><mfrac><mi>f</mi><mrow><mi mathvariant=\"normal\">kHz</mi></mrow></mfrac></mrow><mo>)</mo></mrow></mrow><mi>\u03b1</mi></msup></mrow></math>, where \u03b1 and \u03b2 are parameters specific to the animal model (see below)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "Each binaural neuron receives two monaurally filtered inputs, one from each side, with an internal delay defined by the animal model. The firing rate response of the binaural neuron is given by the formula <math id=\"inf4\"><mrow><mstyle displaystyle=\"true\"><mo>\u222b</mo></mstyle><msup><mrow><mo>(</mo><mi>L</mi><mo>+</mo><mi>R</mi><mo>)</mo></mrow><mtext>k</mtext></msup></mrow></math>, with a constant k defined by the animal model, and L(t) and R(t) are delayed and normalized versions of the gammatone filtered signals at the left and right ears at time t. The normalization factor is proportional to <math id=\"inf5\"><mrow><msup><mrow><mo>|</mo><mrow><mstyle displaystyle=\"true\"><mo>\u222b</mo></mstyle><msup><mrow><mo>(</mo><mi>L</mi><mo>+</mo><mi>R</mi><mo>)</mo></mrow><mtext>k</mtext></msup></mrow><mo>|</mo></mrow><mrow><mfrac><mn>1</mn><mtext>k</mtext></mfrac></mrow></msup></mrow></math>, and chosen for a target maximal firing rate F of the binaural neuron. This binaural model is a generalization of two previous models that were found to produce good fits for the delay\u2013response curves of the guinea pig (<a href=\"#bib26\">Harper and McAlpine, 2004</a>) and owl models (<a href=\"#bib15\">Fischer et al., 2008</a>). Here, we generalized it to include cats and humans, and checked that the delay\u2013response curves give good fits to published data for the cat (<a href=\"#bib33\">Joris et al., 2006</a>)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "The result is the output response r of the binaural neuron, and the spike count is drawn from a Poisson distribution with mean r (so that r/T is the firing rate of the neuron for duration T)."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "All simulations were performed using the \u2018Brian\u2019 simulator (<a href=\"#bib21\">Goodman and Brette, 2008</a>, <a href=\"#bib22\">2009</a>) with the \u2018Brian hears\u2019 auditory periphery library (<a href=\"#bib18\">Fontaine et al., 2011</a>)."
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s4-2", 
                        "title": "Animal models", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "Each binaural neuron then is specified by a BF and a BD so that the left channel is delayed by BD/2 and the right channel by \u2212BD/2. The distribution of these parameters, as well as the bandwidths for the monaural filters, is defined separately for each animal model."
                            }, 
                            {
                                "type": "paragraph", 
                                "text": "For all models, we used a range of 480 BFs ERB spaced between 100 Hz and 1.5 kHz, with the exception of the cat model with HRTFs (as the recorded HRTFs were not reliable below 400 Hz) and the owl (which uses higher frequencies for ITD processing). The firing rate of the binaural neurons was calibrated to have a peak of F = 200 Hz. As firing is Poisson, smaller or larger values would only increase or decrease neuronal noise. Parameters for all models are summarised in <a href=\"#tbl1\">Table 1</a>."
                            }, 
                            {
                                "type": "table", 
                                "doi": "10.7554/eLife.01312.012", 
                                "id": "tbl1", 
                                "label": "Table 1.", 
                                "title": "Summary of animal models", 
                                "caption": [
                                    {
                                        "type": "paragraph", 
                                        "text": "Summary of animal models"
                                    }
                                ], 
                                "tables": [
                                    "<table><thead><tr><th>Name</th><th>ITD source</th><th>ITD range, \u03bcs</th><th>Best delays (BD)</th><th>Best frequencies (BF)</th><th>\u03b1</th><th>\u03b2</th><th>k</th></tr></thead><tbody><tr><td>Guinea pig</td><td>Artificial</td><td>\u00b1 300</td><td>Measured</td><td>100\u20131500 Hz</td><td align=\"char\" char=\".\">0.35</td><td align=\"char\" char=\".\">4.0</td><td align=\"char\" char=\".\">8</td></tr><tr><td>Guinea pig</td><td>HRTF</td><td>\u00b1 250</td><td>Measured</td><td>100\u20131500 Hz</td><td align=\"char\" char=\".\">0.35</td><td align=\"char\" char=\".\">4.0</td><td align=\"char\" char=\".\">8</td></tr><tr><td>Cat</td><td>Artificial</td><td>\u00b1 400</td><td>Measured</td><td>100\u20131500 Hz</td><td align=\"char\" char=\".\">0.37</td><td align=\"char\" char=\".\">5.0</td><td align=\"char\" char=\".\">4</td></tr><tr><td>Cat</td><td>HRTF</td><td>\u00b1 450</td><td>Measured</td><td>400\u20131500 Hz</td><td align=\"char\" char=\".\">0.37</td><td align=\"char\" char=\".\">5.0</td><td align=\"char\" char=\".\">4</td></tr><tr><td>Human</td><td>HRTF</td><td>\u00b1 950</td><td>Uniform within \u03c0-limit</td><td>100\u20131500 Hz</td><td align=\"char\" char=\".\">0.37</td><td align=\"char\" char=\".\">5.0</td><td align=\"char\" char=\".\">4</td></tr><tr><td>Human</td><td>HRTF</td><td>\u00b1 950</td><td>Guinea pig distribution</td><td>100\u20131500 Hz</td><td align=\"char\" char=\".\">0.37</td><td align=\"char\" char=\".\">5.0</td><td align=\"char\" char=\".\">4</td></tr><tr><td>Human</td><td>HRTF</td><td>\u00b1 950</td><td>Cat distribution</td><td>100\u20131500 Hz</td><td align=\"char\" char=\".\">0.37</td><td align=\"char\" char=\".\">5.0</td><td align=\"char\" char=\".\">4</td></tr><tr><td>Owl</td><td>HRTF</td><td>\u00b1 260</td><td>Measured</td><td>2\u20138 kHz</td><td align=\"char\" char=\".\">0.50</td><td align=\"char\" char=\".\">4.3</td><td align=\"char\" char=\".\">2</td></tr></tbody></table>"
                                ]
                            }, 
                            {
                                "type": "section", 
                                "id": "s4-2-1", 
                                "title": "Guinea pig", 
                                "content": [
                                    {
                                        "type": "paragraph", 
                                        "text": "For the artificially induced ITD model (no diffraction), we use a maximal ITD of 300 \u03bcs (<a href=\"#bib57\">Sterbing et al., 2003</a>) and a range of BDs measured from inferior colliculus of guinea pigs (<a href=\"#bib47\">McAlpine et al., 2001</a>). Given a BF, we selected a BD from a normal distribution with the measured mean and variance for that BF. The bandwidth parameters \u03b1 and \u03b2 were as given in <a href=\"#bib53\">Shera et al. (2002)</a>. The binaural power k was selected to match the curves in <a href=\"#bib26\">Harper and McAlpine (2004)</a>. We measured high-resolution guinea pig HRTFs from a taxidermist model from the Museum of Natural History (Paris), in an anechoic chamber covered with glass wool wedges, using the same protocol and equipment as for the LISTEN HRTF database (<a href=\"http://www.ircam.fr/equipes/salles/listen/\">http://www.ircam.fr/equipes/salles/listen/</a>). Because of the impedance mismatch between the skin and the air, acoustical properties are essentially determined by the shape, not by the material inside the body. The taxidermist model is both still and in a natural posture, which makes it very convenient to measure reliable HRTFs. ITDs were found to be frequency dependent, a maximal ITD of 250 \u03bcs, consistent with previously reported measurements in live guinea pigs (<a href=\"#bib57\">Sterbing et al., 2003</a>)."
                                    }
                                ]
                            }, 
                            {
                                "type": "section", 
                                "id": "s4-2-2", 
                                "title": "Cat", 
                                "content": [
                                    {
                                        "type": "paragraph", 
                                        "text": "For the artificially induced ITD model, we used a maximal ITD of 400 \u03bcs (<a href=\"#bib68\">Yin and Chan, 1990b</a>) and a range of BDs measured from cat IC (<a href=\"#bib33\">Joris et al., 2006</a>). We generated a kernel density estimate (KDE) probability distribution of BD and BF from the measured set, and then for each BF, we chose a BD from the conditional KDE distribution of BD, given the BF. The measured data used characteristic frequency (CF) rather than BF; however, in a linear model such as the one used here, these two measures are equivalent. The bandwidth parameters \u03b1 and \u03b2 were as given in <a href=\"#bib53\">Shera et al. (2002)</a>. The binaural power k = 4 was chosen to fit the data of <a href=\"#bib33\">Joris et al. (2006)</a>, although note selecting a power of k = 2 to match the guinea pig model did not significantly alter the results. For the HRTF model, we used the HRTFs recorded by <a href=\"#bib62\">Tollin and Koka (2009b)</a>, which had a maximal ITD of 450 \u03bcs. These HRTFs were unreliable below 400 Hz, and so this model was restricted to be used between 400 Hz and 1.5 kHz."
                                    }
                                ]
                            }, 
                            {
                                "type": "section", 
                                "id": "s4-2-3", 
                                "title": "Owl", 
                                "content": [
                                    {
                                        "type": "paragraph", 
                                        "text": "We used HRTFs and a distribution of BDs measured from barn owl IC from <a href=\"#bib64\">Wagner et al. (2007)</a>. BDs were chosen using the same procedure as in cats, with KDE estimates. The HRTFs had a maximal ITD of 260 \u03bcs. The bandwidth parameters \u03b1 and \u03b2 were as given in <a href=\"#bib36\">K\u00f6ppl (1997)</a>. The binaural power k from <a href=\"#bib15\">Fischer et al. (2008)</a> was used. BFs from 2\u20138 kHz were used, as the owl is known to be ITD sensitive above 2 kHz (<a href=\"#bib9\">Coles and Guppy, 1988</a>), and the HRTFs were only accurate up to 8 kHz."
                                    }
                                ]
                            }, 
                            {
                                "type": "section", 
                                "id": "s4-2-4", 
                                "title": "Human", 
                                "content": [
                                    {
                                        "type": "paragraph", 
                                        "text": "HRTFs from the IRCAM LISTEN database (<a href=\"http://www.ircam.fr/equipes/salles/listen/\">http://www.ircam.fr/equipes/salles/listen/</a>) were used. These had a maximal ITD of approximately 950 \u03bcs. As the distribution of BDs in human is unknown, we used three hypothetical distributions: (i) a uniform distribution of BDs within the pi-limit, (ii) the distribution used in the guinea pig model, and (iii) the distribution used in the cat model. Bandwidth parameters and the binaural power k were as used in the cat. We tested other binaural powers and bandwidths (including the much sharper bandwidth estimates from <a href=\"#bib53\">Shera et al. (2002)</a>), but these did not significantly alter our results."
                                    }
                                ]
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s4-3", 
                        "title": "Decoders", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "The decoding problem is to compute an estimate <math id=\"inf6\"><mrow><mover accent=\"true\"><mi>\u03b8</mi><mo>^</mo></mover></mrow></math> of \u03b8, given the vector of responses <b>r</b> of the binaural neurons. We define a training set and a testing set of data. The acoustical inputs can be different between the two sets, for example, training with white noise and testing with colored noise (<a href=\"#fig3\">Figure 3D</a>). The training set is used to set the parameters of the decoder, and the testing set is used to compute the errors and biases of the decoder (\u2018Analysis\u2019). We consider the following decoders, all of which can be straightforwardly implemented with a simple neural circuit:"
                            }, 
                            {
                                "type": "section", 
                                "id": "s4-3-1", 
                                "title": "Peak decoder", 
                                "content": [
                                    {
                                        "type": "paragraph", 
                                        "text": "The naive form of the peak decoder takes <math id=\"inf7\"><mrow><mrow><mover accent=\"true\"><mi>\u03b8</mi><mo>^</mo></mover></mrow><mrow><mo>(</mo><mi mathvariant=\"bold\">r</mi><mo>)</mo></mrow></mrow></math> to be the BD of the maximally responsive neuron. We also define a smoothed form, in which the maximum is taken with respect to a Gaussian smoothed response of <b>r</b> defined by <math id=\"inf8\"><mrow><mi>\u03c3</mi><msub><mrow><mo>(</mo><mi mathvariant=\"bold\">r</mi><mo>)</mo></mrow><mi>i</mi></msub><mo>=</mo><mrow><mrow><munder><mstyle displaystyle=\"true\"><mo>\u2211</mo></mstyle><mi>j</mi></munder><msub><mi>\u03c9</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msub><mi>r</mi><mi>j</mi></msub></mrow><mo>/</mo><mrow><munder><mstyle displaystyle=\"true\"><mo>\u2211</mo></mstyle><mi>j</mi></munder><msub><mi>\u03c9</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mrow></mrow></math>, where <math id=\"inf9\"><mrow><msub><mi>\u03c9</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msup><mi>e</mi><mrow><mfrac><mrow><mo>\u2212</mo><msup><mrow><mo>(</mo><mrow><mi>B</mi><msub><mi>D</mi><mtext>i</mtext></msub><mo>\u2212</mo><mi>B</mi><msub><mi>D</mi><mtext>j</mtext></msub></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><msup><mi>w</mi><mn>2</mn></msup></mrow></mfrac></mrow></msup></mrow></math> and <i>w</i> is the smoothing window width."
                                    }
                                ]
                            }, 
                            {
                                "type": "section", 
                                "id": "s4-3-2", 
                                "title": "Hemispheric decoder", 
                                "content": [
                                    {
                                        "type": "paragraph", 
                                        "text": "A normalized hemispheric difference \u03bb is computed as the difference between the sum of the responses of neurons with positive BDs and the sum of the responses of neurons with negative BDs divided by the sum of the responses of all the neurons. Mathematically, <math id=\"inf10\"><mrow><mi mathvariant=\"normal\">\u03bb</mi><mrow><mo>(</mo><mi mathvariant=\"bold\">r</mi><mo>)</mo></mrow><mo>=</mo><mfrac><mrow><mo>(</mo><mstyle displaystyle=\"true\"><msub><mo>\u2211</mo><mrow><mtext>i</mtext><mo>\u2208</mo><mtext>I</mtext></mrow></msub><mrow><msub><mi>r</mi><mtext>i</mtext></msub></mrow></mstyle><mo>\u2212</mo><mstyle displaystyle=\"true\"><msub><mo>\u2211</mo><mrow><mtext>i</mtext><mo>\u2209</mo><mtext>I</mtext></mrow></msub><mrow><msub><mi>r</mi><mtext>i</mtext></msub></mrow></mstyle><mo>)</mo></mrow><mrow><mstyle displaystyle=\"true\"><msub><mo>\u2211</mo><mi mathvariant=\"normal\">i</mi></msub><mrow><msub><mi>r</mi><mtext>i</mtext></msub></mrow></mstyle></mrow></mfrac></mrow></math>, where I is the set of neurons with positive BD. The estimation <math id=\"inf11\"><mrow><mrow><mover accent=\"true\"><mi>\u03b8</mi><mo>^</mo></mover></mrow><mrow><mo>(</mo><mi mathvariant=\"bold\">r</mi><mo>)</mo></mrow></mrow></math> is defined by inverting the average hemispheric difference <math id=\"inf12\"><mrow><mrow><mover accent=\"true\"><mi mathvariant=\"normal\">\u03bb</mi><mo>\u00af</mo></mover></mrow><mrow><mo>(</mo><mtext>\u03b8</mtext><mo>)</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo>[</mo><mi mathvariant=\"normal\">\u03bb</mi><mrow><mo>(</mo><mi mathvariant=\"bold\">r</mi><mo>)</mo></mrow><mo>|</mo><mtext>\u03b8</mtext><mo>]</mo></mrow></mrow></math>, where the expectation is taken over the training data. In practice, a polynomial p(\u03b8) is fitted to the data (\u03b8<sub>i</sub>, \u03bb<sub>i</sub>) where \u03b8<sub>i</sub> is the location of training datum i and \u03bb<sub>i</sub> is the corresponding hemispheric difference, and this polynomial is inverted to give <math id=\"inf13\"><mrow><mrow><mover accent=\"true\"><mi>\u03b8</mi><mo>^</mo></mover></mrow><mrow><mo>(</mo><mi mathvariant=\"bold\">r</mi><mo>)</mo></mrow><mo>=</mo><msup><mtext>p</mtext><mrow><mo>\u2212</mo><mn>1</mn></mrow></msup><mrow><mo>(</mo><mi mathvariant=\"normal\">\u03bb</mi><mrow><mo>(</mo><mi mathvariant=\"bold\">r</mi><mo>)</mo></mrow><mo>)</mo></mrow></mrow></math>. The degree of the polynomial was chosen to maximize performance (lower degrees fit poorly but higher degrees overfit). We also consider an enhanced version of the hemispheric model able to integrate information across frequencies, the frequency-dependent hemispheric model, where the ratio is given by <math id=\"inf14\"><mrow><mi>\u03bb</mi><mrow><mo>(</mo><mi mathvariant=\"bold\">r</mi><mo>)</mo></mrow><mo>=</mo><mfrac><mrow><mo>(</mo><mrow><mstyle displaystyle=\"true\"><msub><mo>\u2211</mo><mrow><mtext>i</mtext><mo>\u2208</mo><mtext>I</mtext></mrow></msub><mrow><mfrac><mrow><msub><mi>r</mi><mtext>i</mtext></msub></mrow><mrow><msub><mi>f</mi><mtext>i</mtext></msub></mrow></mfrac></mrow></mstyle><mo>\u2212</mo><mstyle displaystyle=\"true\"><msub><mo>\u2211</mo><mrow><mtext>i</mtext><mo>\u2209</mo><mtext>I</mtext></mrow></msub><mrow><mfrac><mrow><msub><mi>r</mi><mtext>i</mtext></msub></mrow><mrow><msub><mi>f</mi><mtext>i</mtext></msub></mrow></mfrac></mrow></mstyle></mrow><mo>)</mo></mrow><mrow><mstyle displaystyle=\"true\"><msub><mo>\u2211</mo><mi mathvariant=\"normal\">i</mi></msub><mrow><msub><mi>r</mi><mtext>i</mtext></msub></mrow></mstyle></mrow></mfrac></mrow></math>, where <i>f</i><sub>i</sub> is the BF of neuron i. Most papers studying the hemispheric difference model do not take varying levels into account and therefore use an un-normalized hemispheric difference. <a href=\"#bib56\">Stecker et al. (2005)</a> use the maximum rather than the sum as a normalizing factor, but this is essentially equivalent."
                                    }
                                ]
                            }, 
                            {
                                "type": "section", 
                                "id": "s4-3-3", 
                                "title": "Pattern match decoder", 
                                "content": [
                                    {
                                        "type": "paragraph", 
                                        "text": "Each training datum forms a response pattern we write as <b>\u03c1</b> to distinguish from the testing response <b>r</b>. We compute a similarity index for each training datum"
                                    }, 
                                    {
                                        "type": "mathml", 
                                        "id": "equ1", 
                                        "mathml": "<math><mrow><msub><mi>\u03c8</mi><mi>j</mi></msub><mo>=</mo><mrow><mo>(</mo><mrow><mfrac><mi mathvariant=\"bold-italic\">r</mi><mrow><mo>|</mo><mi mathvariant=\"bold-italic\">r</mi><mo>|</mo></mrow></mfrac></mrow><mo>)</mo></mrow><mo>.</mo><mrow><mrow><mo>(</mo><mrow><mfrac><mrow><msub><mi mathvariant=\"bold-italic\">\u03c1</mi><mi mathvariant=\"bold-italic\">j</mi></msub></mrow><mrow><mo>|</mo><mrow><msub><mi mathvariant=\"bold-italic\">\u03c1</mi><mi mathvariant=\"bold-italic\">j</mi></msub></mrow><mo>|</mo></mrow></mfrac></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mfrac><mrow><msub><mstyle displaystyle=\"true\"><mo>\u2211</mo></mstyle><mi>i</mi></msub><msub><mi>r</mi><mi>i</mi></msub><msub><mi>\u03c1</mi><mrow><mi>j</mi><mi>i</mi></mrow></msub></mrow><mrow><msqrt><mrow><msub><mstyle displaystyle=\"true\"><mo>\u2211</mo></mstyle><mi>i</mi></msub><msubsup><mi>r</mi><mi>i</mi><mn>2</mn></msubsup></mrow></msqrt><mo>.</mo><msqrt><mrow><msub><mstyle displaystyle=\"true\"><mo>\u2211</mo></mstyle><mi>i</mi></msub><msubsup><mi>\u03c1</mi><mrow><mi>j</mi><mi>i</mi></mrow><mn>2</mn></msubsup></mrow></msqrt></mrow></mfrac><mo>,</mo></mrow></math>"
                                    }, 
                                    {
                                        "type": "paragraph", 
                                        "text": "which varies between 0 (totally dissimilar) and 1 (totally similar). This is the standard cosine similarity measure from machine learning theory (the value of <math id=\"inf15\"><mrow><msub><mi>\u03c8</mi><mi>j</mi></msub></mrow></math> is the cosine of the angle between the two vectors). The estimate <math id=\"inf16\"><mrow><mrow><mover accent=\"true\"><mi>\u03b8</mi><mo>^</mo></mover></mrow><mrow><mo>(</mo><mi mathvariant=\"bold\">r</mi><mo>)</mo></mrow></mrow></math> is the location \u03b8<sub>j</sub> for the index j that maximizes <math id=\"inf17\"><mrow><msub><mi>\u03c8</mi><mi>j</mi></msub></mrow></math>. We also consider a frequency-dependent pattern matching decoder in which the pattern <math id=\"inf18\"><mrow><msub><mi mathvariant=\"bold-italic\">\u03c1</mi><mi mathvariant=\"bold-italic\">j</mi></msub></mrow></math> is broken into subvectors corresponding to frequency bands, and each subvector is normalized separately. That is, each neural response is divided by the norm of all the neural responses in the same frequency band. More precisely, assuming that the neuron indices are sorted by increasing BF, and the bands are of equal size consisting of B neurons each (i.e., the first band is neurons 0 to B \u2212 1, the second from B to 2B \u2212 1, etc.; we used B = 40), we compute the dot product"
                                    }, 
                                    {
                                        "type": "mathml", 
                                        "id": "equ2", 
                                        "mathml": "<math><mrow><msub><mi>\u03c8</mi><mi>j</mi></msub><mo>=</mo><mrow><mo>(</mo><mrow><mfrac><mi mathvariant=\"bold-italic\">r</mi><mrow><mo>|</mo><mi mathvariant=\"bold-italic\">r</mi><mo>|</mo></mrow></mfrac></mrow><mo>)</mo></mrow><mo>.</mo><mtext>bandnorm</mtext><mrow><mo>(</mo><msub><mi mathvariant=\"bold-italic\">\u03c1</mi><mi mathvariant=\"bold-italic\">j</mi></msub><mo>)</mo></mrow><mo>=</mo><munder><mstyle displaystyle=\"true\"><mo>\u2211</mo></mstyle><mi>i</mi></munder><mfrac><mrow><msub><mi>r</mi><mi>i</mi></msub></mrow><mrow><msqrt><mrow><msub><mstyle displaystyle=\"true\"><mo>\u2211</mo></mstyle><mi>k</mi></msub><msubsup><mi>r</mi><mi>k</mi><mn>2</mn></msubsup></mrow></msqrt></mrow></mfrac><mo>.</mo><mfrac><mrow><msub><mi>\u03c1</mi><mrow><mi>j</mi><mi>i</mi></mrow></msub></mrow><mrow><msqrt><mrow><msubsup><mstyle displaystyle=\"true\"><mo>\u2211</mo></mstyle><mrow><mi>k</mi><mo>=</mo><mrow><mo>(</mo><mrow><mrow><mo>\u230a</mo><mrow><mfrac><mi>i</mi><mi>B</mi></mfrac></mrow><mo>\u230b</mo></mrow><mo>.</mo><mi>B</mi></mrow><mo>)</mo></mrow></mrow><mrow><mrow><mo>(</mo><mrow><mrow><mo>\u230a</mo><mrow><mfrac><mi>i</mi><mi>B</mi></mfrac></mrow><mo>\u230b</mo></mrow><mo>+</mo><mn>1</mn></mrow><mo>)</mo></mrow><mo>.</mo><mi>B</mi><mo>\u2212</mo><mn>1</mn></mrow></msubsup><msubsup><mi>\u03c1</mi><mrow><mi>j</mi><mi>k</mi></mrow><mn>2</mn></msubsup></mrow></msqrt></mrow></mfrac><mo>,</mo></mrow></math>"
                                    }, 
                                    {
                                        "type": "paragraph", 
                                        "text": "where for a vector <b>x</b>, <math id=\"inf19\"><mrow><mtext>bandnorm</mtext><msub><mrow><mo>(</mo><mi mathvariant=\"bold-italic\">x</mi><mo>)</mo></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><msub><mi mathvariant=\"bold-italic\">x</mi><mi>i</mi></msub></mrow><mrow><msqrt><mrow><msubsup><mstyle displaystyle=\"true\"><mo>\u2211</mo></mstyle><mrow><mi>j</mi><mo>=</mo><mrow><mo>(</mo><mrow><mrow><mo>\u230a</mo><mrow><mfrac><mi>i</mi><mi>B</mi></mfrac></mrow><mo>\u230b</mo></mrow><mo>.</mo><mi>B</mi></mrow><mo>)</mo></mrow></mrow><mrow><mrow><mrow><mo>(</mo><mrow><mrow><mo>\u230a</mo><mrow><mfrac><mi>i</mi><mi>B</mi></mfrac></mrow><mo>\u230b</mo></mrow><mo>+</mo><mn>1</mn></mrow><mo>)</mo></mrow></mrow><mo>.</mo><mi>B</mi><mo>\u2212</mo><mn>1</mn></mrow></msubsup><msubsup><mi>x</mi><mi>j</mi><mn>2</mn></msubsup></mrow></msqrt></mrow></mfrac></mrow></math>, where \u230a<i>z</i>\u230b is the floor function, the greatest integer less than or equal to z. Note that this banded <math id=\"inf20\"><mrow><msub><mi>\u03c8</mi><mi>j</mi></msub></mrow></math> does not vary between 0 and 1, but the value of j that maximizes it is still used to find the best estimate of the location."
                                    }, 
                                    {
                                        "type": "paragraph", 
                                        "text": "In addition to these three decoders, we tested several standard decoders from machine learning and theoretical neuroscience including linear/ridge regression, nearest neighbor regression, maximum likelihood estimators, and support vector classifiers. Data for some of these are shown in <a href=\"#fig3s1\">Figure 3\u2014figure supplement 1</a>. Detailed results and analysis of these decoders are not presented here, as in all cases they were outperformed by the pattern match decoder. The best of these decoders was nearest neighbor regression, which performed almost as well as the pattern match decoder. The machine learning algorithms were implemented using the scikits-learn package (<a href=\"#bib51\">Pedregosa et al., 2011</a>)."
                                    }
                                ]
                            }
                        ]
                    }, 
                    {
                        "type": "section", 
                        "id": "s4-4", 
                        "title": "Analysis", 
                        "content": [
                            {
                                "type": "paragraph", 
                                "text": "We analyze the decoders based on their errors and biases. The error is computed as <math id=\"inf21\"><mrow><mi>E</mi><mrow><mo>[</mo><mo>|</mo><mrow><mover accent=\"true\"><mi>\u03b8</mi><mo>^</mo></mover></mrow><mo>\u2212</mo><mtext>\u03b8</mtext><mo>|</mo><mo>]</mo></mrow></mrow></math>, where the expectation is taken over the testing data. The bias is computed by taking a linear regression through the points <math id=\"inf22\"><mrow><mo>(</mo><msub><mtext>\u03b8</mtext><mtext>i</mtext></msub><mo>,</mo><msub><mrow><mover accent=\"true\"><mi>\u03b8</mi><mo>^</mo></mover></mrow><mtext>i</mtext></msub><mo>)</mo></mrow></math> with the restriction that the line must pass through (0, 0). The bias <i>b</i> is given as a percentage bias toward the center from the slope <i>g</i> of the best fit line via <math id=\"inf23\"><mrow><mi>b</mi><mo>=</mo><mn>100</mn><mtext>\u2009</mtext><mrow><mo>(</mo><mn>1</mn><mo>\u2212</mo><mi>g</mi><mo>)</mo></mrow></mrow></math>. To get a better estimate, we compute multiple values of the error and bias over 25 different shuffles of the data, and compute the mean and standard deviation of these values over the multiple shuffles. We generate 6400 total data, and to form each shuffled set of data, we take the following steps: (i) choose a subset of the full set of cells to consider (in those analyses where the number of cells was varied), (ii) choose a random subset of the data as training data, usually 400 data, (iii) choose a nonoverlapping random subset of the data as testing data, usually 800 data. This procedure was chosen to minimize biases introduced by the random sampling while keeping total computation times to a reasonable level (total computation time on an 8-core Intel i7 desktop was approximately 1 week)."
                            }
                        ]
                    }
                ]
            }
        ], 
        "references": [
            {
                "type": "journal", 
                "id": "bib1", 
                "date": "1985", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "LM Aitkin", 
                            "index": "Aitkin, LM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JD Pettigrew", 
                            "index": "Pettigrew, JD"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "MB Calford", 
                            "index": "Calford, MB"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "SC Phillips", 
                            "index": "Phillips, SC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "LZ Wise", 
                            "index": "Wise, LZ"
                        }
                    }
                ], 
                "articleTitle": "Representation of stimulus azimuth by low-frequency neurons in inferior colliculus of the cat", 
                "journal": {
                    "name": [
                        "J Neurophysiol"
                    ]
                }, 
                "volume": "53", 
                "pages": {
                    "first": "43", 
                    "last": "59", 
                    "range": "43\u201359"
                }
            }, 
            {
                "type": "journal", 
                "id": "bib2", 
                "date": "2011", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "G Ashida", 
                            "index": "Ashida, G"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "CE Carr", 
                            "index": "Carr, CE"
                        }
                    }
                ], 
                "articleTitle": "Sound localization: jeffress and beyond", 
                "journal": {
                    "name": [
                        "Curr Opin Neurobiol"
                    ]
                }, 
                "volume": "21", 
                "pages": {
                    "first": "745", 
                    "last": "751", 
                    "range": "745\u2013751"
                }, 
                "doi": "10.1016/j.conb.2011.05.008"
            }, 
            {
                "type": "journal", 
                "id": "bib3", 
                "date": "2001", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "D Attwell", 
                            "index": "Attwell, D"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "SB Laughlin", 
                            "index": "Laughlin, SB"
                        }
                    }
                ], 
                "articleTitle": "An energy budget for signaling in the grey matter of the brain", 
                "journal": {
                    "name": [
                        "J Cereb Blood Flow Metab"
                    ]
                }, 
                "volume": "21", 
                "pages": {
                    "first": "1133", 
                    "last": "1145", 
                    "range": "1133\u20131145"
                }, 
                "doi": "10.1097/00004647-200110000-00001"
            }, 
            {
                "type": "journal", 
                "id": "bib4", 
                "date": "2010", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Brette", 
                            "index": "Brette, R"
                        }
                    }
                ], 
                "articleTitle": "On the interpretation of sensitivity analyses of neural responses", 
                "journal": {
                    "name": [
                        "J Acoust Soc Am"
                    ]
                }, 
                "volume": "128", 
                "pages": {
                    "first": "2965", 
                    "last": "2972", 
                    "range": "2965\u20132972"
                }, 
                "doi": "10.1121/1.3488311"
            }, 
            {
                "type": "journal", 
                "id": "bib5", 
                "date": "2013", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "PM Briley", 
                            "index": "Briley, PM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "PT Kitterick", 
                            "index": "Kitterick, PT"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AQ Summerfield", 
                            "index": "Summerfield, AQ"
                        }
                    }
                ], 
                "articleTitle": "Evidence for opponent process analysis of sound source location in humans", 
                "journal": {
                    "name": [
                        "J Assoc Res Otolaryngol"
                    ]
                }, 
                "volume": "14", 
                "pages": {
                    "first": "83", 
                    "last": "101", 
                    "range": "83\u2013101"
                }, 
                "doi": "10.1007/s10162-012-0356-x"
            }, 
            {
                "type": "journal", 
                "id": "bib6", 
                "date": "2011", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Carandini", 
                            "index": "Carandini, M"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DJ Heeger", 
                            "index": "Heeger, DJ"
                        }
                    }
                ], 
                "articleTitle": "Normalization as a canonical neural computation", 
                "journal": {
                    "name": [
                        "Nat Rev Neurosci"
                    ]
                }, 
                "volume": "13", 
                "pages": {
                    "first": "51", 
                    "last": "62", 
                    "range": "51\u201362"
                }, 
                "doi": "10.1038/nrn3136"
            }, 
            {
                "type": "journal", 
                "id": "bib7", 
                "date": "1997", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Carlile", 
                            "index": "Carlile, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "P Leong", 
                            "index": "Leong, P"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Hyams", 
                            "index": "Hyams, S"
                        }
                    }
                ], 
                "articleTitle": "The nature and distribution of errors in sound localization by human listeners", 
                "journal": {
                    "name": [
                        "Hear Res"
                    ]
                }, 
                "volume": "114", 
                "pages": {
                    "first": "179", 
                    "last": "196", 
                    "range": "179\u2013196"
                }, 
                "doi": "10.1016/S0378-5955(97)00161-5"
            }, 
            {
                "type": "journal", 
                "id": "bib8", 
                "date": "1973", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JH Casseday", 
                            "index": "Casseday, JH"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "WD Neff", 
                            "index": "Neff, WD"
                        }
                    }
                ], 
                "articleTitle": "Localization of pure tones", 
                "journal": {
                    "name": [
                        "J Acoust Soc Am"
                    ]
                }, 
                "volume": "54", 
                "pages": {
                    "first": "365", 
                    "last": "372", 
                    "range": "365\u2013372"
                }, 
                "doi": "10.1121/1.1913586"
            }, 
            {
                "type": "journal", 
                "id": "bib9", 
                "date": "1988", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RB Coles", 
                            "index": "Coles, RB"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Guppy", 
                            "index": "Guppy, A"
                        }
                    }
                ], 
                "articleTitle": "Directional hearing in the barn owl (Tyto alba)", 
                "journal": {
                    "name": [
                        "J Comp Physiol A"
                    ]
                }, 
                "volume": "163", 
                "pages": {
                    "first": "117", 
                    "last": "133", 
                    "range": "117\u2013133"
                }, 
                "doi": "10.1007/BF00612002"
            }, 
            {
                "type": "journal", 
                "id": "bib10", 
                "date": "2010", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "K Couchman", 
                            "index": "Couchman, K"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "B Grothe", 
                            "index": "Grothe, B"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "F Felmy", 
                            "index": "Felmy, F"
                        }
                    }
                ], 
                "articleTitle": "Medial superior olivary neurons receive surprisingly few excitatory and inhibitory inputs with balanced strength and short-term dynamics", 
                "journal": {
                    "name": [
                        "J Neurosci"
                    ]
                }, 
                "volume": "30", 
                "pages": {
                    "first": "17111", 
                    "last": "17121", 
                    "range": "17111\u201317121"
                }, 
                "doi": "10.1523/JNEUROSCI.1760-10.2010"
            }, 
            {
                "type": "journal", 
                "id": "bib11", 
                "date": "2012", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "K Couchman", 
                            "index": "Couchman, K"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "B Grothe", 
                            "index": "Grothe, B"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "F Felmy", 
                            "index": "Felmy, F"
                        }
                    }
                ], 
                "articleTitle": "Functional localization of neurotransmitter receptors and synaptic inputs to mature neurons of the medial superior olive", 
                "journal": {
                    "name": [
                        "J Neurophysiol"
                    ]
                }, 
                "volume": "107", 
                "pages": {
                    "first": "1186", 
                    "last": "1198", 
                    "range": "1186\u20131198"
                }, 
                "doi": "10.1152/jn.00586.2011"
            }, 
            {
                "type": "journal", 
                "id": "bib12", 
                "date": "2013", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "ML Day", 
                            "index": "Day, ML"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "B Delgutte", 
                            "index": "Delgutte, B"
                        }
                    }
                ], 
                "articleTitle": "Decoding sound source location and separation using neural population activity patterns", 
                "journal": {
                    "name": [
                        "J Neurosci"
                    ]
                }, 
                "volume": "33", 
                "pages": {
                    "first": "15837", 
                    "last": "15847", 
                    "range": "15837\u201315847"
                }, 
                "doi": "10.1523/JNEUROSCI.2034-13.2013"
            }, 
            {
                "type": "book", 
                "id": "bib13", 
                "date": "2001", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "P Dayan", 
                            "index": "Dayan, P"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "L Abbott", 
                            "index": "Abbott, L"
                        }
                    }
                ], 
                "bookTitle": "Theoretical neuroscience: computational and mathematical modeling of neural systems", 
                "publisher": {
                    "name": [
                        "The MIT Press"
                    ], 
                    "address": {
                        "formatted": [
                            "Cambridge, MA"
                        ], 
                        "components": {
                            "locality": [
                                "Cambridge, MA"
                            ]
                        }
                    }
                }
            }, 
            {
                "type": "journal", 
                "id": "bib14", 
                "date": "2009", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Devore", 
                            "index": "Devore, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Ihlefeld", 
                            "index": "Ihlefeld, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "K Hancock", 
                            "index": "Hancock, K"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "B Shinn-Cunningham", 
                            "index": "Shinn-Cunningham, B"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "B Delgutte", 
                            "index": "Delgutte, B"
                        }
                    }
                ], 
                "articleTitle": "Accurate sound localization in reverberant environments is mediated by robust encoding of spatial cues in the auditory midbrain", 
                "journal": {
                    "name": [
                        "Neuron"
                    ]
                }, 
                "volume": "62", 
                "pages": {
                    "first": "123", 
                    "last": "134", 
                    "range": "123\u2013134"
                }, 
                "doi": "10.1016/j.neuron.2009.02.018"
            }, 
            {
                "type": "journal", 
                "id": "bib15", 
                "date": "2008", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "BJ Fischer", 
                            "index": "Fischer, BJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "GB Christianson", 
                            "index": "Christianson, GB"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JL Pena", 
                            "index": "Pena, JL"
                        }
                    }
                ], 
                "articleTitle": "Cross-correlation in the auditory coincidence detectors of owls", 
                "journal": {
                    "name": [
                        "J Neurosci"
                    ]
                }, 
                "volume": "28", 
                "pages": {
                    "first": "8107", 
                    "last": "8115", 
                    "range": "8107\u20138115"
                }, 
                "doi": "10.1523/JNEUROSCI.1969-08.2008"
            }, 
            {
                "type": "journal", 
                "id": "bib16", 
                "date": "2011", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "BJ Fischer", 
                            "index": "Fischer, BJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JL Pe\u00f1a", 
                            "index": "Pe\u00f1a, JL"
                        }
                    }
                ], 
                "articleTitle": "Owl\u2019s behavior and neural representation predicted by Bayesian inference", 
                "journal": {
                    "name": [
                        "Nat Neurosci"
                    ]
                }, 
                "volume": "14", 
                "pages": {
                    "first": "1061", 
                    "last": "1066", 
                    "range": "1061\u20131066"
                }, 
                "doi": "10.1038/nn.2872"
            }, 
            {
                "type": "journal", 
                "id": "bib17", 
                "date": "1997", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DC Fitzpatrick", 
                            "index": "Fitzpatrick, DC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Batra", 
                            "index": "Batra, R"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "TR Stanford", 
                            "index": "Stanford, TR"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Kuwada", 
                            "index": "Kuwada, S"
                        }
                    }
                ], 
                "articleTitle": "A neuronal population code for sound localization", 
                "journal": {
                    "name": [
                        "Nature"
                    ]
                }, 
                "volume": "388", 
                "pages": {
                    "first": "871", 
                    "last": "874", 
                    "range": "871\u2013874"
                }, 
                "doi": "10.1038/42246"
            }, 
            {
                "type": "journal", 
                "id": "bib18", 
                "date": "2011", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "B Fontaine", 
                            "index": "Fontaine, B"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DFM Goodman", 
                            "index": "Goodman, DFM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "V Benichoux", 
                            "index": "Benichoux, V"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Brette", 
                            "index": "Brette, R"
                        }
                    }
                ], 
                "articleTitle": "Brian hears: online auditory processing using vectorization over channels", 
                "journal": {
                    "name": [
                        "Front Neuroinform"
                    ]
                }, 
                "volume": "5", 
                "pages": "9", 
                "doi": "10.3389/fninf.2011.00009"
            }, 
            {
                "type": "journal", 
                "id": "bib19", 
                "date": "2000", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Furukawa", 
                            "index": "Furukawa, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "L Xu", 
                            "index": "Xu, L"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JC Middlebrooks", 
                            "index": "Middlebrooks, JC"
                        }
                    }
                ], 
                "articleTitle": "Coding of sound-source location by ensembles of cortical neurons", 
                "journal": {
                    "name": [
                        "J Neurosci"
                    ]
                }, 
                "volume": "20", 
                "pages": {
                    "first": "1216", 
                    "last": "1228", 
                    "range": "1216\u20131228"
                }
            }, 
            {
                "type": "journal", 
                "id": "bib20", 
                "date": "1990", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "BR Glasberg", 
                            "index": "Glasberg, BR"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "BC Moore", 
                            "index": "Moore, BC"
                        }
                    }
                ], 
                "articleTitle": "Derivation of auditory filter shapes from notched-noise data", 
                "journal": {
                    "name": [
                        "Hear Res"
                    ]
                }, 
                "volume": "47", 
                "pages": {
                    "first": "103", 
                    "last": "138", 
                    "range": "103\u2013138"
                }, 
                "doi": "10.1016/0378-5955(90)90170-T"
            }, 
            {
                "type": "journal", 
                "id": "bib21", 
                "date": "2008", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "D Goodman", 
                            "index": "Goodman, D"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Brette", 
                            "index": "Brette, R"
                        }
                    }
                ], 
                "articleTitle": "Brian: a simulator for spiking neural networks in python", 
                "journal": {
                    "name": [
                        "Front Neuroinform"
                    ]
                }, 
                "volume": "2", 
                "pages": "5", 
                "doi": "10.3389/neuro.11.005.2008"
            }, 
            {
                "type": "journal", 
                "id": "bib22", 
                "date": "2009", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DFM Goodman", 
                            "index": "Goodman, DFM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Brette", 
                            "index": "Brette, R"
                        }
                    }
                ], 
                "articleTitle": "The Brian simulator", 
                "journal": {
                    "name": [
                        "Front Neurosci"
                    ]
                }, 
                "volume": "3", 
                "pages": {
                    "first": "192", 
                    "last": "197", 
                    "range": "192\u2013197"
                }, 
                "doi": "10.3389/neuro.01.026.2009"
            }, 
            {
                "type": "journal", 
                "id": "bib23", 
                "date": "2012", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "B Gour\u00e9vitch", 
                            "index": "Gour\u00e9vitch, B"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Brette", 
                            "index": "Brette, R"
                        }
                    }
                ], 
                "articleTitle": "The impact of early reflections on binaural cues", 
                "journal": {
                    "name": [
                        "J Acoust Soc Am"
                    ]
                }, 
                "volume": "132", 
                "pages": {
                    "first": "9", 
                    "last": "27", 
                    "range": "9\u201327"
                }, 
                "doi": "10.1121/1.4726052"
            }, 
            {
                "type": "journal", 
                "id": "bib24", 
                "date": "2010", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "B Grothe", 
                            "index": "Grothe, B"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Pecka", 
                            "index": "Pecka, M"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "D McAlpine", 
                            "index": "McAlpine, D"
                        }
                    }
                ], 
                "articleTitle": "Mechanisms of sound localization in mammals", 
                "journal": {
                    "name": [
                        "Physiol Rev"
                    ]
                }, 
                "volume": "90", 
                "pages": {
                    "first": "983", 
                    "last": "1012", 
                    "range": "983\u20131012"
                }, 
                "doi": "10.1152/physrev.00026.2009"
            }, 
            {
                "type": "journal", 
                "id": "bib25", 
                "date": "2004", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "KE Hancock", 
                            "index": "Hancock, KE"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "B Delgutte", 
                            "index": "Delgutte, B"
                        }
                    }
                ], 
                "articleTitle": "A Physiologically based model of interaural time difference discrimination", 
                "journal": {
                    "name": [
                        "J Neurosci"
                    ]
                }, 
                "volume": "24", 
                "pages": {
                    "first": "7110", 
                    "last": "7117", 
                    "range": "7110\u20137117"
                }, 
                "doi": "10.1523/JNEUROSCI.0762-04.2004"
            }, 
            {
                "type": "journal", 
                "id": "bib26", 
                "date": "2004", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "NS Harper", 
                            "index": "Harper, NS"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "D McAlpine", 
                            "index": "McAlpine, D"
                        }
                    }
                ], 
                "articleTitle": "Optimal neural population coding of an auditory spatial cue", 
                "journal": {
                    "name": [
                        "Nature"
                    ]
                }, 
                "volume": "430", 
                "pages": {
                    "first": "682", 
                    "last": "686", 
                    "range": "682\u2013686"
                }, 
                "doi": "10.1038/nature02768"
            }, 
            {
                "type": "journal", 
                "id": "bib27", 
                "date": "2005", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "HE Heffner", 
                            "index": "Heffner, HE"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RS Heffner", 
                            "index": "Heffner, RS"
                        }
                    }
                ], 
                "articleTitle": "The sound-localization ability of cats", 
                "journal": {
                    "name": [
                        "J Neurophysiol"
                    ]
                }, 
                "volume": "94", 
                "pages": {
                    "first": "3653", 
                    "last": "3655", 
                    "range": "3653\u20133655"
                }, 
                "doi": "10.1152/jn.00720.2005"
            }, 
            {
                "type": "journal", 
                "id": "bib28", 
                "date": "1988", 
                "discriminator": "a", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RS Heffner", 
                            "index": "Heffner, RS"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "HE Heffner", 
                            "index": "Heffner, HE"
                        }
                    }
                ], 
                "articleTitle": "Sound localization acuity in the cat: effect of azimuth, signal duration, and test procedure", 
                "journal": {
                    "name": [
                        "Hear Res"
                    ]
                }, 
                "volume": "36", 
                "pages": {
                    "first": "221", 
                    "last": "232", 
                    "range": "221\u2013232"
                }, 
                "doi": "10.1016/0378-5955(88)90064-0"
            }, 
            {
                "type": "journal", 
                "id": "bib29", 
                "date": "1988", 
                "discriminator": "b", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RS Heffner", 
                            "index": "Heffner, RS"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "HE Heffner", 
                            "index": "Heffner, HE"
                        }
                    }
                ], 
                "articleTitle": "Sound localization and use of binaural cues by the gerbil (<i>Meriones unguiculatus</i>)", 
                "journal": {
                    "name": [
                        "Behav Neurosci"
                    ]
                }, 
                "volume": "102", 
                "pages": {
                    "first": "422", 
                    "last": "428", 
                    "range": "422\u2013428"
                }, 
                "doi": "10.1037/0735-7044.102.3.422"
            }, 
            {
                "type": "journal", 
                "id": "bib30", 
                "date": "1992", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RS Heffner", 
                            "index": "Heffner, RS"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "HE Heffner", 
                            "index": "Heffner, HE"
                        }
                    }
                ], 
                "articleTitle": "Visual factors in sound localization in mammals", 
                "journal": {
                    "name": [
                        "J Comp Neurol"
                    ]
                }, 
                "volume": "317", 
                "pages": {
                    "first": "219", 
                    "last": "232", 
                    "range": "219\u2013232"
                }, 
                "doi": "10.1002/cne.903170302"
            }, 
            {
                "type": "journal", 
                "id": "bib31", 
                "date": "1948", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "LA Jeffress", 
                            "index": "Jeffress, LA"
                        }
                    }
                ], 
                "articleTitle": "A place theory of sound localization", 
                "journal": {
                    "name": [
                        "J Comp Physiol Psychol"
                    ]
                }, 
                "volume": "41", 
                "pages": {
                    "first": "35", 
                    "last": "39", 
                    "range": "35\u201339"
                }, 
                "doi": "10.1037/h0061495"
            }, 
            {
                "type": "journal", 
                "id": "bib32", 
                "date": "1982", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "WM Jenkins", 
                            "index": "Jenkins, WM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RB Masterton", 
                            "index": "Masterton, RB"
                        }
                    }
                ], 
                "articleTitle": "Sound localization: effects of unilateral lesions in central auditory system", 
                "journal": {
                    "name": [
                        "J Neurophysiol"
                    ]
                }, 
                "volume": "47", 
                "pages": {
                    "first": "987", 
                    "last": "1016", 
                    "range": "987\u20131016"
                }
            }, 
            {
                "type": "journal", 
                "id": "bib33", 
                "date": "2006", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "PX Joris", 
                            "index": "Joris, PX"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "B Van de Sande", 
                            "index": "Van de Sande, B"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DH Louage", 
                            "index": "Louage, DH"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M van der Heijden", 
                            "index": "van der Heijden, M"
                        }
                    }
                ], 
                "articleTitle": "Binaural and cochlear disparities", 
                "journal": {
                    "name": [
                        "Proc Natl Acad Sci USA"
                    ]
                }, 
                "volume": "103", 
                "pages": "12917", 
                "doi": "10.1073/pnas.0601396103"
            }, 
            {
                "type": "journal", 
                "id": "bib34", 
                "date": "1979", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "EI Knudsen", 
                            "index": "Knudsen, EI"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "GG Blasdel", 
                            "index": "Blasdel, GG"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Konishi", 
                            "index": "Konishi, M"
                        }
                    }
                ], 
                "articleTitle": "Sound localization by the barn owl (Tyto alba) measured with the search coil technique", 
                "journal": {
                    "name": [
                        "J Comp Physiol"
                    ]
                }, 
                "volume": "133", 
                "pages": {
                    "first": "1", 
                    "last": "11", 
                    "range": "1\u201311"
                }, 
                "doi": "10.1007/BF00663105"
            }, 
            {
                "type": "journal", 
                "id": "bib35", 
                "date": "2003", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Konishi", 
                            "index": "Konishi, M"
                        }
                    }
                ], 
                "articleTitle": "Coding of auditory space", 
                "journal": {
                    "name": [
                        "Annu Rev Neurosci"
                    ]
                }, 
                "volume": "26", 
                "pages": {
                    "first": "31", 
                    "last": "55", 
                    "range": "31\u201355"
                }, 
                "doi": "10.1146/annurev.neuro.26.041002.131123"
            }, 
            {
                "type": "journal", 
                "id": "bib36", 
                "date": "1997", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "C K\u00f6ppl", 
                            "index": "K\u00f6ppl, C"
                        }
                    }
                ], 
                "articleTitle": "Frequency tuning and spontaneous activity in the auditory nerve and cochlear nucleus magnocellularis of the barn owl Tyto alba", 
                "journal": {
                    "name": [
                        "J Neurophysiol"
                    ]
                }, 
                "volume": "77", 
                "pages": {
                    "first": "364", 
                    "last": "377", 
                    "range": "364\u2013377"
                }
            }, 
            {
                "type": "journal", 
                "id": "bib37", 
                "date": "2011", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "T Kuenzel", 
                            "index": "Kuenzel, T"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JGG Borst", 
                            "index": "Borst, JGG"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M van der Heijden", 
                            "index": "van der Heijden, M"
                        }
                    }
                ], 
                "articleTitle": "Factors controlling the input-output relationship of spherical bushy cells in the gerbil cochlear nucleus", 
                "journal": {
                    "name": [
                        "J Neurosci"
                    ]
                }, 
                "volume": "31", 
                "pages": {
                    "first": "4260", 
                    "last": "4273", 
                    "range": "4260\u20134273"
                }, 
                "doi": "10.1523/JNEUROSCI.5433-10.2011"
            }, 
            {
                "type": "journal", 
                "id": "bib38", 
                "date": "1977", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "GF Kuhn", 
                            "index": "Kuhn, GF"
                        }
                    }
                ], 
                "articleTitle": "Model for the interaural time differences in the azimuthal plane", 
                "journal": {
                    "name": [
                        "J Acoust Soc Am"
                    ]
                }, 
                "volume": "62", 
                "pages": {
                    "first": "157", 
                    "last": "167", 
                    "range": "157\u2013167"
                }, 
                "doi": "10.1121/1.381498"
            }, 
            {
                "type": "journal", 
                "id": "bib39", 
                "date": "1983", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Kuwada", 
                            "index": "Kuwada, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "TC Yin", 
                            "index": "Yin, TC"
                        }
                    }
                ], 
                "articleTitle": "Binaural interaction in low-frequency neurons in inferior colliculus of the cat. I. Effects of long interaural delays, intensity, and repetition rate on interaural delay function", 
                "journal": {
                    "name": [
                        "J Neurophysiol"
                    ]
                }, 
                "volume": "50", 
                "pages": {
                    "first": "981", 
                    "last": "999", 
                    "range": "981\u2013999"
                }
            }, 
            {
                "type": "journal", 
                "id": "bib40", 
                "date": "2013", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "CC Lee", 
                            "index": "Lee, CC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JC Middlebrooks", 
                            "index": "Middlebrooks, JC"
                        }
                    }
                ], 
                "articleTitle": "Specialization for sound localization in fields A1, DZ, and PAF of cat auditory cortex", 
                "journal": {
                    "name": [
                        "J Assoc Res Otolaryngol"
                    ]
                }, 
                "volume": "14", 
                "pages": {
                    "first": "61", 
                    "last": "82", 
                    "range": "61\u201382"
                }, 
                "doi": "10.1007/s10162-012-0357-9"
            }, 
            {
                "type": "journal", 
                "id": "bib41", 
                "date": "2010", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "NA Lesica", 
                            "index": "Lesica, NA"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Lingner", 
                            "index": "Lingner, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "B Grothe", 
                            "index": "Grothe, B"
                        }
                    }
                ], 
                "articleTitle": "Population coding of interaural time differences in gerbils and barn owls", 
                "journal": {
                    "name": [
                        "J Neurosci"
                    ]
                }, 
                "volume": "30", 
                "pages": {
                    "first": "11696", 
                    "last": "11702", 
                    "range": "11696\u201311702"
                }, 
                "doi": "10.1523/JNEUROSCI.0846-10.2010"
            }, 
            {
                "type": "journal", 
                "id": "bib42", 
                "date": "2002", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RY Litovsky", 
                            "index": "Litovsky, RY"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "BJ Fligor", 
                            "index": "Fligor, BJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "MJ Tramo", 
                            "index": "Tramo, MJ"
                        }
                    }
                ], 
                "articleTitle": "Functional role of the human inferior colliculus in binaural hearing", 
                "journal": {
                    "name": [
                        "Hear Res"
                    ]
                }, 
                "volume": "165", 
                "pages": {
                    "first": "177", 
                    "last": "188", 
                    "range": "177\u2013188"
                }, 
                "doi": "10.1016/S0378-5955(02)00304-0"
            }, 
            {
                "type": "journal", 
                "id": "bib43", 
                "date": "2011", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "H L\u00fcling", 
                            "index": "L\u00fcling, H"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "I Siveke", 
                            "index": "Siveke, I"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "B Grothe", 
                            "index": "Grothe, B"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "C Leibold", 
                            "index": "Leibold, C"
                        }
                    }
                ], 
                "articleTitle": "Frequency-invariant representation of interaural time differences in mammals", 
                "journal": {
                    "name": [
                        "PLOS Comput Biol"
                    ]
                }, 
                "volume": "7", 
                "pages": "e1002013", 
                "doi": "10.1371/journal.pcbi.1002013"
            }, 
            {
                "type": "journal", 
                "id": "bib44", 
                "date": "2005", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "K Maki", 
                            "index": "Maki, K"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Furukawa", 
                            "index": "Furukawa, S"
                        }
                    }
                ], 
                "articleTitle": "Acoustical cues for sound localization by the Mongolian gerbil, <i>Meriones unguiculatus</i>", 
                "journal": {
                    "name": [
                        "J Acoust Soc Am"
                    ]
                }, 
                "volume": "118", 
                "pages": {
                    "first": "872", 
                    "last": "886", 
                    "range": "872\u2013886"
                }, 
                "doi": "10.1121/1.1944647"
            }, 
            {
                "type": "journal", 
                "id": "bib45", 
                "date": "1990", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JC Makous", 
                            "index": "Makous, JC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JC Middlebrooks", 
                            "index": "Middlebrooks, JC"
                        }
                    }
                ], 
                "articleTitle": "Two-dimensional sound localization by human listeners", 
                "journal": {
                    "name": [
                        "J Acoust Soc Am"
                    ]
                }, 
                "volume": "87", 
                "pages": {
                    "first": "2188", 
                    "last": "2200", 
                    "range": "2188\u20132200"
                }, 
                "doi": "10.1121/1.399186"
            }, 
            {
                "type": "journal", 
                "id": "bib46", 
                "date": "2004", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "S Malhotra", 
                            "index": "Malhotra, S"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AJ Hall", 
                            "index": "Hall, AJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "SG Lomber", 
                            "index": "Lomber, SG"
                        }
                    }
                ], 
                "articleTitle": "Cortical control of sound localization in the cat: unilateral cooling deactivation of 19 cerebral areas", 
                "journal": {
                    "name": [
                        "J Neurophysiol"
                    ]
                }, 
                "volume": "92", 
                "pages": {
                    "first": "1625", 
                    "last": "1643", 
                    "range": "1625\u20131643"
                }, 
                "doi": "10.1152/jn.01205.2003"
            }, 
            {
                "type": "journal", 
                "id": "bib47", 
                "date": "2001", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "D McAlpine", 
                            "index": "McAlpine, D"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "D Jiang", 
                            "index": "Jiang, D"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AR Palmer", 
                            "index": "Palmer, AR"
                        }
                    }
                ], 
                "articleTitle": "A neural code for low-frequency sound localization in mammals", 
                "journal": {
                    "name": [
                        "Nat Neurosci"
                    ]
                }, 
                "volume": "4", 
                "pages": {
                    "first": "396", 
                    "last": "401", 
                    "range": "396\u2013401"
                }, 
                "doi": "10.1038/86049"
            }, 
            {
                "type": "journal", 
                "id": "bib48", 
                "date": "2009", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "LM Miller", 
                            "index": "Miller, LM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "GH Recanzone", 
                            "index": "Recanzone, GH"
                        }
                    }
                ], 
                "articleTitle": "Populations of auditory cortical neurons can accurately encode acoustic space across stimulus intensity", 
                "journal": {
                    "name": [
                        "Proc Natl Acad Sci USA"
                    ]
                }, 
                "volume": "106", 
                "pages": {
                    "first": "5931", 
                    "last": "5935", 
                    "range": "5931\u20135935"
                }, 
                "doi": "10.1073/pnas.0901023106"
            }, 
            {
                "type": "journal", 
                "id": "bib49", 
                "date": "1989", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Moiseff", 
                            "index": "Moiseff, A"
                        }
                    }
                ], 
                "articleTitle": "Binaural disparity cues available to the barn owl for sound localization", 
                "journal": {
                    "name": [
                        "J Comp Physiol"
                    ]
                }, 
                "volume": "164", 
                "pages": {
                    "first": "629", 
                    "last": "636", 
                    "range": "629\u2013636"
                }, 
                "doi": "10.1007/BF00614505"
            }, 
            {
                "type": "journal", 
                "id": "bib50", 
                "date": "2008", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JM Moore", 
                            "index": "Moore, JM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DJ Tollin", 
                            "index": "Tollin, DJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "TCT Yin", 
                            "index": "Yin, TCT"
                        }
                    }
                ], 
                "articleTitle": "Can measures of sound localization acuity be related to the precision of absolute location estimates?", 
                "journal": {
                    "name": [
                        "Hear Res"
                    ]
                }, 
                "volume": "238", 
                "pages": {
                    "first": "94", 
                    "last": "109", 
                    "range": "94\u2013109"
                }, 
                "doi": "10.1016/j.heares.2007.11.006"
            }, 
            {
                "type": "journal", 
                "id": "bib51", 
                "date": "2011", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "F Pedregosa", 
                            "index": "Pedregosa, F"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "G Varoquaux", 
                            "index": "Varoquaux, G"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Gramfort", 
                            "index": "Gramfort, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "V Michel", 
                            "index": "Michel, V"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "B Thirion", 
                            "index": "Thirion, B"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "O Grisel", 
                            "index": "Grisel, O"
                        }
                    }
                ], 
                "authorsEtAl": true, 
                "articleTitle": "Scikit-learn: machine learning in python", 
                "journal": {
                    "name": [
                        "J Mach Learn Res"
                    ]
                }, 
                "volume": "12", 
                "pages": {
                    "first": "2825", 
                    "last": "2830", 
                    "range": "2825\u20132830"
                }
            }, 
            {
                "type": "journal", 
                "id": "bib52", 
                "date": "2004", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "LC Populin", 
                            "index": "Populin, LC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DJ Tollin", 
                            "index": "Tollin, DJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "TCT Yin", 
                            "index": "Yin, TCT"
                        }
                    }
                ], 
                "articleTitle": "Effect of eye position on saccades and neuronal responses to acoustic stimuli in the superior colliculus of the behaving cat", 
                "journal": {
                    "name": [
                        "J Neurophysiol"
                    ]
                }, 
                "volume": "92", 
                "pages": {
                    "first": "2151", 
                    "last": "2167", 
                    "range": "2151\u20132167"
                }, 
                "doi": "10.1152/jn.00453.2004"
            }, 
            {
                "type": "journal", 
                "id": "bib53", 
                "date": "2002", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "CA Shera", 
                            "index": "Shera, CA"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JJ Guinan", 
                            "index": "Guinan, JJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "AJ Oxenham", 
                            "index": "Oxenham, AJ"
                        }
                    }
                ], 
                "articleTitle": "Revised estimates of human cochlear tuning from otoacoustic and behavioral measurements", 
                "journal": {
                    "name": [
                        "Proc Natl Acad Sci USA"
                    ]
                }, 
                "volume": "99", 
                "pages": {
                    "first": "3318", 
                    "last": "3323", 
                    "range": "3318\u20133323"
                }, 
                "doi": "10.1073/pnas.032675099"
            }, 
            {
                "type": "book", 
                "id": "bib54", 
                "date": "1993", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Slaney", 
                            "index": "Slaney, M"
                        }
                    }
                ], 
                "bookTitle": "Auditory toolbox, apple technical report #45", 
                "uri": "https://engineering.purdue.edu/~malcolm/interval/1998-010/", 
                "publisher": {
                    "name": [
                        "Apple Computer, Inc"
                    ]
                }
            }, 
            {
                "type": "journal", 
                "id": "bib55", 
                "date": "1987", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DL Sparks", 
                            "index": "Sparks, DL"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "IS Nelson", 
                            "index": "Nelson, IS"
                        }
                    }
                ], 
                "articleTitle": "Sensory and motor maps in the mammalian superior colliculus", 
                "journal": {
                    "name": [
                        "Trend Neurosci"
                    ]
                }, 
                "volume": "10", 
                "pages": {
                    "first": "312", 
                    "last": "317", 
                    "range": "312\u2013317"
                }, 
                "doi": "10.1016/0166-2236(87)90085-3"
            }, 
            {
                "type": "journal", 
                "id": "bib56", 
                "date": "2005", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "GC Stecker", 
                            "index": "Stecker, GC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "IA Harrington", 
                            "index": "Harrington, IA"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JC Middlebrooks", 
                            "index": "Middlebrooks, JC"
                        }
                    }
                ], 
                "articleTitle": "Location coding by opponent neural populations in the auditory cortex", 
                "journal": {
                    "name": [
                        "PLOS Biol"
                    ]
                }, 
                "volume": "3", 
                "pages": "e78", 
                "doi": "10.1371/journal.pbio.0030078"
            }, 
            {
                "type": "journal", 
                "id": "bib57", 
                "date": "2003", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "SJ Sterbing", 
                            "index": "Sterbing, SJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "K Hartung", 
                            "index": "Hartung, K"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "K-P Hoffmann", 
                            "index": "Hoffmann, K-P"
                        }
                    }
                ], 
                "articleTitle": "Spatial tuning to virtual sounds in the inferior colliculus of the guinea pig", 
                "journal": {
                    "name": [
                        "J Neurophysiol"
                    ]
                }, 
                "volume": "90", 
                "pages": {
                    "first": "2648", 
                    "last": "2659", 
                    "range": "2648\u20132659"
                }, 
                "doi": "10.1152/jn.00348.2003"
            }, 
            {
                "type": "book-chapter", 
                "id": "bib58", 
                "date": "1995", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "RM Stern", 
                            "index": "Stern, RM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "C Trahiotis", 
                            "index": "Trahiotis, C"
                        }
                    }
                ], 
                "editors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "Brian CJ Moore", 
                            "index": "Moore, Brian CJ"
                        }
                    }
                ], 
                "bookTitle": "Handbook of perception and cognition", 
                "chapterTitle": "Models of binaural interaction", 
                "pages": {
                    "first": "347", 
                    "last": "387", 
                    "range": "347\u2013387"
                }, 
                "publisher": {
                    "name": [
                        "Academic Press"
                    ], 
                    "address": {
                        "formatted": [
                            "New York"
                        ], 
                        "components": {
                            "locality": [
                                "New York"
                            ]
                        }
                    }
                }
            }, 
            {
                "type": "journal", 
                "id": "bib59", 
                "date": "1984", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "T Takahashi", 
                            "index": "Takahashi, T"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Moiseff", 
                            "index": "Moiseff, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M Konishi", 
                            "index": "Konishi, M"
                        }
                    }
                ], 
                "articleTitle": "Time and intensity cues are processed independently in the auditory system of the owl", 
                "journal": {
                    "name": [
                        "J Neurosci"
                    ]
                }, 
                "volume": "4", 
                "pages": {
                    "first": "1781", 
                    "last": "1786", 
                    "range": "1781\u20131786"
                }
            }, 
            {
                "type": "journal", 
                "id": "bib60", 
                "date": "2006", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "SK Thompson", 
                            "index": "Thompson, SK"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "K von Kriegstein", 
                            "index": "von Kriegstein, K"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Deane-Pratt", 
                            "index": "Deane-Pratt, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "T Marquardt", 
                            "index": "Marquardt, T"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "R Deichmann", 
                            "index": "Deichmann, R"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "TD Griffiths", 
                            "index": "Griffiths, TD"
                        }
                    }
                ], 
                "authorsEtAl": true, 
                "articleTitle": "Representation of interaural time delay in the human auditory midbrain", 
                "journal": {
                    "name": [
                        "Nat Neurosci"
                    ]
                }, 
                "volume": "9", 
                "pages": {
                    "first": "1096", 
                    "last": "1098", 
                    "range": "1096\u20131098"
                }, 
                "doi": "10.1038/nn1755"
            }, 
            {
                "type": "journal", 
                "id": "bib61", 
                "date": "2009", 
                "discriminator": "a", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DJ Tollin", 
                            "index": "Tollin, DJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "K Koka", 
                            "index": "Koka, K"
                        }
                    }
                ], 
                "articleTitle": "Postnatal development of sound pressure transformations by the head and pinnae of the cat: binaural characteristics", 
                "journal": {
                    "name": [
                        "J Acoust Soc Am"
                    ]
                }, 
                "volume": "126", 
                "pages": {
                    "first": "3125", 
                    "last": "3136", 
                    "range": "3125\u20133136"
                }, 
                "doi": "10.1121/1.3257234"
            }, 
            {
                "type": "journal", 
                "id": "bib62", 
                "date": "2009", 
                "discriminator": "b", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DJ Tollin", 
                            "index": "Tollin, DJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "K Koka", 
                            "index": "Koka, K"
                        }
                    }
                ], 
                "articleTitle": "Postnatal development of sound pressure transformations by the head and pinnae of the cat: monaural characteristics", 
                "journal": {
                    "name": [
                        "J Acoust Soc Am"
                    ]
                }, 
                "volume": "125", 
                "pages": {
                    "first": "980", 
                    "last": "994", 
                    "range": "980\u2013994"
                }, 
                "doi": "10.1121/1.3058630"
            }, 
            {
                "type": "journal", 
                "id": "bib63", 
                "date": "2005", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DJ Tollin", 
                            "index": "Tollin, DJ"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "LC Populin", 
                            "index": "Populin, LC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JM Moore", 
                            "index": "Moore, JM"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JL Ruhland", 
                            "index": "Ruhland, JL"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "TCT Yin", 
                            "index": "Yin, TCT"
                        }
                    }
                ], 
                "articleTitle": "Sound-localization performance in the cat: the effect of restraining the head", 
                "journal": {
                    "name": [
                        "J Neurophysiol"
                    ]
                }, 
                "volume": "93", 
                "pages": {
                    "first": "1223", 
                    "last": "1234", 
                    "range": "1223\u20131234"
                }, 
                "doi": "10.1152/jn.00747.2004"
            }, 
            {
                "type": "journal", 
                "id": "bib64", 
                "date": "2007", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "H Wagner", 
                            "index": "Wagner, H"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "A Asadollahi", 
                            "index": "Asadollahi, A"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "P Bremen", 
                            "index": "Bremen, P"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "F Endler", 
                            "index": "Endler, F"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "K Vonderschen", 
                            "index": "Vonderschen, K"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "M von Campenhausen", 
                            "index": "von Campenhausen, M"
                        }
                    }
                ], 
                "articleTitle": "Distribution of interaural time difference in the barn owl\u2019s inferior colliculus in the low- and high-frequency ranges", 
                "journal": {
                    "name": [
                        "J Neurosci"
                    ]
                }, 
                "volume": "27", 
                "pages": {
                    "first": "4191", 
                    "last": "4200", 
                    "range": "4191\u20134200"
                }, 
                "doi": "10.1523/JNEUROSCI.5250-06.2007"
            }, 
            {
                "type": "journal", 
                "id": "bib65", 
                "date": "1974", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "OS Wakeford", 
                            "index": "Wakeford, OS"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DE Robinson", 
                            "index": "Robinson, DE"
                        }
                    }
                ], 
                "articleTitle": "Lateralization of tonal stimuli by the cat", 
                "journal": {
                    "name": [
                        "J Acoust Soc Am"
                    ]
                }, 
                "volume": "55", 
                "pages": {
                    "first": "649", 
                    "last": "652", 
                    "range": "649\u2013652"
                }, 
                "doi": "10.1121/1.1914577"
            }, 
            {
                "type": "journal", 
                "id": "bib66", 
                "date": "1992", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "FL Wightman", 
                            "index": "Wightman, FL"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "DJ Kistler", 
                            "index": "Kistler, DJ"
                        }
                    }
                ], 
                "articleTitle": "The dominant role of low-frequency interaural time differences in sound localization", 
                "journal": {
                    "name": [
                        "J Acoust Soc Am"
                    ]
                }, 
                "volume": "91", 
                "pages": {
                    "first": "1648", 
                    "last": "1661", 
                    "range": "1648\u20131661"
                }, 
                "doi": "10.1121/1.402445"
            }, 
            {
                "type": "journal", 
                "id": "bib67", 
                "date": "1990", 
                "discriminator": "a", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "TC Yin", 
                            "index": "Yin, TC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JC Chan", 
                            "index": "Chan, JC"
                        }
                    }
                ], 
                "articleTitle": "Interaural time sensitivity in medial superior olive of cat", 
                "journal": {
                    "name": [
                        "J Neurophysiol"
                    ]
                }, 
                "volume": "64", 
                "pages": {
                    "first": "465", 
                    "last": "488", 
                    "range": "465\u2013488"
                }
            }, 
            {
                "type": "journal", 
                "id": "bib68", 
                "date": "1990", 
                "discriminator": "b", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "TC Yin", 
                            "index": "Yin, TC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JC Chan", 
                            "index": "Chan, JC"
                        }
                    }
                ], 
                "articleTitle": "Interaural time sensitivity in medial superior olive of cat", 
                "journal": {
                    "name": [
                        "J Neurophysiol"
                    ]
                }, 
                "volume": "64", 
                "pages": {
                    "first": "465", 
                    "last": "488", 
                    "range": "465\u2013488"
                }
            }, 
            {
                "type": "journal", 
                "id": "bib69", 
                "date": "1987", 
                "authors": [
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "TC Yin", 
                            "index": "Yin, TC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "JC Chan", 
                            "index": "Chan, JC"
                        }
                    }, 
                    {
                        "type": "person", 
                        "name": {
                            "preferred": "LH Carney", 
                            "index": "Carney, LH"
                        }
                    }
                ], 
                "articleTitle": "Effects of interaural time delays of noise stimuli on low-frequency cells in the cat\u2019s inferior colliculus. III. Evidence for cross-correlation", 
                "journal": {
                    "name": [
                        "J Neurophysiol"
                    ]
                }, 
                "volume": "58", 
                "pages": {
                    "first": "562", 
                    "last": "583", 
                    "range": "562\u2013583"
                }
            }
        ], 
        "acknowledgements": [
            {
                "type": "paragraph", 
                "text": "We thank the Museum of Natural History for providing stuffed animals, Hermann Wagner for sharing measured HRTFs and electrophysiological measurements of BD and BF in barn owls, Daniel Tollin for sharing measured HRTFs of a cat, and Philip Joris for sharing electrophysiological measurements of BD and BF in cat\u2019s IC. We also thank Mitchell Day, Marcel Stimberg, Agn\u00e8s L\u00e9ger, and Christian Lorenzi for additional comments."
            }
        ], 
        "decisionLetter": {
            "doi": "10.7554/eLife.01312.013", 
            "description": [
                {
                    "type": "paragraph", 
                    "text": "eLife posts the editorial decision letter and author response on a selection of the published articles (subject to the approval of the authors). An edited version of the letter sent to the authors after peer review is shown, indicating the substantive concerns or comments; minor concerns are not usually shown. Reviewers have the opportunity to discuss the decision before the letter is sent (see <a href=\"http://elife.elifesciences.org/review-process\">review process</a>). Similarly, the author response typically shows only responses to the major concerns raised by the reviewers."
                }
            ], 
            "content": [
                {
                    "type": "paragraph", 
                    "text": "Thank you for sending your work entitled \u201cDecoding neural responses to sound location\u201d for consideration at <i>eLife</i>. Your article has been favorably evaluated by a Senior editor and 3 reviewers, one of whom is a member of our Board of Reviewing Editors."
                }, 
                {
                    "type": "paragraph", 
                    "text": "The Reviewing editor and the other reviewers discussed their comments before we reached this decision, and the Reviewing editor has assembled the following comments to help you prepare a revised submission."
                }, 
                {
                    "type": "paragraph", 
                    "text": "This is a modeling study comparing different ways of extracting information about sound location from the responses of a model population of binaural neurons. The conclusion of the manuscript is that, while a labeled line code is too inefficient, summing the activity in each hemisphere discards too much of the information that is present in neural activity patterns."
                }, 
                {
                    "type": "paragraph", 
                    "text": "This is an interesting and important topic that could be of general interest. However, one of the reviewers felt that it would be nice to expand on the population decoding, and discuss the fact that they have not considered population models that do not simply sum activities (e.g.,, those with optimal weighting of the contribution of each cell) and network nonlinearities useful for marginalization of task-irrelevant information like divisive normalization. Other properties known to be critical for information loss and decoding optimality, like shared variability and interneuronal correlations, have also not been considered. The reviewers would like to see a broader coverage/discussion, such that this work can appeal to the broader neuroscience community."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Specific comments:"
                }, 
                {
                    "type": "paragraph", 
                    "text": "One of the reviewers particularly liked that the authors model the effects of a unilateral lesion. Such a lesion of their pattern-match model predicts strictly contralesional localization deficits, which is what is seen in all the animal lesion studies. In contrast, a unilateral lesion of their hemispheric model predicts bilateral deficits, which are never seen in animal studies. The reviewers would like to see that result given a little more prominence, such as mention in the Abstract."
                }, 
                {
                    "type": "paragraph", 
                    "text": "The title should be revised to more specifically indicate that the study examines \u201csound location based on interaural time differences\u201d."
                }, 
                {
                    "type": "paragraph", 
                    "text": "The results in <a href=\"#fig7\">Figure 7</a> for the simulated lesions should be compared, at least qualitatively, to results for the human listeners with lesions. The two models shown in <a href=\"#fig7\">Figure 7B</a> have very different results, so the comparison may be interesting."
                }, 
                {
                    "type": "paragraph", 
                    "text": "In the section on \u201cComparison to Behavioral Performance\u201d, the argument is made that the hemispheric difference model predicts errors that are larger than those observed in behavioral studies. In the preamble to this section, it is stated that the pattern match model has very small errors, but the numerical errors for the pattern-match model are not provided for comparison to specific species and cases, as they are for the hemispheric difference model. Despite the fact that the pattern-match model's errors will appear to be quite small, they are useful and should be provided for the reader. Although the absolute errors will be smaller than behavioral thresholds, the trends in the errors across conditions are interesting to present. One can argue that the actual system will have errors larger than this very detailed model, but the (fractional) difference between model and actual performance should be comparable across conditions. (That is, it would be bothersome if the model were 1 order of magnitude too accurate in some cases, and 3 orders of magnitude too accurate in others, such that the degradation in performance required to match behavior had to change dramatically across conditions.)"
                }, 
                {
                    "type": "paragraph", 
                    "text": "The model results presented here illustrate an interesting difference in the trend of the errors between the hemispheric model and both the smoothed peak and pattern-match models at high frequencies (e.g., <a href=\"#fig2 fig3 fig4\">Figures 2, 3, 4</a>). The comparison of this prediction to behavioral results deserves inclusion in the section that compares model to behavioral performance. Again, this is a consistent trend in the results that can be compared qualitatively to trends in behavioral results."
                }, 
                {
                    "type": "paragraph", 
                    "text": "In the Discussion, the argument is made that additional processing would be required to generate spatially tuned neurons from the hemispheric model. This is an interesting point, but it is not clear what spatially tuned neurons the authors are thinking about. It would help to be more specific as to what neurons (presumably at a level higher than the IC) are being considered here (indeed, there are precious few spatially tuned neurons at higher levels, and the hemispheric model doesn't require such neurons, does it?). For example, it might be helpful to consider decoding schemes proposed for the cortex. <a href=\"#bib56\">Stecker, Harrington, and Middlebrooks, 2005</a> (cited) tested a hemispheric model as a sort of worst-case scenario, although several authors have seized on the hemispheric model as reality. Others have looked at decoding based on spatial tuning of individual neurons, compiled as ensembles (anesthetized cat: <a href=\"#bib19\">Furukawa, Xu, and Middlebrooks, 2000</a>; behaving cat: <a href=\"#bib40\">Lee and Middlebrooks, 2013</a>; awake monkey: <a href=\"#bib48\">Miller and Recanzone, 2009</a>). These experimental studies should be discussed because they do empirically what the authors are doing with their simulations."
                }, 
                {
                    "type": "paragraph", 
                    "text": "It would also be useful for the authors to include comment on the recent paper by Briley et al., JARO 2013, Vol 14: 83-101, which supports the hemispheric model, based on EEG recordings in human."
                }
            ]
        }, 
        "authorResponse": {
            "doi": "10.7554/eLife.01312.014", 
            "content": [
                {
                    "type": "paragraph", 
                    "text": "<i>This is an interesting and important topic that could be of general interest. However, one of the reviewers felt that it would be nice to expand on the population decoding, and discuss the fact that they have not considered population models that do not simply sum activities (e.g., those with optimal weighting of the contribution of each cell) and network nonlinearities useful for marginalization of task-irrelevant information like divisive normalization. Other properties known to be critical for information loss and decoding optimality, like shared variability and interneuronal correlations, have also not been considered. The reviewers would like to see a broader coverage/discussion, such that this work can appeal to the broader neuroscience community</i>."
                }, 
                {
                    "type": "paragraph", 
                    "text": "The target of this research was the ongoing debate between two major competing models of sound localization, and so in the paper we focused on these models. However, we also tested a large number of other decoders, including a large number of standard decoders from machine learning. We added a figure supplement to <a href=\"#fig3\">Figure 3</a> showing the results of two of these decoders, ridge regression and nearest neighbor regression. Ridge regression is similar to linear regression but has an additional penalty to large coefficients. Because of the signal correlations between cells with overlapping frequency bands, the linear regression decoder was highly subject to noise, and ridge regression resolves this issue and finds the optimal weights for each cell. As can be seen in that figure, the linear/ridge regression performed similarly to the hemispheric decoder: performing slightly better in some aspects and worse in others. We also show the nearest neighbor regression decoder performs quite similarly to the pattern match decoder, which is not surprising as it is based on a similar idea (comparison of test result to stored patterns). To keep the paper to a manageable length, we only presented results of the three decoders, which we feel makes sense as two are the major current models of ITD decoding, and the third (pattern match) performed the best of all the decoders we tried. The pattern match estimator also has the virtue that it is straightforward to implement in a neural circuit, unlike many of the methods from machine learning. We also added new paragraphs to the Results and Methods sections mentioning that we tried other decoders."
                }, 
                {
                    "type": "paragraph", 
                    "text": "Some normalization is already present in the responses of binaural neurons (see Methods, Response Model), where level is normalized, and therefore is included in all decoders. It indeed removes some task-independent sources of variability, namely overall level and ILDs. However, the differences between decoders are not due to this normalization, since it is included in all of them. The pattern match decoder also includes divisive normalization in the calculation of similarity between responses and templates, however it has no influence on the decoder\u2019s output because it uses a winner-take-all operation and the normalization factor is identical for all candidate templates. The hemispheric decoder also uses a normalized difference, so it is not the decisive factor in the performance differences."
                }, 
                {
                    "type": "paragraph", 
                    "text": "We added a section about shared variability and correlations in the Discussion. The bottom line is that, because the MSO (first binaural nucleus) is an essentially anatomically feedforward and tonotopic circuit, the main source of correlations should be stimulus variability. The topic of correlations is indeed very relevant to this study, because the previous conclusion that the hemispheric code (or \u201cslope coding\u201d) is supposedly optimal relied on the implicit assumption that neural responses are independent, conditionally to the ITD (<a href=\"#bib26\">Harper and McAlpine, 2004</a>). But the variability of the stimulus, which is shared, implies that a better decoder must use the structure of correlations. For example, in a Jeffress-like model, changes in the sound (e.g., level, background noise) results in changes in the activity of all neurons, but the identity of the most active neuron does not change (a theoretical argument made in <a href=\"#bib4\">Brette, 2010</a>)."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>One of the reviewers particularly liked that the authors model the effects of a unilateral lesion. Such a lesion of their pattern-match model predicts strictly contralesional localization deficits, which is what is seen in all the animal lesion studies. In contrast, a unilateral lesion of their hemispheric model predicts bilateral deficits, which are never seen in animal studies. The reviewers would like to see that result given a little more prominence, such as mention in the Abstract</i>."
                }, 
                {
                    "type": "paragraph", 
                    "text": "We added this to the abstract."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>The title should be revised to more specifically indicate that the study examines \u201csound location based on interaural time differences\u201d</i>."
                }, 
                {
                    "type": "paragraph", 
                    "text": "We used the reviewers\u2019 suggestion of \u201cDecoding neural responses to temporal cues for sound localization\u201d."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>The results in</i> <a href=\"#fig7\"><i>Figure 7</i></a> <i>for the simulated lesions should be compared, at least qualitatively, to results for the human listeners with lesions. The two models shown in</i> <a href=\"#fig7\"><i>Figure 7B</i></a> <i>have very different results, so the comparison may be interesting</i>."
                }, 
                {
                    "type": "paragraph", 
                    "text": "We added the following sentence: \u201cLesion data indicate that sound localization performance is greatly degraded in the contralateral hemifield, but not completely abolished, which would discard the smoothed peak decoder \u2013 although lesions might not have been complete, and those were free-field experiments involving other cues than ITD.\u201d"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>In the section on \u201cComparison to Behavioral Performance\u201d, the argument is made that the hemispheric difference model predicts errors that are larger than those observed in behavioral studies. In the preamble to this section, it is stated that the pattern match model has very small errors, but the numerical errors for the pattern-match model are not provided for comparison to specific species and cases, as they are for the hemispheric difference model. Despite the fact that the pattern-match model's errors will appear to be quite small, they are useful and should be provided for the reader. Although the absolute errors will be smaller than behavioral thresholds, the trends in the errors across conditions are interesting to present. One can argue that the actual system will have errors larger than this very detailed model, but the (fractional) difference between model and actual performance should be comparable across conditions. (That is, it would be bothersome if the model were 1 order of magnitude too accurate in some cases, and 3 orders of magnitude too accurate in others, such that the degradation in performance required to match behavior had to change dramatically across conditions.</i>)"
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>The model results presented here illustrate an interesting difference in the trend of the errors between the hemispheric model and both the smoothed peak and pattern-match models at high frequencies (e.g.,</i> <a href=\"#fig2 fig3 fig4\"><i>Figures 2, 3, 4</i></a><i>). The comparison of this prediction to behavioral results deserves inclusion in the section that compares model to behavioral performance. Again, this is a consistent trend in the results that can be compared qualitatively to trends in behavioral results</i>."
                }, 
                {
                    "type": "paragraph", 
                    "text": "We understand the reasoning and we had considered including a discussion of these trends. However, we had decided not to include them for two reasons, even though they are generally in line with our conclusions."
                }, 
                {
                    "type": "paragraph", 
                    "text": "First, it relies on an assumption that the degradation of error between the \u201coptimal\u201d model and behavior is a frequency-independent factor. But this assumption may not be true. In that section, we argued that there are additional sources of errors, in particular the fact that the estimation of sound location relies not only on accurate acoustical cues but also on accurate feedback, such as visual feedback. If the limiting factor is the accuracy of this feedback (which is supported by the Heffner & Heffner study), then it should not be frequency-dependent, even if the coding accuracy of acoustical cues is frequency-dependent. Therefore, we think the extrapolation is a bit speculative. What is more informative, however, is when behavior is more accurate than a model (such as the hemispheric model), which does not have this additional source of error. In this case it is fair to conclude to the model is insufficiently accurate."
                }, 
                {
                    "type": "paragraph", 
                    "text": "The second reason is that many studies use free-field experiments, and acoustical cues depend on frequency, in amount and in reliability (both ITDs and ILDs). It would bring a potentially confounding factor to the comparisons."
                }, 
                {
                    "type": "paragraph", 
                    "text": "However, we added a paragraph in which we compared our results with a behavioral experiment using controlled binaural tones presented through earphones (no ILD), but we feel that this aspect should not be over-emphasized in this comparison. We also added a mention of the error of the pattern decoder in the first paragraph."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>In the Discussion, the argument is made that additional processing would be required to generate spatially tuned neurons from the hemispheric model. This is an interesting point, but it is not clear what spatially tuned neurons the authors are thinking about. It would help to be more specific as to what neurons (presumably at a level higher than the IC) are being considered here (indeed, there are precious few spatially tuned neurons at higher levels, and the hemispheric model doesn't require such neurons, does it?). For example, it might be helpful to consider decoding schemes proposed for the cortex.</i> <a href=\"#bib56\"><i>Stecker, Harrington, and Middlebrooks, 2005</i></a> <i>(cited) tested a hemispheric model as a sort of worst-case scenario, although several authors have seized on the hemispheric model as reality. Others have looked at decoding based on spatial tuning of individual neurons, compiled as ensembles (anesthetized cat:</i> <a href=\"#bib19\"><i>Furukawa, Xu, and Middlebrooks, 2000</i></a><i>; behaving cat:</i> <a href=\"#bib40\"><i>Lee and Middlebrooks, 2013</i></a><i>; awake monkey:</i> <a href=\"#bib48\"><i>Miller and Recanzone, 2009</i></a><i>). These experimental studies should be discussed because they do empirically what the authors are doing with their simulations</i>."
                }, 
                {
                    "type": "paragraph", 
                    "text": "We wrote in the previous paragraph: \u201cIn the cat, most low frequency neurons in the central nucleus of the inferior colliculus are spatially tuned, with preferred azimuth homogeneously distributed in the contralateral hemifield (<a href=\"#bib1\">Aitkin et al., 1985</a>).\u201d Perhaps more importantly, sound localization behavior does require that the graded code assumed in the hemispheric model be converted to spatially tuned responses, at least for eye movements, which have been used to measure sound localization accuracy in cats. We now discuss this point in the Discussion (Physiological mechanisms). In the superior colliculus (to which IC projects), there are spatially tuned auditory neurons, whose stimulation produces movements of fixed amplitude and direction, independently of stimulation strength, and they are arranged topographically."
                }, 
                {
                    "type": "paragraph", 
                    "text": "We did not address the question of how cortical responses might be decoded, because the controversy we address arose from measurements of responses in MSO and IC, and because these are earlier in the auditory pathway. However, we agree that there are a number of papers about estimating sound location from cortical responses, which would be relevant to discuss. We added a paragraph about them in the Discussion (Pattern decoders). Some of the decoders used in these studies are, indeed, similar to the pattern decoder we used (the closest one being the maximum likelihood decoder in <a href=\"#bib48\">Miller and Recanzone, 2009</a>), however we do not agree that these studies do empirically what we are doing with simulations. Our key point is that decoders should be tested in a situation when the stimulus is allowed to be variable (different spectrum, etc.); otherwise a large part of the problem is neglected (stimulus-dependent variability). The difference between hemispheric decoder and pattern decoder only appears in this more general situation. The studies cited above generally find that decoders based on patterns (either spike timing or spike counts) perform well, provided there are enough neurons, but because the stimulus is fixed (except for changes in level), they do not show that such decoders are robust (i.e., would work with other sounds). Conversely, the opponent channel model shows good results in one cortical study by Stecker et al., but as in other previous studies in subcortical areas, it may not be robust to stimulus-dependent variability other than level. Our analysis strongly suggests that it is not, because the hemispheric difference is likely also sensitive to sound spectrum and other features that cortical neurons are tuned to, and because adding more neurons in the decoder does not remove stimulus-dependent variability."
                }, 
                {
                    "type": "paragraph", 
                    "text": "<i>It would also be useful for the authors to include comment on the recent paper by Briley et al., JARO 2013, Vol 14: 83-101, which supports the hemispheric model, based on EEG recordings in human</i>."
                }, 
                {
                    "type": "paragraph", 
                    "text": "As far as we understand it, this paper is about cortical responses to different sound locations, not about how these responses might be \u201cdecoded\u201d into an estimate of sound location. It provides some indirect evidence that the distribution of BDs in humans is similar to what was found with single-unit electrophysiology in small mammals, i.e., more neurons with large BDs than expected from a uniform distribution. This observation does not by itself imply that sound location is estimated from the average response (note that the behavioral part in that study is in fact an analysis of the sensitivity of the hemispheric decoder, not of its accuracy as we do in our study). In fact, in our study, we start precisely from such a distribution of BD and show that the hemispheric is suboptimal. Therefore, that paper cannot be taken as evidence in favor of the hemispheric model. The approach is also indirect, as individual neural responses are not measured, and therefore a number of factors other than BD could contribute to EEG responses (e.g., peak firing rate, tuning width, if these properties have a non-zero correlation with BD). We added a mention of that paper in the paragraph about humans."
                }
            ]
        }
    }
}